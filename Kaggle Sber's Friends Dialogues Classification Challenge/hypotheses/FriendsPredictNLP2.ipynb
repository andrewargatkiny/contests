{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":304,"status":"ok","timestamp":1636037468369,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"jfX9Mo2IRKkS","outputId":"72476e94-f6d5-4f3f-9289-95aba0fefb20"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.9.7\n"]}],"source":["! python -V"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.12.3-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 626 kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /home/andrew/anaconda3/envs/nn/lib/python3.9/site-packages (from transformers) (1.21.2)\n","Collecting filelock\n","  Downloading filelock-3.3.2-py3-none-any.whl (9.7 kB)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (661 kB)\n","\u001b[K     |████████████████████████████████| 661 kB 9.8 MB/s \n","\u001b[?25hCollecting regex!=2019.12.17\n","  Downloading regex-2021.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n","\u001b[K     |████████████████████████████████| 762 kB 9.7 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.1.0-py3-none-any.whl (59 kB)\n","\u001b[K     |████████████████████████████████| 59 kB 4.7 MB/s \n","\u001b[?25hCollecting requests\n","  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 712 kB/s \n","\u001b[?25hCollecting tqdm>=4.27\n","  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n","\u001b[K     |████████████████████████████████| 76 kB 3.7 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 9.8 MB/s \n","\u001b[?25hCollecting packaging>=20.0\n","  Downloading packaging-21.2-py3-none-any.whl (40 kB)\n","\u001b[K     |████████████████████████████████| 40 kB 4.5 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 10.4 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /home/andrew/anaconda3/envs/nn/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Collecting pyparsing<3,>=2.0.2\n","  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 4.4 MB/s \n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /home/andrew/anaconda3/envs/nn/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n","Collecting charset-normalizer~=2.0.0\n","  Downloading charset_normalizer-2.0.7-py3-none-any.whl (38 kB)\n","Collecting urllib3<1.27,>=1.21.1\n","  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 10.4 MB/s \n","\u001b[?25hCollecting idna<4,>=2.5\n","  Downloading idna-3.3-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: joblib in /home/andrew/anaconda3/envs/nn/lib/python3.9/site-packages (from sacremoses->transformers) (1.1.0)\n","Collecting click\n","  Downloading click-8.0.3-py3-none-any.whl (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 4.7 MB/s \n","\u001b[?25hRequirement already satisfied: six in /home/andrew/anaconda3/envs/nn/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n","Installing collected packages: urllib3, pyparsing, idna, charset-normalizer, tqdm, requests, regex, pyyaml, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyparsing\n","    Found existing installation: pyparsing 3.0.4\n","    Uninstalling pyparsing-3.0.4:\n","      Successfully uninstalled pyparsing-3.0.4\n","Successfully installed charset-normalizer-2.0.7 click-8.0.3 filelock-3.3.2 huggingface-hub-0.1.0 idna-3.3 packaging-21.2 pyparsing-2.4.7 pyyaml-6.0 regex-2021.11.2 requests-2.26.0 sacremoses-0.0.46 tokenizers-0.10.3 tqdm-4.62.3 transformers-4.12.3 urllib3-1.26.7\n"]}],"source":["! pip install transformers"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":28083,"status":"ok","timestamp":1636037505252,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"JplCyr0VKrhP"},"outputs":[],"source":["import random \n","import time\n","import copy\n","\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","import torch\n","import torch.nn as nn\n","from torch.cuda.amp import autocast, GradScaler\n","\n","from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n","from transformers import BertTokenizer, BertModel, AdamW\n","from transformers import RobertaTokenizer, RobertaModel\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["True"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":209,"referenced_widgets":["adef346525b5428cb77ce85b67b7de02","632a7169fbd74159b11d92ab6cbacfa7","f32062e1b8f74b2ba3ebb65244b8345d","21bf688381ef4a8495a3a6981a84ef8d","d601368d185f4c2f8de3b222976c42ef","a825221a71434b82be79352ad867c68a","52e9ba2a4d974b15ae4b6ab1232dc256","6c7f0e73512743efb870026d6677531e","939389df612a4f23b8ab42d6dccd6c8d","769e20765ef64788b8de218a9853c99e","32acd792c0bf45419a87561dc4ccdb4c","79f29a0c5f01482dbbb7700bd7b573a7","d469fb245e2244848f21d12c9897e0e8","4718ae66701049229c66c8506b3efe1b","bddc64019a20420589041d59a8ac1e86","158f6d85beec4b33bdc422ee9e115808","d70b870ad108499e8651b57c9e9be34b","65cbb712ea2f4dab90ba6600d8440c0b","830958dc67714696a237fc7a051931bc","2d185bee7972497296fc31ba5c0d54d6","faaf710ce2cc471c9370811df2f54ba6","2e6a2c5306764e31bea3a9e37121ff8c","a56c41e3f2744ba6b2f5cd408a86e6d7","d15f42cd6e9d427c99f12b45ba2b04e1","8e60d43dcd7e4df9a554b7b8ed28c56d","ebbe8ae171e94413be8fcc944c05b28b","c280900ff8ba4cc8a2dbf30daad33a4b","192f33925dd045d792b38a2444794a10","a7c1b532fc64473eab127d4f73c4ffd7","d5ed4335e6bb418aaebd5316b616f54c","6502e372ae624b618f6248ee2ea778b6","4e0b4d1769974ba88e49d4fb02e2c4a2","317c759beaf6494db054eae9162ccfb2","a89df2c0f77a445eb9a12550fcaed50d","ee730afc554f486591437c1c9de33490","6cd8338fff6a4f469d417911e8b8142b","edd582160bd349c68d35b5461b9771c2","f1868ee80eff44af8596b13875f7cddd","7148c15a118641d3a9488fd981cc3bf3","54feb1dd180f4bf8b47c18713336d41c","58c863f270ac42c3b195987575a8bc9a","784667efc3604b52a7a3e90afeeba909","5e3622f69800454d9704f414226d5869","6c7b0a0b13b3450fa83c21af7c8525a2","e9d9038ad82440aebdb0fb714add647d","85aa7a96758841a3bb30895cf30d9912","717056921033432aa1612afdd7aab763","f010001c717b439797f738bb4353b74d","0f3925eaafb9438ab0f6b27c356cfe99","58564c36a43e4f3ab99a0e153cb5e480","8d900d48dde840e0824e409582df0dd2","5fa6528c3aa5487e87edb8797ebf465e","d3ce46e504bd4daf9ac3763a7cdc222f","487d23c4e2b64adda4a945df313d1ed1","82b0759acdb845ea9859d2f96ce0e5d3","e87825600783430391ed6af6be32c278","b9b60187d34644bda94b224017bc450d","73c9f7d056704fd2ac03cb76d6f36df5","972de0d98911484dad5f2c7b560d973c","0344eb1638a44fc0bd8be3d2b5aafc99","df27936694364ed583b70df9a0870a08","7d83773323bd4e90bc86003c4220a662","f543e115e78f40f7bc9813a76b5ba862","269978945c9c48d280cd1eb1ddf2f7fc","91647e75ea5e4c16a11046fda73ba026","e2cbc04f6abc4b45b5374f424dd88efa"]},"executionInfo":{"elapsed":4421,"status":"ok","timestamp":1636037509668,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"o24cy8ORGJjU","outputId":"2c57e157-d12e-41c3-9631-cd59f18b134b"},"outputs":[],"source":["#CHECKPOINT = \"sberbank-ai/sbert_large_nlu_ru\"\n","MAX_LEN = 256\n","TRAIN_BATCH_SIZE = 16\n","VALID_BATCH_SIZE = 16\n","EPOCHS = 5\n","LEARNING_RATE = 2e-05\n","#tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)\n","CHECKPOINT = \"sberbank-ai/ruBert-base\"\n","tokenizer = BertTokenizer.from_pretrained(CHECKPOINT)\n","\n","def get_individual_labels(df):\n","    labels = pd.get_dummies(df.label).rename({\n","        \"ДЖОУИ\": \"Joey\", \"МОНИКА\": \"Monica\", \"РЕЙЧЕЛ\": \"Rachel\", \"РОСС\": \"Ross\", \n","        \"ФИБИ\": \"Phoebe\", \"ЧЕНДЛЕР\": \"Chandler\"\n","    }, axis=1)\n","    return pd.concat([df, labels], axis=1)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1636037511385,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"iuShp08vL62l","outputId":"885c5ad6-61d9-40c9-ae33-5be1da37a048"},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/andrew/ml/friends-classification\n","mkdir: cannot create directory ‘models’: File exists\n","example_eng_ru.csv\n","fb_model_translate_en_ru_2_friend_response_test.csv\n","fb_model_translate_en_ru_2_friend_response_train.csv\n","fb_model_translate_en_ru_2_friend_response_val.csv\n","fb_model_translate_en_ru_2_other_speaker_test.csv\n","fb_model_translate_en_ru_2_other_speaker_train.csv\n","fb_model_translate_en_ru_2_other_speaker_val.csv\n","fb_model_translate_ru_en_1_friend_response_test.csv\n","fb_model_translate_ru_en_1_friend_response_train.csv\n","fb_model_translate_ru_en_1_friend_response_val.csv\n","fb_model_translate_ru_en_1_other_speaker_test.csv\n","fb_model_translate_ru_en_1_other_speaker_train.csv\n","fb_model_translate_ru_en_1_other_speaker_val.csv\n","helsinki_model_translate_ru_en_1_friend_response_test.csv\n","helsinki_model_translate_ru_en_1_friend_response_train.csv\n","helsinki_model_translate_ru_en_1_friend_response_val.csv\n","helsinki_model_translate_ru_en_1_other_speaker_test.csv\n","helsinki_model_translate_ru_en_1_other_speaker_train.csv\n","helsinki_model_translate_ru_en_1_other_speaker_val.csv\n","models\n","submission1.csv\n","test.csv\n","test_data_eng_fb_model.csv\n","test_data_eng_google_model.csv\n","test_data_eng_helsinki_model.csv\n","test_data_rus_fb_model.csv\n","train_data.csv\n","train_data_eng_fb_model.csv\n","train_data_eng_google_model.csv\n","train_data_eng_helsinki_model.csv\n","train_data_rus_fb_model.csv\n","val_data.csv\n","val_data_eng_fb_model.csv\n","val_data_eng_google_model.csv\n","val_data_eng_helsinki_model.csv\n","val_data_rus_fb_model.csv\n"]}],"source":["%cd friends-classification/\n","!mkdir models\n","! ls"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":459,"status":"ok","timestamp":1636037511841,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"acv7o-iyMo2n","outputId":"e1180782-7199-4b5b-ef05-41f2f3d4d114"},"outputs":[{"name":"stdout","output_type":"stream","text":["РОСС       0.176569\n","РЕЙЧЕЛ     0.176089\n","ЧЕНДЛЕР    0.170568\n","ДЖОУИ      0.166287\n","МОНИКА     0.160525\n","ФИБИ       0.149962\n","Name: label, dtype: float64\n","\n","РОСС       0.176746\n","РЕЙЧЕЛ     0.176026\n","ЧЕНДЛЕР    0.170626\n","ДЖОУИ      0.166307\n","МОНИКА     0.160547\n","ФИБИ       0.149748\n","Name: label, dtype: float64\n"]}],"source":["df_train = pd.read_csv('train_data.csv').rename({'Category': 'label'}, axis=1)\n","df_train.other_speaker.fillna('', inplace=True)\n","df_val = pd.read_csv('val_data.csv')\n","df_val.other_speaker.fillna('', inplace=True)\n","df_test = pd.read_csv('test.csv')\n","df_test.other_speaker.fillna('', inplace=True)\n","\n","df_train = get_individual_labels(df_train)\n","df_val = get_individual_labels(df_val)\n","\n","# Encoding target variable\n","names_to_cats = LabelEncoder()\n","df_train['label_code'] = names_to_cats.fit_transform(df_train.label)\n","df_val['label_code'] = names_to_cats.transform(df_val.label)\n","df_fb_train = pd.read_csv('train_data_rus_fb_model.csv')\n","df_full = pd.concat([df_train, df_val])\n","print(df_train[\"label\"].value_counts()/df_train.shape[0])\n","print()\n","print(df_val[\"label\"].value_counts()/df_val.shape[0])"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":459,"status":"ok","timestamp":1636037511841,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"acv7o-iyMo2n","outputId":"e1180782-7199-4b5b-ef05-41f2f3d4d114"},"outputs":[{"name":"stdout","output_type":"stream","text":["РОСС       0.176569\n","РЕЙЧЕЛ     0.176089\n","ЧЕНДЛЕР    0.170568\n","ДЖОУИ      0.166287\n","МОНИКА     0.160525\n","ФИБИ       0.149962\n","Name: label, dtype: float64\n","\n","РОСС       0.176746\n","РЕЙЧЕЛ     0.176026\n","ЧЕНДЛЕР    0.170626\n","ДЖОУИ      0.166307\n","МОНИКА     0.160547\n","ФИБИ       0.149748\n","Name: label, dtype: float64\n"]}],"source":["df_train = pd.read_csv('train_data_eng_fb_model.csv')\n","df_train.other_speaker.fillna('', inplace=True)\n","df_val = pd.read_csv('val_data_eng_fb_model.csv')\n","df_val.other_speaker.fillna('', inplace=True)\n","df_test = pd.read_csv('test_data_eng_fb_model.csv')\n","df_test.other_speaker.fillna('', inplace=True)\n","\n","df_train2 = pd.read_csv('train_data_eng_helsinki_model.csv')\n","df_train2.other_speaker.fillna('', inplace=True)\n","df_val2 = pd.read_csv('val_data_eng_helsinki_model.csv')\n","df_val2.other_speaker.fillna('', inplace=True)\n","df_test2 = pd.read_csv('test_data_eng_helsinki_model.csv')\n","df_test2.other_speaker.fillna('', inplace=True)\n","\n","df_train3 = pd.read_csv('train_data_eng_google_model.csv')\n","df_train3.other_speaker.fillna('', inplace=True)\n","df_val3 = pd.read_csv('val_data_eng_google_model.csv')\n","df_val3.other_speaker.fillna('', inplace=True)\n","df_test3 = pd.read_csv('test_data_eng_google_model.csv')\n","df_test3.other_speaker.fillna('', inplace=True)\n","\n","# Encoding target variable\n","names_to_cats = LabelEncoder()\n","df_train['label_code'] = names_to_cats.fit_transform(df_train.label)\n","df_val['label_code'] = names_to_cats.transform(df_val.label)\n","df_fb_train = pd.read_csv('train_data_rus_fb_model.csv')\n","df_full = pd.concat([df_train, df_val])\n","print(df_train[\"label\"].value_counts()/df_train.shape[0])\n","print()\n","print(df_val[\"label\"].value_counts()/df_val.shape[0])"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["df_train_2X = pd.concat([df_train, df_train2])\n","df_train_3X = pd.concat([df_train, df_train2, df_train3])\n","df_val_3X = pd.concat([df_val, df_val2, df_val3])"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>other_speaker</th>\n","      <th>friend_response</th>\n","      <th>label</th>\n","      <th>label_code</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>All right! All right! Enough! Enough! Enough! ...</td>\n","      <td>You know, I think you can take it.</td>\n","      <td>ЧЕНДЛЕР</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Oh, you want a good name, go with Joey. Joey i...</td>\n","      <td>Hey, you know what, if you're going to do this...</td>\n","      <td>ЧЕНДЛЕР</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>My God, what!?</td>\n","      <td>As I said, I was thinking of taking Emma to th...</td>\n","      <td>РОСС</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Pregnancy has a severe effect on the body.</td>\n","      <td>Hey, but even though you got this cool glow of...</td>\n","      <td>ДЖОУИ</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Well, no, that’s the wrong decision. That’s no...</td>\n","      <td>Well, listen, yesterday I would have even thou...</td>\n","      <td>РОСС</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>24988</th>\n","      <td>24988</td>\n","      <td>Nothing! Well, I had a blinding pain in my sto...</td>\n","      <td>Looks like herriation. You must, you - go to t...</td>\n","      <td>ЧЕНДЛЕР</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>24989</th>\n","      <td>24989</td>\n","      <td>Hi.</td>\n","      <td>Very good handshake, good wrist movement.</td>\n","      <td>ФИБИ</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>24990</th>\n","      <td>24990</td>\n","      <td>Joey, how did you spoil it?</td>\n","      <td>Yes, it's easy. Yes, I can do it with anything...</td>\n","      <td>ДЖОУИ</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>24991</th>\n","      <td>24991</td>\n","      <td>Hey! How was your date with Jake?</td>\n","      <td>We could not take the eyes from each other all...</td>\n","      <td>ФИБИ</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>24992</th>\n","      <td>24992</td>\n","      <td>Phoebe, 800 - free, 801 - Utah.</td>\n","      <td>No, no, no, oh no no, no, it should be 801. Be...</td>\n","      <td>ФИБИ</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>74198 rows × 5 columns</p>\n","</div>"],"text/plain":["          Id                                      other_speaker  \\\n","0          0  All right! All right! Enough! Enough! Enough! ...   \n","1          1  Oh, you want a good name, go with Joey. Joey i...   \n","2          2                                     My God, what!?   \n","3          3         Pregnancy has a severe effect on the body.   \n","4          4  Well, no, that’s the wrong decision. That’s no...   \n","...      ...                                                ...   \n","24988  24988  Nothing! Well, I had a blinding pain in my sto...   \n","24989  24989                                                Hi.   \n","24990  24990                        Joey, how did you spoil it?   \n","24991  24991                  Hey! How was your date with Jake?   \n","24992  24992                    Phoebe, 800 - free, 801 - Utah.   \n","\n","                                         friend_response    label  label_code  \n","0                     You know, I think you can take it.  ЧЕНДЛЕР           5  \n","1      Hey, you know what, if you're going to do this...  ЧЕНДЛЕР           5  \n","2      As I said, I was thinking of taking Emma to th...     РОСС           3  \n","3      Hey, but even though you got this cool glow of...    ДЖОУИ           0  \n","4      Well, listen, yesterday I would have even thou...     РОСС           3  \n","...                                                  ...      ...         ...  \n","24988  Looks like herriation. You must, you - go to t...  ЧЕНДЛЕР           5  \n","24989          Very good handshake, good wrist movement.     ФИБИ           4  \n","24990  Yes, it's easy. Yes, I can do it with anything...    ДЖОУИ           0  \n","24991  We could not take the eyes from each other all...     ФИБИ           4  \n","24992  No, no, no, oh no no, no, it should be 801. Be...     ФИБИ           4  \n","\n","[74198 rows x 5 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df_train_3X.drop_duplicates()"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":436},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1636037511842,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"q87GsjIbOl_e","outputId":"382b8f47-59e7-47df-8e3c-c137d3c72bc1"},"outputs":[{"name":"stdout","output_type":"stream","text":["(24993, 5) (2778, 5) (3086, 3)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>other_speaker</th>\n","      <th>friend_response</th>\n","      <th>label</th>\n","      <th>label_code</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Good, and we don't eat at all?</td>\n","      <td>Come on, it's time to be serious, to fight the...</td>\n","      <td>МОНИКА</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>All right, all right, listen, I know I'm Mr. I...</td>\n","      <td>Good, here it is! Get off it!</td>\n","      <td>РОСС</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Yeah. You know, I have all these feelings, and...</td>\n","      <td>Well, I saw a pretty big pigeon.</td>\n","      <td>ДЖОУИ</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>My God! Just a few minutes ago, and now I am.</td>\n","      <td>Wait, you can't give birth here! That is, I di...</td>\n","      <td>МОНИКА</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Not as he is, just not as he is.</td>\n","      <td>Look, this is an artist formerly known as Chan...</td>\n","      <td>РОСС</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2773</th>\n","      <td>2773</td>\n","      <td>What's going on tonight?</td>\n","      <td>This is our first official date. Our first date.</td>\n","      <td>РЕЙЧЕЛ</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2774</th>\n","      <td>2774</td>\n","      <td>Hey, aren't you dressed up?</td>\n","      <td>Yes, and this time you better make sure that h...</td>\n","      <td>РЕЙЧЕЛ</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2775</th>\n","      <td>2775</td>\n","      <td>You were not there!</td>\n","      <td>No, but it's, you know, just a funny picture, ...</td>\n","      <td>РОСС</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2776</th>\n","      <td>2776</td>\n","      <td>You are talking on the phone!</td>\n","      <td>That was the fire part, we had a fire!</td>\n","      <td>РЕЙЧЕЛ</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2777</th>\n","      <td>2777</td>\n","      <td>I'm sorry.</td>\n","      <td>At least I earned ten dollars on my relationsh...</td>\n","      <td>РОСС</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2778 rows × 5 columns</p>\n","</div>"],"text/plain":["        Id                                      other_speaker  \\\n","0        0                     Good, and we don't eat at all?   \n","1        1  All right, all right, listen, I know I'm Mr. I...   \n","2        2  Yeah. You know, I have all these feelings, and...   \n","3        3      My God! Just a few minutes ago, and now I am.   \n","4        4                   Not as he is, just not as he is.   \n","...    ...                                                ...   \n","2773  2773                           What's going on tonight?   \n","2774  2774                        Hey, aren't you dressed up?   \n","2775  2775                                You were not there!   \n","2776  2776                      You are talking on the phone!   \n","2777  2777                                         I'm sorry.   \n","\n","                                        friend_response   label  label_code  \n","0     Come on, it's time to be serious, to fight the...  МОНИКА           1  \n","1                         Good, here it is! Get off it!    РОСС           3  \n","2                      Well, I saw a pretty big pigeon.   ДЖОУИ           0  \n","3     Wait, you can't give birth here! That is, I di...  МОНИКА           1  \n","4     Look, this is an artist formerly known as Chan...    РОСС           3  \n","...                                                 ...     ...         ...  \n","2773   This is our first official date. Our first date.  РЕЙЧЕЛ           2  \n","2774  Yes, and this time you better make sure that h...  РЕЙЧЕЛ           2  \n","2775  No, but it's, you know, just a funny picture, ...    РОСС           3  \n","2776             That was the fire part, we had a fire!  РЕЙЧЕЛ           2  \n","2777  At least I earned ten dollars on my relationsh...    РОСС           3  \n","\n","[2778 rows x 5 columns]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["print(df_train.shape, df_val.shape, df_test.shape)\n","df_val"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":264,"status":"ok","timestamp":1636041805080,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"6fwxjlLEGzIT"},"outputs":[],"source":["class FriendsDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_length=512, padding='max_length', \n","                 with_labels=True):\n","\n","        self.dataframe = dataframe  # pandas dataframe\n","        #Initialize the tokenizer\n","        self.tokenizer = tokenizer  \n","        self.padding = padding\n","        self.max_length = max_length\n","        \n","        self.with_labels = with_labels \n","        if 'label' not in self.dataframe.columns:\n","          self.with_labels = False\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, index):\n","\n","        # Selecting sentence1 and sentence2 at the specified index in the data frame\n","        sent1 = self.dataframe.other_speaker.iloc[index]\n","        sent2 = self.dataframe.friend_response.iloc[index]\n","\n","        # Tokenize the pair of sentences to get token ids, attention masks and token type ids\n","        encoded_pair = self.tokenizer(sent1, sent2, \n","                                      padding=self.padding,  # Pad to max_length\n","                                      truncation=True,  # Truncate to max_length\n","                                      max_length=self.max_length,  \n","                                      return_tensors='pt')  # Return torch.Tensor objects\n","        \n","        token_ids = encoded_pair['input_ids'].squeeze(0)  # tensor of token ids\n","        attn_masks = encoded_pair['attention_mask'].squeeze(0)  # binary tensor with \"0\" for padded values and \"1\" for the other values\n","        token_type_ids = encoded_pair['token_type_ids'].squeeze(0)  # binary tensor with \"0\" for the 1st sentence tokens & \"1\" for the 2nd sentence tokens\n","\n","        if self.with_labels:  # True if the dataset has labels\n","            label = self.dataframe.label_code.iloc[index]\n","            label = self.dataframe.Phoebe.iloc[index]\n","            return token_ids, attn_masks, token_type_ids, label  \n","        else:\n","            return token_ids, attn_masks, token_type_ids"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1636011617187,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"qJWu9ZEGYwui","outputId":"b0920bbc-27cd-43ce-ebd6-15ab7ac953c5"},"outputs":[],"source":["FriendsDataset(df_val, tokenizer)[2]"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1636011617187,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"NCOVhXIwY8EQ","outputId":"adfd41dd-9c00-431d-d1b1-afdd0d7428d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'input_ids': [[101, 9006, 121, 106, 945, 2167, 672, 18111, 686, 161, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 9006, 121, 9006, 121, 24103, 378, 121, 119, 2289, 121, 693, 1806, 4331, 1231, 50085, 31392, 24625, 121, 750, 736, 818, 5409, 121, 119, 9268, 113, 4775, 5617, 121, 785, 947, 27480, 1499, 121, 107, 119, 1293, 3371, 52885, 114, 1905, 107, 45808, 1679, 121, 3823, 377, 378, 121, 6254, 2808, 121, 1293, 121, 1293, 67095, 1024, 126, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"]}],"source":["print(tokenizer.batch_encode_plus(df_val.other_speaker[:2].to_list(), padding=True))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1636011621059,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"XeQGWQHShk6g","outputId":"4f1b0520-0753-4b2b-c630-9f6d25aa5a68"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'input_ids': [[101, 9006, 121, 106, 945, 2167, 672, 18111, 686, 161, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 9006, 121, 9006, 121, 24103, 378, 121, 119, 2289, 121, 693, 1806, 4331, 1231, 50085, 31392, 24625, 121, 750, 736, 818, 5409, 121, 119, 9268, 113, 4775, 5617, 121, 785, 947, 27480, 1499, 121, 107, 119, 1293, 3371, 52885, 114, 1905, 107, 45808, 1679, 121, 3823, 377, 378, 121, 6254, 2808, 121, 1293, 121, 1293, 67095, 1024, 126, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'[CLS] ладно, а мы вообще не обедаем? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["encoded_input = tokenizer(df_val.other_speaker[:2].to_list(), padding=True)\n","print(encoded_input)\n","tokenizer.decode(encoded_input[\"input_ids\"][0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":273,"status":"ok","timestamp":1636011626459,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"A3MzcF4WhqPF","outputId":"4510c98f-3b98-4733-ef1c-72fc36133c5a"},"outputs":[{"data":{"text/plain":["['Ладно, а мы вообще не обедаем?',\n"," 'Ладно, ладно, послушай, я знаю, что сегодня веду себя мистером Несоответствующим, но это так тяжело, я имею в виду увидеть, как ты гуляешь, и я просто хочу прикоснуться к тебе и обнять тебя, давай, никого рядом, просто, просто поцелуй меня.']"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["df_val.other_speaker[:2].to_list()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"elapsed":544,"status":"ok","timestamp":1636011627375,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"ERDB6JyobclV","outputId":"0fe39def-fc13-40f3-fb72-c8dcfd8ecafe"},"outputs":[{"data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7fe6eb47fbd0>"]},"execution_count":14,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["seq_len = [len(i.split()) for i in df_train.other_speaker.fillna('')]\n","\n","pd.Series(seq_len).hist(bins = 30)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":469},"executionInfo":{"elapsed":644,"status":"ok","timestamp":1636011628318,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"8vdS5P-2az0b","outputId":"5e99479f-a945-443c-97a5-ec54b965acef"},"outputs":[{"data":{"text/plain":["17         4\n","18         7\n","19        14\n","20        26\n","21        48\n","       ...  \n","268    29293\n","269    29308\n","270    29329\n","271    29345\n","272    29365\n","Name: seq_len, Length: 256, dtype: int64"]},"execution_count":15,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["dfs_all = pd.concat([df_train, df_val, df_test])\n","dfs_all['seq_len'] = dfs_all.apply(lambda row: \n","                                   len(row['other_speaker'] + row['friend_response']), axis=1)\n","print(len(dfs_all), \"number of all dialogs in train, validation and test\")\n","[len(i.split()) for i in dfs_all.other_speaker]\n","dfs_all['seq_len'].hist(bins = 30)\n","dfs_all['seq_len'].value_counts().sort_index(ascending=True).cumsum().head(256)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1635935619917,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"sbhksA3xcLna","outputId":"107b86ad-8bb8-439f-b706-aa823fce7773"},"outputs":[{"data":{"text/plain":["count     24993\n","unique    21269\n","top        Что?\n","freq        263\n","Name: other_speaker, dtype: object"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["df_train.other_speaker.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Mdv07RUakHR"},"outputs":[],"source":["model = BertModel.from_pretrained(CHECKPOINT)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1635926776189,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"iagLgdpUbxzU","outputId":"8c46b13a-8ee1-4c58-8cd5-3f505169c983"},"outputs":[{"data":{"text/plain":["BertConfig {\n","  \"_name_or_path\": \"sberbank-ai/sbert_large_nlu_ru\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 120138\n","}"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["model.config"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1635926776190,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"eL0HT2PmSj3D","outputId":"1f3b9b1d-90ad-40fd-ea98-e7c729eb4ebb"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Ага. Знаешь, у меня есть все эти чувства, и я не знаю, что с ними делать, потому что я не могу встречаться как нормальный человек, и это нормально, потому что мне не нужны отношения, я имею в виду все, что я действительно хочу одну отличную ночь. Просто секс, понимаешь? Никаких условий, никаких отношений, просто с кем-то, с кем мне комфортно и кто знает, что он делает. Я имею в виду, что на одну прекрасную ночь действительно так… трудно… найти. Как прошел твой день?'"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["df_val.other_speaker[2]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1367,"status":"ok","timestamp":1635926777543,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"huooGHOoccF2","outputId":"9dcaf530-386d-424e-cadd-ec33483c4ba1"},"outputs":[{"name":"stdout","output_type":"stream","text":["BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 7.1882e-01, -5.3918e-03, -8.3920e-01,  ...,  3.3451e-01,\n","          -3.1676e-01, -5.1034e-01],\n","         [ 5.5719e-01, -8.0553e-02, -3.7181e-01,  ..., -1.7804e-01,\n","          -1.0751e-02, -9.4979e-01],\n","         [ 8.5000e-01, -2.2997e-01, -1.1100e+00,  ..., -2.6581e-01,\n","           4.5181e-01, -4.4495e-04],\n","         ...,\n","         [ 1.0387e+00,  2.0646e-02, -9.4394e-01,  ...,  3.9442e-02,\n","           5.3907e-01, -6.4463e-01],\n","         [ 8.8433e-01, -3.8336e-02, -1.5689e+00,  ...,  3.1330e-01,\n","           6.2395e-01,  3.8496e-02],\n","         [-5.5417e-01, -1.9077e-01, -9.9541e-01,  ..., -4.3991e-01,\n","          -4.3730e-01,  3.4922e-01]]]), pooler_output=tensor([[ 0.0782,  0.0337, -0.4183,  ..., -0.1049,  0.8060, -0.0340]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","torch.Size([1, 1024]) torch.Size([1, 118, 1024])\n"]}],"source":["with torch.no_grad():\n","  output = model(**tokenizer(df_val.other_speaker[2], return_tensors='pt'), )\n","print(output)\n","print(output.pooler_output.shape, output.last_hidden_state.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1635923888287,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"1BUrLzPQfm3e","outputId":"4ffacb2f-5021-4cb1-e8bf-8b470ca8ed2e"},"outputs":[{"data":{"text/plain":["{'input_ids': tensor([[  101, 20054,   126,  5075,   121,   118,  1024,  1114,   780,  1090,\n","          6724,   121,   107,   119,   672,  2289,   121,   693,   110,  3192,\n","          2555,   121,  1747,   693,   119,   672,  1385, 20345,   785,  3122,\n","         20900,   378,  1266,   121,   107,   736,  8501,   121,  1747,   693,\n","          1098,   672,  6474,  3269,   121,   119,  9268,   113,  4775,   780,\n","           121,   693,   119,   784, 34083, 21338,  1102,  3371,  3641, 46962,\n","          2774,   126,  1293, 18341,   121, 10302,   161,  4029, 16437,   121,\n","          4029,  3384,   121,  1293,   110,  5477,   133,   696,   121,   110,\n","          5477,  1098, 22819,   107,  1309,  3730,   121,   693,   795,  5190,\n","           126,   119,  9268,   113,  4775,   121,   693,   660,  3641, 40184,\n","          2774,   784, 34083, 21338,  1102,   818,   194,  4759,   194,  2775,\n","           680,   126,   785,  6568,  9229,  1336,   161,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer(df_val.other_speaker[2], return_tensors='pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1635923888288,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"9osfOgxuaO43","outputId":"51928964-2fc1-4125-ad46-a18bff032606"},"outputs":[{"data":{"text/plain":["{'cls_token': '[CLS]',\n"," 'mask_token': '[MASK]',\n"," 'pad_token': '[PAD]',\n"," 'sep_token': '[SEP]',\n"," 'unk_token': '[UNK]'}"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.special_tokens_map"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1636037511843,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"jLmUmq46a0D6"},"outputs":[],"source":["class SentencePairClassifier(nn.Module):\n","\n","    def __init__(self, model=CHECKPOINT, freeze_model=True):\n","        super(SentencePairClassifier, self).__init__()\n","        #  Instantiating BERT-based model object\n","        # self.pretrained_layer = AutoModel.from_pretrained(CHECKPOINT)\n","        self.pretrained_layer = BertModel.from_pretrained(CHECKPOINT)\n","        #self.pretrained_layer = RobertaModel.from_pretrained(CHECKPOINT)\n","\n","        hidden_size = self.pretrained_layer.config.hidden_size\n","\n","        # Freeze model layers and only train the classification layer weights\n","        if freeze_model:\n","            for p in self.pretrained_layer.parameters():\n","                p.requires_grad = False\n","            print('All parameters frozen')\n","        # Classification layer\n","        self.cls_layer = nn.Linear(hidden_size, 2)\n","\n","        self.dropout = nn.Dropout(p=0.3)\n","\n","    @autocast()  # run in mixed precision\n","    def forward(self, input_ids, attn_masks, token_type_ids):\n","        '''\n","        Inputs:\n","            -input_ids : Tensor  containing token ids\n","            -attn_masks : Tensor containing attention masks to be used to focus on non-padded values\n","            -token_type_ids : Tensor containing token type ids to be used to identify sentence1 and sentence2\n","        '''\n","\n","        # Feeding the inputs to the BERT-based model to obtain contextualized representations\n","        output = self.pretrained_layer(input_ids, attn_masks, token_type_ids)\n","\n","        # Feeding to the classifier layer the last layer hidden-state of the [CLS] token further processed by a\n","        # Linear Layer and a Tanh activation. The Linear layer weights were trained from the sentence order prediction (ALBERT) or next sentence prediction (BERT)\n","        # objective during pre-training.\n","        logits = self.cls_layer(self.dropout(output.pooler_output))\n","\n","        return logits"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1636037511843,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"JKiUIjwGiWEv"},"outputs":[],"source":["def set_seed(seed):\n","    \"\"\" Set all seeds to make results reproducible \"\"\"\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    #os.environ['PYTHONHASHSEED'] = str(seed)\n","    \n","@autocast()\n","def evaluate_loss(net, device, criterion, dataloader):\n","    net.eval()\n","    n_correct = 0\n","    mean_loss = 0\n","    count = 0\n","\n","    with torch.no_grad():\n","        for it, (seq, attn_masks, token_type_ids, labels) in enumerate(tqdm(dataloader)):\n","            seq, attn_masks, token_type_ids, labels = \\\n","                seq.to(device), attn_masks.to(device), token_type_ids.to(device), labels.to(device)\n","            logits = net(seq, attn_masks, token_type_ids)\n","            mean_loss += criterion(logits.squeeze(-1), labels).item()\n","            count += 1\n","            max_logits, argmax_idx = torch.max(logits.data, dim=1)\n","            n_correct += calcuate_accu(argmax_idx, labels)\n","    del logits\n","    return mean_loss / count, n_correct / len(dataloader.dataset)\n","  \n","# Function to calcuate the accuracy of the model\n","def calcuate_accu(big_idx, targets):\n","    n_correct = (big_idx==targets).sum().item()\n","    return n_correct"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":271,"status":"ok","timestamp":1636040507768,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"NNBTL2IC8PMJ"},"outputs":[],"source":["def train_bert(net, criterion, opti, lr, lr_scheduler, train_loader, val_loader, epochs, iters_to_accumulate):\n","\n","    best_loss = np.Inf\n","    best_acc = 0\n","    best_ep = 1\n","    n_iterations = len(train_loader)\n","    batch_size = train_loader.batch_size\n","    print_every = 1000 // batch_size  # print the training loss this many times per epoch\n","    print_eval_iters = 10000 // batch_size\n","    scaler = GradScaler()\n","\n","    for ep in range(epochs):\n","        net.train()\n","        curr_loss = 0.0\n","        curr_n_correct = 0.\n","        trailing_loss = 0.\n","        trailing_n_correct = 0.\n","        curr_n_tr_examples = 0\n","        trainling_n_tr_examples = 0\n","\n","        for it, (seq, attn_masks, token_type_ids, labels) in enumerate(tqdm(train_loader)):\n","            # Converting to cuda tensors\n","            seq, attn_masks, token_type_ids, labels = \\\n","                seq.to(device), attn_masks.to(device), token_type_ids.to(device), labels.to(device)\n","  \n","            # Enables autocasting for the forward pass (model + loss)\n","            with autocast():\n","                # Obtaining the logits from the model\n","                pooled = net(seq, attn_masks, token_type_ids)\n","\n","                # Computing loss\n","                loss = criterion(pooled.squeeze(-1), labels)\n","                #print(loss, type(loss))\n","                loss = loss / iters_to_accumulate  # Normalize the loss because it is averaged\n","                # Computing accuracy\n","                #print(pooled.squeeze(-1), labels)\n","                curr_loss += loss.item() \n","                big_val, big_idx = torch.max(pooled.data, dim=1)\n","                n_correct = calcuate_accu(big_idx, labels)\n","                curr_n_correct += n_correct\n","\n","            trailing_loss += loss.item() \n","            trailing_n_correct += n_correct\n","            curr_n_tr_examples += labels.size(0)\n","            trainling_n_tr_examples += labels.size(0)\n","\n","            # Backpropagating the gradients\n","            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n","            scaler.scale(loss).backward()\n","\n","            if (it + 1) % iters_to_accumulate == 0:\n","                # Optimization step\n","                # scaler.step() first unscales the gradients of the optimizer's assigned params.\n","                # If these gradients do not contain infs or NaNs, opti.step() is then called,\n","                # otherwise, opti.step() is skipped.\n","                scaler.step(opti)\n","                # Updates the scale for next iteration.\n","                scaler.update()\n","                # Adjust the learning rate based on the number of iterations.\n","                lr_scheduler.step()\n","                # Clear gradients\n","                opti.zero_grad()\n","\n","            if (it + 1) % print_every == 0:  # Print training loss information\n","                print()\n","                print(\"Batch {}/{} of epoch {} complete. Loss per last {} samples:: {} \"\n","                      .format(it+1, n_iterations, ep+1, curr_n_tr_examples, curr_loss / print_every))\n","                accu_step = (curr_n_correct*100) / curr_n_tr_examples \n","                #print(f\"Training Loss per 5000 steps: {loss_step}\")\n","                print(f\"Training Accuracy per last {curr_n_tr_examples} samples: {accu_step}\")\n","                curr_loss = 0.0\n","                curr_n_tr_examples = 0\n","                curr_n_correct = 0\n","\n","\n","            if (it + 1) % print_eval_iters == 0 or it ==  n_iterations - 1:\n","                del pooled, loss\n","                print(\"Epoch {}, batch {} complete! Training Loss : {}\"\n","                .format(ep+1, it+1, trailing_loss / (it+1)))\n","                print(\"Epoch {}, batch {} complete! Training Accuracy : {}\"\n","                .format(ep+1, it+1, trailing_n_correct / trainling_n_tr_examples))\n","                with autocast():\n","                    val_loss, val_accuracy = evaluate_loss(net, device, criterion, val_loader)  # Compute validation loss\n","                #print()\n","                print(\"Epoch {}, batch {} complete! Validation Loss : {}\".format(ep+1, it+1, val_loss))\n","                print(\"Epoch {}, batch {} complete! Validation Accuracy : {}\".format(ep+1, it+1,val_accuracy))\n","                net.train()\n","                #if val_loss < best_loss:\n","                if val_accuracy > best_acc:\n","                    print(\"Validation loss changed from {} to {}\".format(best_loss, val_loss))\n","                    print(\"Best validation accuracy improved from {} to {}\".format(best_acc, val_accuracy))\n","                    print()\n","                    #net_copy = copy.deepcopy(net)  # save a copy of the model\n","                    best_loss = val_loss\n","                    best_acc = val_accuracy\n","                    best_ep = ep + 1\n","                    # Saving the model\n","                    path_to_model='models/{}_lr_{}_val_acc_{}_ep_{}.pt'.format(time.ctime(), lr, round(best_acc, 4), best_ep)\n","                    torch.save(net.state_dict(), path_to_model)\n","                    print(\"The model has been saved in {}\".format(path_to_model))\n","\n","    torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["3d8a373f8b1a4da3841d55ed5fd62935","5435b27f9fab4fcd9f0cf0fe1f11db71","b968066f8f924c309860b111ae0816a4","98ff0c5dbe8049c588ef631dfbc08ef8","121075183d2441ddb2e99f849d2e9686","77b7765f0fe04c8a976230fb2eb01065","88b743167cd44b318de6a3998f466556","ef630b6fc27b4750839918ef7ac13c6c","e55762599f664a0fa5288de998af11c1","e3aeb80a52bf4ccdb69330b3ebce4355","7f4f04df6382427288c4e9422e4fbf7d"]},"executionInfo":{"elapsed":1839309,"status":"ok","timestamp":1636039351577,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"tV_3pDzJ81v9","outputId":"5413e47a-47a4-4216-9f14-592c6d734425"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading training data...\n","Reading validation data...\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at sberbank-ai/ruBert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["cuda:0\n"]}],"source":["from transformers import get_linear_schedule_with_warmup\n","from transformers import get_constant_schedule\n","from sklearn.utils import compute_class_weight\n","#  Set all seeds to make reproducible results\n","set_seed(1)\n","\n","# Creating instances of training and validation set\n","print(\"Reading training data...\")\n","train_set = FriendsDataset(dataframe=df_train, tokenizer=tokenizer, max_length=MAX_LEN)\n","#train_set = FriendsDataset(dataframe=df_full, tokenizer=tokenizer, max_length=MAX_LEN)\n","\n","print(\"Reading validation data...\")\n","val_set = FriendsDataset(dataframe=df_val, tokenizer=tokenizer, max_length=MAX_LEN)\n","# Creating instances of training and validation dataloaders\n","train_loader = DataLoader(train_set, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_set, batch_size=VALID_BATCH_SIZE, shuffle=False, num_workers=2)\n","\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","net = SentencePairClassifier(model=CHECKPOINT, freeze_model=False)\n","print(device)\n","\n","if torch.cuda.device_count() > 1:  # if multiple GPUs\n","    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n","    net = nn.DataParallel(net)\n","\n","net.to(device)\n","\n","class_weights = compute_class_weight(\n","    'balanced', \n","    classes=np.unique(df_train.Phoebe), y=df_train.Phoebe)\n","class_weights = torch.tensor(class_weights, dtype=torch.float)\n","class_weights = class_weights.to(device)\n","criterion = nn.CrossEntropyLoss(weight=class_weights)\n","\n","opti = AdamW(net.parameters(), lr=LEARNING_RATE, weight_decay=1e-2)\n","num_warmup_steps = 0 # The number of steps for the warmup phase.\n","iters_to_accumulate = 2\n","num_training_steps = EPOCHS * len(train_loader)  # The total number of training steps\n","t_total = (len(train_loader) // iters_to_accumulate) * EPOCHS  # Necessary to take into account Gradient accumulation\n","#lr_scheduler = get_linear_schedule_with_warmup(optimizer=opti, num_warmup_steps=num_warmup_steps, num_training_steps=t_total)\n","lr_scheduler = get_constant_schedule(optimizer=opti)\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  4%|▍         | 62/1563 [00:40<16:03,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 62/1563 of epoch 1 complete. Loss per last 992 samples:: 0.35020277528993543 \n","Training Accuracy per last 992 samples: 67.64112903225806\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 124/1563 [01:24<17:18,  1.39it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 124/1563 of epoch 1 complete. Loss per last 992 samples:: 0.355123647278355 \n","Training Accuracy per last 992 samples: 63.00403225806452\n"]},{"name":"stderr","output_type":"stream","text":[" 12%|█▏        | 186/1563 [02:08<16:24,  1.40it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 186/1563 of epoch 1 complete. Loss per last 992 samples:: 0.34738927358581173 \n","Training Accuracy per last 992 samples: 72.68145161290323\n"]},{"name":"stderr","output_type":"stream","text":[" 16%|█▌        | 248/1563 [02:53<15:45,  1.39it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 248/1563 of epoch 1 complete. Loss per last 992 samples:: 0.35068977455939015 \n","Training Accuracy per last 992 samples: 68.8508064516129\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|█▉        | 310/1563 [03:38<14:54,  1.40it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 310/1563 of epoch 1 complete. Loss per last 992 samples:: 0.3601706624031067 \n","Training Accuracy per last 992 samples: 53.62903225806452\n"]},{"name":"stderr","output_type":"stream","text":[" 24%|██▍       | 372/1563 [04:22<14:20,  1.38it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 372/1563 of epoch 1 complete. Loss per last 992 samples:: 0.34365792476361795 \n","Training Accuracy per last 992 samples: 58.266129032258064\n"]},{"name":"stderr","output_type":"stream","text":[" 28%|██▊       | 434/1563 [05:07<13:25,  1.40it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 434/1563 of epoch 1 complete. Loss per last 992 samples:: 0.35680137790979877 \n","Training Accuracy per last 992 samples: 60.483870967741936\n"]},{"name":"stderr","output_type":"stream","text":[" 32%|███▏      | 496/1563 [05:48<11:37,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 496/1563 of epoch 1 complete. Loss per last 992 samples:: 0.34899738382908607 \n","Training Accuracy per last 992 samples: 56.04838709677419\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▌      | 558/1563 [06:29<10:58,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 558/1563 of epoch 1 complete. Loss per last 992 samples:: 0.3583476000255154 \n","Training Accuracy per last 992 samples: 59.375\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 620/1563 [07:09<10:16,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 620/1563 of epoch 1 complete. Loss per last 992 samples:: 0.34432818380094343 \n","Training Accuracy per last 992 samples: 64.51612903225806\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 624/1563 [07:12<10:16,  1.52it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 625 complete! Training Loss : 0.3513881617307663\n","Epoch 1, batch 625 complete! Training Accuracy : 0.6256\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 625 complete! Validation Loss : 0.6582543937296703\n","Epoch 1, batch 625 complete! Validation Accuracy : 0.7566594672426206\n","Validation loss changed from inf to 0.6582543937296703\n","Best validation accuracy improved from 0 to 0.7566594672426206\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 625/1563 [07:52<3:16:55, 12.60s/it]"]},{"name":"stdout","output_type":"stream","text":["The model has been saved in models/Tue Nov 16 14:53:41 2021_lr_2e-05_val_acc_0.7567_ep_1.pt\n"]},{"name":"stderr","output_type":"stream","text":[" 44%|████▎     | 682/1563 [08:29<09:36,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 682/1563 of epoch 1 complete. Loss per last 992 samples:: 0.34459150606586086 \n","Training Accuracy per last 992 samples: 68.95161290322581\n"]},{"name":"stderr","output_type":"stream","text":[" 48%|████▊     | 744/1563 [09:09<08:54,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 744/1563 of epoch 1 complete. Loss per last 992 samples:: 0.3453815266970665 \n","Training Accuracy per last 992 samples: 56.55241935483871\n"]},{"name":"stderr","output_type":"stream","text":[" 52%|█████▏    | 806/1563 [09:50<08:14,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 806/1563 of epoch 1 complete. Loss per last 992 samples:: 0.3326312959674866 \n","Training Accuracy per last 992 samples: 73.89112903225806\n"]},{"name":"stderr","output_type":"stream","text":[" 56%|█████▌    | 868/1563 [10:30<07:34,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 868/1563 of epoch 1 complete. Loss per last 992 samples:: 0.33989367754228655 \n","Training Accuracy per last 992 samples: 68.6491935483871\n"]},{"name":"stderr","output_type":"stream","text":[" 57%|█████▋    | 887/1563 [10:42<07:16,  1.55it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 60%|█████▉    | 930/1563 [11:10<06:54,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 930/1563 of epoch 1 complete. Loss per last 992 samples:: 0.3295661160542119 \n","Training Accuracy per last 992 samples: 78.32661290322581\n"]},{"name":"stderr","output_type":"stream","text":[" 63%|██████▎   | 992/1563 [11:51<06:18,  1.51it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 992/1563 of epoch 1 complete. Loss per last 992 samples:: 0.32978402630936715 \n","Training Accuracy per last 992 samples: 70.76612903225806\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 1054/1563 [12:32<05:31,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1054/1563 of epoch 1 complete. Loss per last 992 samples:: 0.34040963673783886 \n","Training Accuracy per last 992 samples: 65.02016129032258\n"]},{"name":"stderr","output_type":"stream","text":[" 71%|███████▏  | 1116/1563 [13:12<04:51,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1116/1563 of epoch 1 complete. Loss per last 992 samples:: 0.34021522609456895 \n","Training Accuracy per last 992 samples: 70.76612903225806\n"]},{"name":"stderr","output_type":"stream","text":[" 75%|███████▌  | 1178/1563 [13:52<04:10,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1178/1563 of epoch 1 complete. Loss per last 992 samples:: 0.32608017445571963 \n","Training Accuracy per last 992 samples: 70.36290322580645\n"]},{"name":"stderr","output_type":"stream","text":[" 78%|███████▊  | 1217/1563 [14:17<03:42,  1.56it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 79%|███████▉  | 1240/1563 [14:32<03:30,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1240/1563 of epoch 1 complete. Loss per last 992 samples:: 0.3365840558563509 \n","Training Accuracy per last 992 samples: 66.12903225806451\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|███████▉  | 1249/1563 [14:38<03:21,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 1250 complete! Training Loss : 0.3437221996426582\n","Epoch 1, batch 1250 complete! Training Accuracy : 0.65815\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:40<00:00,  4.31it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 1250 complete! Validation Loss : 0.6488456061516685\n","Epoch 1, batch 1250 complete! Validation Accuracy : 0.8516918646508279\n","Validation loss changed from 0.6582543937296703 to 0.6488456061516685\n","Best validation accuracy improved from 0.7566594672426206 to 0.8516918646508279\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|███████▉  | 1250/1563 [15:20<1:08:42, 13.17s/it]"]},{"name":"stdout","output_type":"stream","text":["The model has been saved in models/Tue Nov 16 15:01:09 2021_lr_2e-05_val_acc_0.8517_ep_1.pt\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 1302/1563 [15:54<02:50,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1302/1563 of epoch 1 complete. Loss per last 992 samples:: 0.3308110371712715 \n","Training Accuracy per last 992 samples: 77.41935483870968\n"]},{"name":"stderr","output_type":"stream","text":[" 87%|████████▋ | 1364/1563 [16:34<02:09,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1364/1563 of epoch 1 complete. Loss per last 992 samples:: 0.3213578337623227 \n","Training Accuracy per last 992 samples: 76.71370967741936\n"]},{"name":"stderr","output_type":"stream","text":[" 91%|█████████ | 1426/1563 [17:15<01:29,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1426/1563 of epoch 1 complete. Loss per last 992 samples:: 0.3305612043026955 \n","Training Accuracy per last 992 samples: 69.35483870967742\n"]},{"name":"stderr","output_type":"stream","text":[" 93%|█████████▎| 1454/1563 [17:33<01:11,  1.53it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 95%|█████████▌| 1488/1563 [17:55<00:49,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1488/1563 of epoch 1 complete. Loss per last 992 samples:: 0.3313484348116382 \n","Training Accuracy per last 992 samples: 69.25403225806451\n"]},{"name":"stderr","output_type":"stream","text":[" 99%|█████████▉| 1550/1563 [18:35<00:08,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1550/1563 of epoch 1 complete. Loss per last 992 samples:: 0.3185009667950292 \n","Training Accuracy per last 992 samples: 71.27016129032258\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 1562/1563 [18:43<00:00,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 1563 complete! Training Loss : 0.34055127821247777\n","Epoch 1, batch 1563 complete! Training Accuracy : 0.6722682351058297\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.55it/s]\n","100%|██████████| 1563/1563 [19:21<00:00,  1.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 1563 complete! Validation Loss : 0.638644377733099\n","Epoch 1, batch 1563 complete! Validation Accuracy : 0.8297336213102952\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 62/1563 [00:40<16:19,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 62/1563 of epoch 2 complete. Loss per last 992 samples:: 0.3198511944182457 \n","Training Accuracy per last 992 samples: 68.75\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 124/1563 [01:20<15:40,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 124/1563 of epoch 2 complete. Loss per last 992 samples:: 0.30937983864738094 \n","Training Accuracy per last 992 samples: 71.37096774193549\n"]},{"name":"stderr","output_type":"stream","text":[" 12%|█▏        | 186/1563 [02:01<15:01,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 186/1563 of epoch 2 complete. Loss per last 992 samples:: 0.30756006750368303 \n","Training Accuracy per last 992 samples: 68.14516129032258\n"]},{"name":"stderr","output_type":"stream","text":[" 16%|█▌        | 248/1563 [02:41<14:17,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 248/1563 of epoch 2 complete. Loss per last 992 samples:: 0.3198856946922118 \n","Training Accuracy per last 992 samples: 65.625\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|█▉        | 310/1563 [03:21<13:40,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 310/1563 of epoch 2 complete. Loss per last 992 samples:: 0.309460754596418 \n","Training Accuracy per last 992 samples: 75.60483870967742\n"]},{"name":"stderr","output_type":"stream","text":[" 24%|██▍       | 372/1563 [04:01<12:57,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 372/1563 of epoch 2 complete. Loss per last 992 samples:: 0.2895948605672006 \n","Training Accuracy per last 992 samples: 80.24193548387096\n"]},{"name":"stderr","output_type":"stream","text":[" 28%|██▊       | 434/1563 [04:42<12:17,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 434/1563 of epoch 2 complete. Loss per last 992 samples:: 0.31262298288845247 \n","Training Accuracy per last 992 samples: 70.16129032258064\n"]},{"name":"stderr","output_type":"stream","text":[" 32%|███▏      | 496/1563 [05:22<11:38,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 496/1563 of epoch 2 complete. Loss per last 992 samples:: 0.3060238116210507 \n","Training Accuracy per last 992 samples: 72.98387096774194\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▌      | 558/1563 [06:02<10:59,  1.52it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 558/1563 of epoch 2 complete. Loss per last 992 samples:: 0.3097180726547395 \n","Training Accuracy per last 992 samples: 67.64112903225806\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 620/1563 [06:43<10:16,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 620/1563 of epoch 2 complete. Loss per last 992 samples:: 0.301545214989493 \n","Training Accuracy per last 992 samples: 67.84274193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 624/1563 [06:45<10:17,  1.52it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 625 complete! Training Loss : 0.3083141553401947\n","Epoch 2, batch 625 complete! Training Accuracy : 0.7088\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.55it/s]\n"," 40%|███▉      | 625/1563 [07:24<3:09:41, 12.13s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 625 complete! Validation Loss : 0.6413542410765571\n","Epoch 2, batch 625 complete! Validation Accuracy : 0.7156227501799856\n"]},{"name":"stderr","output_type":"stream","text":[" 44%|████▎     | 682/1563 [08:01<09:36,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 682/1563 of epoch 2 complete. Loss per last 992 samples:: 0.3070804724289525 \n","Training Accuracy per last 992 samples: 68.14516129032258\n"]},{"name":"stderr","output_type":"stream","text":[" 48%|████▊     | 744/1563 [08:41<08:56,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 744/1563 of epoch 2 complete. Loss per last 992 samples:: 0.30654166903226604 \n","Training Accuracy per last 992 samples: 67.84274193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 52%|█████▏    | 806/1563 [09:22<08:14,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 806/1563 of epoch 2 complete. Loss per last 992 samples:: 0.27791674110677933 \n","Training Accuracy per last 992 samples: 79.93951612903226\n"]},{"name":"stderr","output_type":"stream","text":[" 56%|█████▌    | 868/1563 [10:02<07:33,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 868/1563 of epoch 2 complete. Loss per last 992 samples:: 0.3193025646671172 \n","Training Accuracy per last 992 samples: 72.47983870967742\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|█████▉    | 930/1563 [10:42<06:52,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 930/1563 of epoch 2 complete. Loss per last 992 samples:: 0.31347707899347427 \n","Training Accuracy per last 992 samples: 70.36290322580645\n"]},{"name":"stderr","output_type":"stream","text":[" 63%|██████▎   | 992/1563 [11:23<06:13,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 992/1563 of epoch 2 complete. Loss per last 992 samples:: 0.2973907265451647 \n","Training Accuracy per last 992 samples: 74.19354838709677\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 1054/1563 [12:03<05:33,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1054/1563 of epoch 2 complete. Loss per last 992 samples:: 0.29454813993746237 \n","Training Accuracy per last 992 samples: 73.89112903225806\n"]},{"name":"stderr","output_type":"stream","text":[" 68%|██████▊   | 1066/1563 [12:11<05:24,  1.53it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 71%|███████▏  | 1116/1563 [12:43<04:51,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1116/1563 of epoch 2 complete. Loss per last 992 samples:: 0.30085905857624545 \n","Training Accuracy per last 992 samples: 70.56451612903226\n"]},{"name":"stderr","output_type":"stream","text":[" 75%|███████▌  | 1178/1563 [13:23<04:11,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1178/1563 of epoch 2 complete. Loss per last 992 samples:: 0.29725959656700013 \n","Training Accuracy per last 992 samples: 73.18548387096774\n"]},{"name":"stderr","output_type":"stream","text":[" 79%|███████▉  | 1240/1563 [14:04<03:30,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1240/1563 of epoch 2 complete. Loss per last 992 samples:: 0.30681635391327644 \n","Training Accuracy per last 992 samples: 71.27016129032258\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|███████▉  | 1245/1563 [14:07<03:26,  1.54it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 80%|███████▉  | 1249/1563 [14:09<03:23,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 1250 complete! Training Loss : 0.3053122138082981\n","Epoch 2, batch 1250 complete! Training Accuracy : 0.71465\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.54it/s]\n"," 80%|███████▉  | 1250/1563 [14:49<1:03:25, 12.16s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 1250 complete! Validation Loss : 0.6268104100706934\n","Epoch 2, batch 1250 complete! Validation Accuracy : 0.6879049676025918\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 1302/1563 [15:22<02:50,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1302/1563 of epoch 2 complete. Loss per last 992 samples:: 0.31091760651719186 \n","Training Accuracy per last 992 samples: 69.25403225806451\n"]},{"name":"stderr","output_type":"stream","text":[" 87%|████████▋ | 1364/1563 [16:03<02:10,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1364/1563 of epoch 2 complete. Loss per last 992 samples:: 0.30766922043215844 \n","Training Accuracy per last 992 samples: 69.35483870967742\n"]},{"name":"stderr","output_type":"stream","text":[" 91%|█████████ | 1426/1563 [16:43<01:29,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1426/1563 of epoch 2 complete. Loss per last 992 samples:: 0.30053049398045384 \n","Training Accuracy per last 992 samples: 73.99193548387096\n"]},{"name":"stderr","output_type":"stream","text":[" 95%|█████████▌| 1488/1563 [17:23<00:48,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1488/1563 of epoch 2 complete. Loss per last 992 samples:: 0.29188816177268184 \n","Training Accuracy per last 992 samples: 74.59677419354838\n"]},{"name":"stderr","output_type":"stream","text":[" 99%|█████████▊| 1541/1563 [17:58<00:14,  1.54it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 99%|█████████▉| 1550/1563 [18:03<00:08,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1550/1563 of epoch 2 complete. Loss per last 992 samples:: 0.2939292579408615 \n","Training Accuracy per last 992 samples: 71.9758064516129\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 1562/1563 [18:11<00:00,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 1563 complete! Training Loss : 0.3043910753522938\n","Epoch 2, batch 1563 complete! Training Accuracy : 0.7156003681030688\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.55it/s]\n","100%|██████████| 1563/1563 [18:50<00:00,  1.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 1563 complete! Validation Loss : 0.6332494233702791\n","Epoch 2, batch 1563 complete! Validation Accuracy : 0.7516198704103672\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 62/1563 [00:40<16:20,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 62/1563 of epoch 3 complete. Loss per last 992 samples:: 0.21859545056377688 \n","Training Accuracy per last 992 samples: 82.86290322580645\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 124/1563 [01:20<15:50,  1.51it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 124/1563 of epoch 3 complete. Loss per last 992 samples:: 0.21962456813743036 \n","Training Accuracy per last 992 samples: 82.05645161290323\n"]},{"name":"stderr","output_type":"stream","text":[" 12%|█▏        | 186/1563 [02:01<14:59,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 186/1563 of epoch 3 complete. Loss per last 992 samples:: 0.2387718803459598 \n","Training Accuracy per last 992 samples: 81.95564516129032\n"]},{"name":"stderr","output_type":"stream","text":[" 16%|█▌        | 248/1563 [02:42<14:32,  1.51it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 248/1563 of epoch 3 complete. Loss per last 992 samples:: 0.22016340590292408 \n","Training Accuracy per last 992 samples: 79.53629032258064\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|█▉        | 310/1563 [03:23<13:45,  1.52it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 310/1563 of epoch 3 complete. Loss per last 992 samples:: 0.2209350683035389 \n","Training Accuracy per last 992 samples: 80.84677419354838\n"]},{"name":"stderr","output_type":"stream","text":[" 24%|██▍       | 372/1563 [04:04<12:58,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 372/1563 of epoch 3 complete. Loss per last 992 samples:: 0.24870419273934058 \n","Training Accuracy per last 992 samples: 80.54435483870968\n"]},{"name":"stderr","output_type":"stream","text":[" 28%|██▊       | 434/1563 [04:45<12:16,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 434/1563 of epoch 3 complete. Loss per last 992 samples:: 0.22486680625907837 \n","Training Accuracy per last 992 samples: 80.84677419354838\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|███       | 473/1563 [05:10<11:43,  1.55it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 32%|███▏      | 496/1563 [05:25<11:38,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 496/1563 of epoch 3 complete. Loss per last 992 samples:: 0.23874983972599428 \n","Training Accuracy per last 992 samples: 78.125\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▌      | 558/1563 [06:05<10:55,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 558/1563 of epoch 3 complete. Loss per last 992 samples:: 0.22290626660950721 \n","Training Accuracy per last 992 samples: 83.16532258064517\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 620/1563 [06:46<10:16,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 620/1563 of epoch 3 complete. Loss per last 992 samples:: 0.21130937770489724 \n","Training Accuracy per last 992 samples: 81.75403225806451\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 624/1563 [06:48<10:32,  1.48it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 625 complete! Training Loss : 0.22676508884429933\n","Epoch 3, batch 625 complete! Training Accuracy : 0.8113\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.53it/s]\n"," 40%|███▉      | 625/1563 [07:27<3:10:18, 12.17s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 625 complete! Validation Loss : 0.7520092050919588\n","Epoch 3, batch 625 complete! Validation Accuracy : 0.6929445644348452\n"]},{"name":"stderr","output_type":"stream","text":[" 44%|████▎     | 682/1563 [08:05<09:36,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 682/1563 of epoch 3 complete. Loss per last 992 samples:: 0.22953222451671476 \n","Training Accuracy per last 992 samples: 80.34274193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 44%|████▍     | 690/1563 [08:10<09:34,  1.52it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 48%|████▊     | 744/1563 [08:45<08:56,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 744/1563 of epoch 3 complete. Loss per last 992 samples:: 0.2256353752266976 \n","Training Accuracy per last 992 samples: 81.5524193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 52%|█████▏    | 806/1563 [09:26<08:17,  1.52it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 806/1563 of epoch 3 complete. Loss per last 992 samples:: 0.21688382159317693 \n","Training Accuracy per last 992 samples: 80.34274193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 56%|█████▌    | 868/1563 [10:06<07:35,  1.52it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 868/1563 of epoch 3 complete. Loss per last 992 samples:: 0.20261436688803858 \n","Training Accuracy per last 992 samples: 85.48387096774194\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|█████▉    | 930/1563 [10:46<06:54,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 930/1563 of epoch 3 complete. Loss per last 992 samples:: 0.244334788812745 \n","Training Accuracy per last 992 samples: 80.34274193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 63%|██████▎   | 992/1563 [11:27<06:13,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 992/1563 of epoch 3 complete. Loss per last 992 samples:: 0.22015323910501697 \n","Training Accuracy per last 992 samples: 82.96370967741936\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 1054/1563 [12:07<05:32,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1054/1563 of epoch 3 complete. Loss per last 992 samples:: 0.2089757409787947 \n","Training Accuracy per last 992 samples: 81.95564516129032\n"]},{"name":"stderr","output_type":"stream","text":[" 71%|███████▏  | 1116/1563 [12:47<04:52,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1116/1563 of epoch 3 complete. Loss per last 992 samples:: 0.2258733650369029 \n","Training Accuracy per last 992 samples: 81.5524193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 75%|███████▌  | 1178/1563 [13:28<04:11,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1178/1563 of epoch 3 complete. Loss per last 992 samples:: 0.21284164806767816 \n","Training Accuracy per last 992 samples: 82.35887096774194\n"]},{"name":"stderr","output_type":"stream","text":[" 79%|███████▉  | 1240/1563 [14:08<03:31,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1240/1563 of epoch 3 complete. Loss per last 992 samples:: 0.2421649979247201 \n","Training Accuracy per last 992 samples: 78.93145161290323\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|███████▉  | 1249/1563 [14:14<03:24,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 1250 complete! Training Loss : 0.22486390168368817\n","Epoch 3, batch 1250 complete! Training Accuracy : 0.8134\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.54it/s]\n"," 80%|███████▉  | 1250/1563 [14:53<1:03:27, 12.16s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 1250 complete! Validation Loss : 0.7252467247261398\n","Epoch 3, batch 1250 complete! Validation Accuracy : 0.6709863210943124\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 1302/1563 [15:27<02:50,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1302/1563 of epoch 3 complete. Loss per last 992 samples:: 0.2177213991601621 \n","Training Accuracy per last 992 samples: 83.46774193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 87%|████████▋ | 1364/1563 [16:09<02:20,  1.41it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1364/1563 of epoch 3 complete. Loss per last 992 samples:: 0.21761759046104648 \n","Training Accuracy per last 992 samples: 83.06451612903226\n"]},{"name":"stderr","output_type":"stream","text":[" 91%|█████████ | 1426/1563 [16:51<01:39,  1.37it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1426/1563 of epoch 3 complete. Loss per last 992 samples:: 0.23132552146430937 \n","Training Accuracy per last 992 samples: 75.80645161290323\n"]},{"name":"stderr","output_type":"stream","text":[" 95%|█████████▌| 1488/1563 [17:32<00:48,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1488/1563 of epoch 3 complete. Loss per last 992 samples:: 0.22438979100796483 \n","Training Accuracy per last 992 samples: 81.45161290322581\n"]},{"name":"stderr","output_type":"stream","text":[" 97%|█████████▋| 1518/1563 [17:51<00:29,  1.53it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 99%|█████████▉| 1550/1563 [18:12<00:08,  1.48it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1550/1563 of epoch 3 complete. Loss per last 992 samples:: 0.23678389456002943 \n","Training Accuracy per last 992 samples: 78.72983870967742\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 1562/1563 [18:21<00:00,  1.51it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 1563 complete! Training Loss : 0.2246857916272495\n","Epoch 3, batch 1563 complete! Training Accuracy : 0.8124274796943144\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:40<00:00,  4.28it/s]\n","100%|██████████| 1563/1563 [19:01<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 1563 complete! Validation Loss : 0.8322242387067312\n","Epoch 3, batch 1563 complete! Validation Accuracy : 0.8135349172066235\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 62/1563 [00:44<17:13,  1.45it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 62/1563 of epoch 4 complete. Loss per last 992 samples:: 0.12087690842247778 \n","Training Accuracy per last 992 samples: 92.84274193548387\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 124/1563 [01:24<15:40,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 124/1563 of epoch 4 complete. Loss per last 992 samples:: 0.0985025949926386 \n","Training Accuracy per last 992 samples: 93.14516129032258\n"]},{"name":"stderr","output_type":"stream","text":[" 12%|█▏        | 186/1563 [02:05<15:00,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 186/1563 of epoch 4 complete. Loss per last 992 samples:: 0.08062862526745565 \n","Training Accuracy per last 992 samples: 94.25403225806451\n"]},{"name":"stderr","output_type":"stream","text":[" 16%|█▌        | 248/1563 [02:45<14:19,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 248/1563 of epoch 4 complete. Loss per last 992 samples:: 0.1129867609950804 \n","Training Accuracy per last 992 samples: 91.53225806451613\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|█▉        | 310/1563 [03:25<13:40,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 310/1563 of epoch 4 complete. Loss per last 992 samples:: 0.11570861112446554 \n","Training Accuracy per last 992 samples: 90.42338709677419\n"]},{"name":"stderr","output_type":"stream","text":[" 24%|██▍       | 372/1563 [04:06<12:58,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 372/1563 of epoch 4 complete. Loss per last 992 samples:: 0.11172118470553428 \n","Training Accuracy per last 992 samples: 93.34677419354838\n"]},{"name":"stderr","output_type":"stream","text":[" 25%|██▍       | 383/1563 [04:13<12:43,  1.55it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 28%|██▊       | 434/1563 [04:46<12:17,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 434/1563 of epoch 4 complete. Loss per last 992 samples:: 0.10507975877713292 \n","Training Accuracy per last 992 samples: 90.7258064516129\n"]},{"name":"stderr","output_type":"stream","text":[" 32%|███▏      | 496/1563 [05:26<11:37,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 496/1563 of epoch 4 complete. Loss per last 992 samples:: 0.12666222522215498 \n","Training Accuracy per last 992 samples: 91.63306451612904\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▌      | 558/1563 [06:07<10:57,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 558/1563 of epoch 4 complete. Loss per last 992 samples:: 0.14097515301358315 \n","Training Accuracy per last 992 samples: 87.70161290322581\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 620/1563 [06:47<10:16,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 620/1563 of epoch 4 complete. Loss per last 992 samples:: 0.1182311400771141 \n","Training Accuracy per last 992 samples: 90.82661290322581\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 624/1563 [06:49<10:14,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, batch 625 complete! Training Loss : 0.1131756725281477\n","Epoch 4, batch 625 complete! Training Accuracy : 0.916\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.54it/s]\n"," 40%|███▉      | 625/1563 [07:28<3:09:55, 12.15s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, batch 625 complete! Validation Loss : 1.0285587238426182\n","Epoch 4, batch 625 complete! Validation Accuracy : 0.7001439884809215\n"]},{"name":"stderr","output_type":"stream","text":[" 44%|████▎     | 682/1563 [08:06<09:35,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 682/1563 of epoch 4 complete. Loss per last 992 samples:: 0.11787660487536941 \n","Training Accuracy per last 992 samples: 90.625\n"]},{"name":"stderr","output_type":"stream","text":[" 48%|████▊     | 744/1563 [08:46<08:55,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 744/1563 of epoch 4 complete. Loss per last 992 samples:: 0.12241246647411777 \n","Training Accuracy per last 992 samples: 90.9274193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 52%|█████▏    | 806/1563 [09:26<08:15,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 806/1563 of epoch 4 complete. Loss per last 992 samples:: 0.10950726547068165 \n","Training Accuracy per last 992 samples: 90.3225806451613\n"]},{"name":"stderr","output_type":"stream","text":[" 56%|█████▌    | 868/1563 [10:06<07:33,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 868/1563 of epoch 4 complete. Loss per last 992 samples:: 0.09495545005906493 \n","Training Accuracy per last 992 samples: 92.03629032258064\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|█████▉    | 930/1563 [10:47<07:09,  1.47it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 930/1563 of epoch 4 complete. Loss per last 992 samples:: 0.12258296791884687 \n","Training Accuracy per last 992 samples: 91.22983870967742\n"]},{"name":"stderr","output_type":"stream","text":[" 62%|██████▏   | 972/1563 [11:14<06:26,  1.53it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 63%|██████▎   | 992/1563 [11:27<06:14,  1.52it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 992/1563 of epoch 4 complete. Loss per last 992 samples:: 0.11258912636267562 \n","Training Accuracy per last 992 samples: 91.33064516129032\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 1054/1563 [12:07<05:32,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1054/1563 of epoch 4 complete. Loss per last 992 samples:: 0.11523418440934151 \n","Training Accuracy per last 992 samples: 90.3225806451613\n"]},{"name":"stderr","output_type":"stream","text":[" 71%|███████▏  | 1116/1563 [12:48<04:51,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1116/1563 of epoch 4 complete. Loss per last 992 samples:: 0.11898676759653515 \n","Training Accuracy per last 992 samples: 90.9274193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 75%|███████▌  | 1178/1563 [13:28<04:11,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1178/1563 of epoch 4 complete. Loss per last 992 samples:: 0.1289660495315348 \n","Training Accuracy per last 992 samples: 90.625\n"]},{"name":"stderr","output_type":"stream","text":[" 79%|███████▉  | 1240/1563 [14:08<03:30,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1240/1563 of epoch 4 complete. Loss per last 992 samples:: 0.10035873763263226 \n","Training Accuracy per last 992 samples: 92.74193548387096\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|███████▉  | 1249/1563 [14:14<03:23,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, batch 1250 complete! Training Loss : 0.11377283048853278\n","Epoch 4, batch 1250 complete! Training Accuracy : 0.91335\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.53it/s]\n"," 80%|███████▉  | 1250/1563 [14:53<1:03:33, 12.18s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, batch 1250 complete! Validation Loss : 1.071707882500928\n","Epoch 4, batch 1250 complete! Validation Accuracy : 0.6627069834413247\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 1302/1563 [15:27<02:50,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1302/1563 of epoch 4 complete. Loss per last 992 samples:: 0.11445290921255946 \n","Training Accuracy per last 992 samples: 89.81854838709677\n"]},{"name":"stderr","output_type":"stream","text":[" 87%|████████▋ | 1364/1563 [16:07<02:10,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1364/1563 of epoch 4 complete. Loss per last 992 samples:: 0.11789439624596026 \n","Training Accuracy per last 992 samples: 90.625\n"]},{"name":"stderr","output_type":"stream","text":[" 89%|████████▉ | 1394/1563 [16:27<01:50,  1.53it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 91%|█████████ | 1426/1563 [16:47<01:29,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1426/1563 of epoch 4 complete. Loss per last 992 samples:: 0.11101661066734983 \n","Training Accuracy per last 992 samples: 91.43145161290323\n"]},{"name":"stderr","output_type":"stream","text":[" 95%|█████████▌| 1488/1563 [17:28<00:49,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1488/1563 of epoch 4 complete. Loss per last 992 samples:: 0.12617453791561625 \n","Training Accuracy per last 992 samples: 89.41532258064517\n"]},{"name":"stderr","output_type":"stream","text":[" 99%|█████████▉| 1550/1563 [18:08<00:08,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1550/1563 of epoch 4 complete. Loss per last 992 samples:: 0.09861699225861699 \n","Training Accuracy per last 992 samples: 92.64112903225806\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 1562/1563 [18:16<00:00,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, batch 1563 complete! Training Loss : 0.11442077298060546\n","Epoch 4, batch 1563 complete! Training Accuracy : 0.9121754091145521\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.53it/s]\n","100%|██████████| 1563/1563 [18:54<00:00,  1.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, batch 1563 complete! Validation Loss : 0.9990652361135374\n","Epoch 4, batch 1563 complete! Validation Accuracy : 0.6882649388048956\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 62/1563 [00:40<16:26,  1.52it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 62/1563 of epoch 5 complete. Loss per last 992 samples:: 0.0659153702999315 \n","Training Accuracy per last 992 samples: 95.66532258064517\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 124/1563 [01:22<15:41,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 124/1563 of epoch 5 complete. Loss per last 992 samples:: 0.049750145825166854 \n","Training Accuracy per last 992 samples: 96.5725806451613\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|▉         | 154/1563 [01:42<15:16,  1.54it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 12%|█▏        | 181/1563 [02:00<15:22,  1.50it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_10691/367460629.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_bert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopti\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miters_to_accumulate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_10691/381011392.py\u001b[0m in \u001b[0;36mtrain_bert\u001b[0;34m(net, criterion, opti, lr, lr_scheduler, train_loader, val_loader, epochs, iters_to_accumulate)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;31m# Computing accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0;31m#print(pooled.squeeze(-1), labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mcurr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0mbig_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mn_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalcuate_accu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbig_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["train_bert(net, criterion, opti, LEARNING_RATE, lr_scheduler, train_loader, val_loader, EPOCHS, iters_to_accumulate)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  4%|▍         | 62/1563 [00:43<17:16,  1.45it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 62/1563 of epoch 1 complete. Loss per last 992 samples:: 0.9063789613785282 \n","Training Accuracy per last 992 samples: 16.532258064516128\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 124/1563 [01:26<16:50,  1.42it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 124/1563 of epoch 1 complete. Loss per last 992 samples:: 0.9024461315524194 \n","Training Accuracy per last 992 samples: 16.22983870967742\n"]},{"name":"stderr","output_type":"stream","text":[" 12%|█▏        | 186/1563 [02:09<16:12,  1.42it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 186/1563 of epoch 1 complete. Loss per last 992 samples:: 0.8988721293787802 \n","Training Accuracy per last 992 samples: 18.548387096774192\n"]},{"name":"stderr","output_type":"stream","text":[" 16%|█▌        | 248/1563 [02:52<15:18,  1.43it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 248/1563 of epoch 1 complete. Loss per last 992 samples:: 0.9003468175088206 \n","Training Accuracy per last 992 samples: 17.036290322580644\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|█▉        | 310/1563 [03:36<14:40,  1.42it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 310/1563 of epoch 1 complete. Loss per last 992 samples:: 0.9004127748550907 \n","Training Accuracy per last 992 samples: 18.245967741935484\n"]},{"name":"stderr","output_type":"stream","text":[" 24%|██▍       | 372/1563 [04:19<13:52,  1.43it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 372/1563 of epoch 1 complete. Loss per last 992 samples:: 0.8979351905084425 \n","Training Accuracy per last 992 samples: 17.338709677419356\n"]},{"name":"stderr","output_type":"stream","text":[" 28%|██▊       | 434/1563 [05:02<13:05,  1.44it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 434/1563 of epoch 1 complete. Loss per last 992 samples:: 0.8905821769468246 \n","Training Accuracy per last 992 samples: 18.548387096774192\n"]},{"name":"stderr","output_type":"stream","text":[" 32%|███▏      | 496/1563 [05:46<12:27,  1.43it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 496/1563 of epoch 1 complete. Loss per last 992 samples:: 0.8960805093088458 \n","Training Accuracy per last 992 samples: 18.75\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▌      | 558/1563 [06:29<11:53,  1.41it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 558/1563 of epoch 1 complete. Loss per last 992 samples:: 0.8905829152753276 \n","Training Accuracy per last 992 samples: 19.657258064516128\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 620/1563 [07:12<11:05,  1.42it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 620/1563 of epoch 1 complete. Loss per last 992 samples:: 0.8806201565650201 \n","Training Accuracy per last 992 samples: 22.177419354838708\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 624/1563 [07:15<11:02,  1.42it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 625 complete! Training Loss : 0.8964169921875\n","Epoch 1, batch 625 complete! Training Accuracy : 0.1833\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:43<00:00,  4.04it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 625 complete! Validation Loss : 1.7506398168103448\n","Epoch 1, batch 625 complete! Validation Accuracy : 0.22102231821454282\n","Validation loss changed from inf to 1.7506398168103448\n","Best validation accuracy improved from 0 to 0.22102231821454282\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 625/1563 [08:00<3:36:24, 13.84s/it]"]},{"name":"stdout","output_type":"stream","text":["The model has been saved in models/Mon Nov 15 19:03:44 2021_lr_2e-05_val_acc_0.221_ep_1.pt\n"]},{"name":"stderr","output_type":"stream","text":[" 44%|████▎     | 682/1563 [08:40<10:21,  1.42it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 682/1563 of epoch 1 complete. Loss per last 992 samples:: 0.8863467554892263 \n","Training Accuracy per last 992 samples: 20.66532258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 48%|████▊     | 744/1563 [09:23<09:36,  1.42it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 744/1563 of epoch 1 complete. Loss per last 992 samples:: 0.8785960289739794 \n","Training Accuracy per last 992 samples: 20.967741935483872\n"]},{"name":"stderr","output_type":"stream","text":[" 52%|█████▏    | 806/1563 [10:07<08:52,  1.42it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 806/1563 of epoch 1 complete. Loss per last 992 samples:: 0.8815695239651588 \n","Training Accuracy per last 992 samples: 20.967741935483872\n"]},{"name":"stderr","output_type":"stream","text":[" 56%|█████▌    | 868/1563 [10:50<08:11,  1.41it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 868/1563 of epoch 1 complete. Loss per last 992 samples:: 0.8786707232075353 \n","Training Accuracy per last 992 samples: 20.362903225806452\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|█████▉    | 930/1563 [11:34<07:20,  1.44it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 930/1563 of epoch 1 complete. Loss per last 992 samples:: 0.8718840691351122 \n","Training Accuracy per last 992 samples: 22.782258064516128\n"]},{"name":"stderr","output_type":"stream","text":[" 63%|██████▎   | 992/1563 [12:16<06:02,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 992/1563 of epoch 1 complete. Loss per last 992 samples:: 0.8741816859091481 \n","Training Accuracy per last 992 samples: 22.983870967741936\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 1054/1563 [12:56<05:31,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1054/1563 of epoch 1 complete. Loss per last 992 samples:: 0.872023674749559 \n","Training Accuracy per last 992 samples: 22.379032258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 71%|███████▏  | 1116/1563 [13:36<04:43,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1116/1563 of epoch 1 complete. Loss per last 992 samples:: 0.8742319537747291 \n","Training Accuracy per last 992 samples: 23.79032258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 75%|███████▌  | 1178/1563 [14:15<04:04,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1178/1563 of epoch 1 complete. Loss per last 992 samples:: 0.8621829555880639 \n","Training Accuracy per last 992 samples: 22.883064516129032\n"]},{"name":"stderr","output_type":"stream","text":[" 79%|███████▉  | 1240/1563 [14:54<03:25,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1240/1563 of epoch 1 complete. Loss per last 992 samples:: 0.8712876842867944 \n","Training Accuracy per last 992 samples: 21.673387096774192\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|███████▉  | 1249/1563 [15:00<03:18,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 1250 complete! Training Loss : 0.8855590744018554\n","Epoch 1, batch 1250 complete! Training Accuracy : 0.2014\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 1250 complete! Validation Loss : 1.7161514457614941\n","Epoch 1, batch 1250 complete! Validation Accuracy : 0.24190064794816415\n","Validation loss changed from 1.7506398168103448 to 1.7161514457614941\n","Best validation accuracy improved from 0.22102231821454282 to 0.24190064794816415\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|███████▉  | 1250/1563 [15:40<1:05:17, 12.52s/it]"]},{"name":"stdout","output_type":"stream","text":["The model has been saved in models/Mon Nov 15 19:11:24 2021_lr_2e-05_val_acc_0.2419_ep_1.pt\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 1302/1563 [16:13<02:45,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1302/1563 of epoch 1 complete. Loss per last 992 samples:: 0.8677595507714057 \n","Training Accuracy per last 992 samples: 24.193548387096776\n"]},{"name":"stderr","output_type":"stream","text":[" 87%|████████▋ | 1364/1563 [16:53<02:06,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1364/1563 of epoch 1 complete. Loss per last 992 samples:: 0.8621951995357391 \n","Training Accuracy per last 992 samples: 22.883064516129032\n"]},{"name":"stderr","output_type":"stream","text":[" 91%|█████████ | 1426/1563 [17:32<01:27,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1426/1563 of epoch 1 complete. Loss per last 992 samples:: 0.878485002825337 \n","Training Accuracy per last 992 samples: 20.66532258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 95%|█████████▌| 1488/1563 [18:11<00:47,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1488/1563 of epoch 1 complete. Loss per last 992 samples:: 0.8732636359430128 \n","Training Accuracy per last 992 samples: 21.471774193548388\n"]},{"name":"stderr","output_type":"stream","text":[" 99%|█████████▉| 1550/1563 [18:51<00:08,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1550/1563 of epoch 1 complete. Loss per last 992 samples:: 0.858755265512774 \n","Training Accuracy per last 992 samples: 22.983870967741936\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 1562/1563 [18:58<00:00,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 1563 complete! Training Loss : 0.8819731628749894\n","Epoch 1, batch 1563 complete! Training Accuracy : 0.20597767374864961\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.47it/s]\n","100%|██████████| 1563/1563 [19:37<00:00,  1.33it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 1563 complete! Validation Loss : 1.714074847341954\n","Epoch 1, batch 1563 complete! Validation Accuracy : 0.21850251979841612\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 62/1563 [00:39<15:56,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 62/1563 of epoch 2 complete. Loss per last 992 samples:: 0.8550328900737147 \n","Training Accuracy per last 992 samples: 23.991935483870968\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 124/1563 [01:18<15:16,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 124/1563 of epoch 2 complete. Loss per last 992 samples:: 0.8653485082810924 \n","Training Accuracy per last 992 samples: 21.673387096774192\n"]},{"name":"stderr","output_type":"stream","text":[" 12%|█▏        | 186/1563 [01:58<14:34,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 186/1563 of epoch 2 complete. Loss per last 992 samples:: 0.8615736807546308 \n","Training Accuracy per last 992 samples: 23.487903225806452\n"]},{"name":"stderr","output_type":"stream","text":[" 16%|█▌        | 248/1563 [02:37<13:55,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 248/1563 of epoch 2 complete. Loss per last 992 samples:: 0.8540434068249118 \n","Training Accuracy per last 992 samples: 22.883064516129032\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|█▉        | 310/1563 [03:16<13:18,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 310/1563 of epoch 2 complete. Loss per last 992 samples:: 0.8495201295421969 \n","Training Accuracy per last 992 samples: 22.983870967741936\n"]},{"name":"stderr","output_type":"stream","text":[" 24%|██▍       | 372/1563 [03:55<12:37,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 372/1563 of epoch 2 complete. Loss per last 992 samples:: 0.8648858224191973 \n","Training Accuracy per last 992 samples: 22.278225806451612\n"]},{"name":"stderr","output_type":"stream","text":[" 28%|██▊       | 434/1563 [04:35<11:57,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 434/1563 of epoch 2 complete. Loss per last 992 samples:: 0.8648152505197833 \n","Training Accuracy per last 992 samples: 21.975806451612904\n"]},{"name":"stderr","output_type":"stream","text":[" 32%|███▏      | 496/1563 [05:14<11:19,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 496/1563 of epoch 2 complete. Loss per last 992 samples:: 0.8615291349349483 \n","Training Accuracy per last 992 samples: 23.18548387096774\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▌      | 558/1563 [05:53<10:38,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 558/1563 of epoch 2 complete. Loss per last 992 samples:: 0.867456159284038 \n","Training Accuracy per last 992 samples: 22.580645161290324\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 620/1563 [06:33<09:57,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 620/1563 of epoch 2 complete. Loss per last 992 samples:: 0.8592547139813823 \n","Training Accuracy per last 992 samples: 24.294354838709676\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 624/1563 [06:35<09:59,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 625 complete! Training Loss : 0.8604004272460938\n","Epoch 2, batch 625 complete! Training Accuracy : 0.2303\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.47it/s]\n"," 40%|███▉      | 625/1563 [07:15<3:12:24, 12.31s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 625 complete! Validation Loss : 1.7121722341954022\n","Epoch 2, batch 625 complete! Validation Accuracy : 0.2361411087113031\n"]},{"name":"stderr","output_type":"stream","text":[" 44%|████▎     | 682/1563 [07:51<09:21,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 682/1563 of epoch 2 complete. Loss per last 992 samples:: 0.8672429361651021 \n","Training Accuracy per last 992 samples: 21.774193548387096\n"]},{"name":"stderr","output_type":"stream","text":[" 48%|████▊     | 744/1563 [08:30<08:39,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 744/1563 of epoch 2 complete. Loss per last 992 samples:: 0.8509376587406281 \n","Training Accuracy per last 992 samples: 24.39516129032258\n"]},{"name":"stderr","output_type":"stream","text":[" 52%|█████▏    | 806/1563 [09:10<08:02,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 806/1563 of epoch 2 complete. Loss per last 992 samples:: 0.8601103751890121 \n","Training Accuracy per last 992 samples: 24.495967741935484\n"]},{"name":"stderr","output_type":"stream","text":[" 56%|█████▌    | 868/1563 [09:49<07:23,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 868/1563 of epoch 2 complete. Loss per last 992 samples:: 0.8597111548146894 \n","Training Accuracy per last 992 samples: 23.588709677419356\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|█████▉    | 930/1563 [10:28<06:43,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 930/1563 of epoch 2 complete. Loss per last 992 samples:: 0.8669420057727445 \n","Training Accuracy per last 992 samples: 25.0\n"]},{"name":"stderr","output_type":"stream","text":[" 63%|██████▎   | 992/1563 [11:08<06:03,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 992/1563 of epoch 2 complete. Loss per last 992 samples:: 0.8488818445513325 \n","Training Accuracy per last 992 samples: 24.495967741935484\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 1054/1563 [11:47<05:23,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1054/1563 of epoch 2 complete. Loss per last 992 samples:: 0.8521883256973759 \n","Training Accuracy per last 992 samples: 22.177419354838708\n"]},{"name":"stderr","output_type":"stream","text":[" 71%|███████▏  | 1116/1563 [12:26<04:44,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1116/1563 of epoch 2 complete. Loss per last 992 samples:: 0.8522543138073336 \n","Training Accuracy per last 992 samples: 24.899193548387096\n"]},{"name":"stderr","output_type":"stream","text":[" 75%|███████▌  | 1178/1563 [13:06<04:04,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1178/1563 of epoch 2 complete. Loss per last 992 samples:: 0.8560609817504883 \n","Training Accuracy per last 992 samples: 24.596774193548388\n"]},{"name":"stderr","output_type":"stream","text":[" 79%|███████▉  | 1240/1563 [13:45<03:24,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1240/1563 of epoch 2 complete. Loss per last 992 samples:: 0.8488673548544606 \n","Training Accuracy per last 992 samples: 27.016129032258064\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|███████▉  | 1249/1563 [13:51<03:18,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 1250 complete! Training Loss : 0.858346597290039\n","Epoch 2, batch 1250 complete! Training Accuracy : 0.23575\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.47it/s]\n"," 80%|███████▉  | 1250/1563 [14:30<1:04:12, 12.31s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 1250 complete! Validation Loss : 1.715612652658046\n","Epoch 2, batch 1250 complete! Validation Accuracy : 0.23794096472282217\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 1302/1563 [15:03<02:45,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1302/1563 of epoch 2 complete. Loss per last 992 samples:: 0.8557437466036889 \n","Training Accuracy per last 992 samples: 26.008064516129032\n"]},{"name":"stderr","output_type":"stream","text":[" 87%|████████▋ | 1364/1563 [15:43<02:06,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1364/1563 of epoch 2 complete. Loss per last 992 samples:: 0.8569437611487604 \n","Training Accuracy per last 992 samples: 25.705645161290324\n"]},{"name":"stderr","output_type":"stream","text":[" 91%|█████████ | 1426/1563 [16:22<01:27,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1426/1563 of epoch 2 complete. Loss per last 992 samples:: 0.8731109865250126 \n","Training Accuracy per last 992 samples: 21.370967741935484\n"]},{"name":"stderr","output_type":"stream","text":[" 95%|█████████▌| 1488/1563 [17:01<00:47,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1488/1563 of epoch 2 complete. Loss per last 992 samples:: 0.8538642698718656 \n","Training Accuracy per last 992 samples: 24.495967741935484\n"]},{"name":"stderr","output_type":"stream","text":[" 99%|█████████▉| 1550/1563 [17:41<00:08,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1550/1563 of epoch 2 complete. Loss per last 992 samples:: 0.8470746317217427 \n","Training Accuracy per last 992 samples: 25.403225806451612\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 1562/1563 [17:48<00:00,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 1563 complete! Training Loss : 0.8579743758120448\n","Epoch 2, batch 1563 complete! Training Accuracy : 0.2381466810706998\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 1563 complete! Validation Loss : 1.7146697647270115\n","Epoch 2, batch 1563 complete! Validation Accuracy : 0.24226061915046795\n","Validation loss changed from 1.7161514457614941 to 1.7146697647270115\n","Best validation accuracy improved from 0.24190064794816415 to 0.24226061915046795\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1563/1563 [18:28<00:00,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["The model has been saved in models/Mon Nov 15 19:33:50 2021_lr_2e-05_val_acc_0.2423_ep_2.pt\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 62/1563 [00:39<15:54,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 62/1563 of epoch 3 complete. Loss per last 992 samples:: 0.8419271284534086 \n","Training Accuracy per last 992 samples: 26.20967741935484\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 124/1563 [01:18<15:14,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 124/1563 of epoch 3 complete. Loss per last 992 samples:: 0.8303802244124874 \n","Training Accuracy per last 992 samples: 29.637096774193548\n"]},{"name":"stderr","output_type":"stream","text":[" 12%|█▏        | 186/1563 [01:58<14:32,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 186/1563 of epoch 3 complete. Loss per last 992 samples:: 0.8334768356815461 \n","Training Accuracy per last 992 samples: 30.04032258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 16%|█▌        | 248/1563 [02:37<13:55,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 248/1563 of epoch 3 complete. Loss per last 992 samples:: 0.8246126174926758 \n","Training Accuracy per last 992 samples: 29.536290322580644\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|█▉        | 310/1563 [03:16<13:17,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 310/1563 of epoch 3 complete. Loss per last 992 samples:: 0.8423695102814706 \n","Training Accuracy per last 992 samples: 26.91532258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 24%|██▍       | 372/1563 [03:56<12:39,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 372/1563 of epoch 3 complete. Loss per last 992 samples:: 0.8395661538647067 \n","Training Accuracy per last 992 samples: 25.806451612903224\n"]},{"name":"stderr","output_type":"stream","text":[" 28%|██▊       | 434/1563 [04:35<11:57,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 434/1563 of epoch 3 complete. Loss per last 992 samples:: 0.8424195935649257 \n","Training Accuracy per last 992 samples: 27.52016129032258\n"]},{"name":"stderr","output_type":"stream","text":[" 32%|███▏      | 496/1563 [05:14<11:18,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 496/1563 of epoch 3 complete. Loss per last 992 samples:: 0.8367010854905651 \n","Training Accuracy per last 992 samples: 28.931451612903224\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▌      | 558/1563 [05:54<10:36,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 558/1563 of epoch 3 complete. Loss per last 992 samples:: 0.8484304797264838 \n","Training Accuracy per last 992 samples: 25.806451612903224\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 620/1563 [06:33<09:57,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 620/1563 of epoch 3 complete. Loss per last 992 samples:: 0.8335905997983871 \n","Training Accuracy per last 992 samples: 27.318548387096776\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 624/1563 [06:35<09:56,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 625 complete! Training Loss : 0.8369092636108398\n","Epoch 3, batch 625 complete! Training Accuracy : 0.2781\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.47it/s]\n"," 40%|███▉      | 625/1563 [07:15<3:12:34, 12.32s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 625 complete! Validation Loss : 1.7332693516522988\n","Epoch 3, batch 625 complete! Validation Accuracy : 0.24010079193664507\n"]},{"name":"stderr","output_type":"stream","text":[" 44%|████▎     | 682/1563 [07:51<09:25,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 682/1563 of epoch 3 complete. Loss per last 992 samples:: 0.8287101253386466 \n","Training Accuracy per last 992 samples: 28.931451612903224\n"]},{"name":"stderr","output_type":"stream","text":[" 48%|████▊     | 744/1563 [08:31<08:40,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 744/1563 of epoch 3 complete. Loss per last 992 samples:: 0.8130398104267735 \n","Training Accuracy per last 992 samples: 30.947580645161292\n"]},{"name":"stderr","output_type":"stream","text":[" 52%|█████▏    | 806/1563 [09:10<08:01,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 806/1563 of epoch 3 complete. Loss per last 992 samples:: 0.8363018804980863 \n","Training Accuracy per last 992 samples: 28.326612903225808\n"]},{"name":"stderr","output_type":"stream","text":[" 56%|█████▌    | 868/1563 [09:50<07:19,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 868/1563 of epoch 3 complete. Loss per last 992 samples:: 0.8446568212201518 \n","Training Accuracy per last 992 samples: 28.326612903225808\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|█████▉    | 930/1563 [10:29<06:40,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 930/1563 of epoch 3 complete. Loss per last 992 samples:: 0.8379067759360036 \n","Training Accuracy per last 992 samples: 29.536290322580644\n"]},{"name":"stderr","output_type":"stream","text":[" 63%|██████▎   | 992/1563 [11:08<06:01,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 992/1563 of epoch 3 complete. Loss per last 992 samples:: 0.8318639878303774 \n","Training Accuracy per last 992 samples: 27.52016129032258\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 1054/1563 [11:47<05:29,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1054/1563 of epoch 3 complete. Loss per last 992 samples:: 0.833858851463564 \n","Training Accuracy per last 992 samples: 27.620967741935484\n"]},{"name":"stderr","output_type":"stream","text":[" 71%|███████▏  | 1116/1563 [12:26<04:41,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1116/1563 of epoch 3 complete. Loss per last 992 samples:: 0.8544466264786259 \n","Training Accuracy per last 992 samples: 24.697580645161292\n"]},{"name":"stderr","output_type":"stream","text":[" 75%|███████▌  | 1178/1563 [13:05<04:02,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1178/1563 of epoch 3 complete. Loss per last 992 samples:: 0.8278299300901352 \n","Training Accuracy per last 992 samples: 32.25806451612903\n"]},{"name":"stderr","output_type":"stream","text":[" 79%|███████▉  | 1240/1563 [13:44<03:22,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1240/1563 of epoch 3 complete. Loss per last 992 samples:: 0.8334229838463568 \n","Training Accuracy per last 992 samples: 27.419354838709676\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|███████▉  | 1249/1563 [13:50<03:16,  1.60it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 1250 complete! Training Loss : 0.8358729274749755\n","Epoch 3, batch 1250 complete! Training Accuracy : 0.2815\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 1250 complete! Validation Loss : 1.7182897808908046\n","Epoch 3, batch 1250 complete! Validation Accuracy : 0.2433405327573794\n","Validation loss changed from 1.7146697647270115 to 1.7182897808908046\n","Best validation accuracy improved from 0.24226061915046795 to 0.2433405327573794\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|███████▉  | 1250/1563 [14:30<1:04:29, 12.36s/it]"]},{"name":"stdout","output_type":"stream","text":["The model has been saved in models/Mon Nov 15 19:48:20 2021_lr_2e-05_val_acc_0.2433_ep_3.pt\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 1302/1563 [15:02<02:43,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1302/1563 of epoch 3 complete. Loss per last 992 samples:: 0.8426888065953408 \n","Training Accuracy per last 992 samples: 29.032258064516128\n"]},{"name":"stderr","output_type":"stream","text":[" 87%|████████▋ | 1364/1563 [15:41<02:04,  1.60it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1364/1563 of epoch 3 complete. Loss per last 992 samples:: 0.8278938416511782 \n","Training Accuracy per last 992 samples: 31.350806451612904\n"]},{"name":"stderr","output_type":"stream","text":[" 91%|█████████ | 1426/1563 [16:20<01:26,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1426/1563 of epoch 3 complete. Loss per last 992 samples:: 0.8333123883893413 \n","Training Accuracy per last 992 samples: 29.133064516129032\n"]},{"name":"stderr","output_type":"stream","text":[" 95%|█████████▌| 1488/1563 [16:59<00:46,  1.60it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1488/1563 of epoch 3 complete. Loss per last 992 samples:: 0.8512762592684838 \n","Training Accuracy per last 992 samples: 27.016129032258064\n"]},{"name":"stderr","output_type":"stream","text":[" 99%|█████████▉| 1550/1563 [17:38<00:08,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1550/1563 of epoch 3 complete. Loss per last 992 samples:: 0.8367457236013105 \n","Training Accuracy per last 992 samples: 29.33467741935484\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 1562/1563 [17:45<00:00,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 1563 complete! Training Loss : 0.835953224643407\n","Epoch 3, batch 1563 complete! Training Accuracy : 0.2835193854279198\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.54it/s]\n","100%|██████████| 1563/1563 [18:24<00:00,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 1563 complete! Validation Loss : 1.7124416307471264\n","Epoch 3, batch 1563 complete! Validation Accuracy : 0.234341252699784\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 62/1563 [00:38<15:42,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 62/1563 of epoch 4 complete. Loss per last 992 samples:: 0.7787654938236359 \n","Training Accuracy per last 992 samples: 36.49193548387097\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 65/1563 [00:41<15:57,  1.56it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_50009/367460629.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_bert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopti\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miters_to_accumulate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_50009/819859485.py\u001b[0m in \u001b[0;36mtrain_bert\u001b[0;34m(net, criterion, opti, lr, lr_scheduler, train_loader, val_loader, epochs, iters_to_accumulate)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# Backpropagating the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m# Scales loss.  Calls backward() on scaled loss to create scaled gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0miters_to_accumulate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/nn/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/nn/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["train_bert(net, criterion, opti, LEARNING_RATE, lr_scheduler, train_loader, val_loader, EPOCHS, iters_to_accumulate)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["net.load_state_dict(torch.load('models/Mon Nov 15 03:12:52 2021_lr_2e-06_val_acc_0.3009_ep_4.pt'))"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  2%|▏         | 62/3125 [00:43<36:01,  1.42it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 62/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8254139807916456 \n","Training Accuracy per last 992 samples: 31.955645161290324\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 124/3125 [01:26<34:53,  1.43it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 124/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8244647979736328 \n","Training Accuracy per last 992 samples: 32.76209677419355\n"]},{"name":"stderr","output_type":"stream","text":["  5%|▌         | 164/3125 [01:54<35:20,  1.40it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  6%|▌         | 186/3125 [02:10<32:15,  1.52it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 186/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8205052652666646 \n","Training Accuracy per last 992 samples: 32.15725806451613\n"]},{"name":"stderr","output_type":"stream","text":["  7%|▋         | 204/3125 [02:21<31:26,  1.55it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  8%|▊         | 248/3125 [02:49<30:26,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 248/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8200784498645414 \n","Training Accuracy per last 992 samples: 31.149193548387096\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 257/3125 [02:55<30:13,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  8%|▊         | 258/3125 [02:55<30:23,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  9%|▉         | 294/3125 [03:19<33:23,  1.41it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 10%|▉         | 310/3125 [03:30<30:18,  1.55it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 310/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8192224194926601 \n","Training Accuracy per last 992 samples: 31.25\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|▉         | 312/3125 [03:31<30:09,  1.55it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 11%|█         | 330/3125 [03:42<29:19,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 12%|█▏        | 372/3125 [04:09<29:06,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 372/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8276081085205078 \n","Training Accuracy per last 992 samples: 32.358870967741936\n"]},{"name":"stderr","output_type":"stream","text":[" 14%|█▍        | 434/3125 [04:48<28:23,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 434/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8155086271224483 \n","Training Accuracy per last 992 samples: 33.16532258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 16%|█▌        | 496/3125 [05:27<27:45,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 496/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8133992533529958 \n","Training Accuracy per last 992 samples: 32.66129032258065\n"]},{"name":"stderr","output_type":"stream","text":[" 18%|█▊        | 558/3125 [06:06<27:05,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 558/3125 of epoch 1 complete. Loss per last 992 samples:: 0.814576671969506 \n","Training Accuracy per last 992 samples: 33.064516129032256\n"]},{"name":"stderr","output_type":"stream","text":[" 18%|█▊        | 566/3125 [06:11<26:59,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 20%|█▉        | 620/3125 [06:46<26:44,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 620/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8135323063019784 \n","Training Accuracy per last 992 samples: 33.66935483870968\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|█▉        | 624/3125 [06:48<26:26,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 625 complete! Training Loss : 0.8191709259033203\n","Epoch 1, batch 625 complete! Training Accuracy : 0.3241\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:40<00:00,  4.33it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 625 complete! Validation Loss : 1.6544427981321839\n","Epoch 1, batch 625 complete! Validation Accuracy : 0.30345572354211664\n","Validation loss changed from inf to 1.6544427981321839\n","Best validation accuracy improved from 0 to 0.30345572354211664\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 625/3125 [07:30<8:58:01, 12.91s/it]"]},{"name":"stdout","output_type":"stream","text":["The model has been saved in models/Mon Nov 15 13:19:01 2021_lr_2e-06_val_acc_0.3035_ep_1.pt\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 629/3125 [07:32<2:29:27,  3.59s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 22%|██▏       | 682/3125 [08:06<25:47,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 682/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8110598902548513 \n","Training Accuracy per last 992 samples: 34.17338709677419\n"]},{"name":"stderr","output_type":"stream","text":[" 24%|██▍       | 744/3125 [08:46<25:13,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 744/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8236367010301159 \n","Training Accuracy per last 992 samples: 31.149193548387096\n"]},{"name":"stderr","output_type":"stream","text":[" 26%|██▌       | 806/3125 [09:25<24:35,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 806/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8138478186822706 \n","Training Accuracy per last 992 samples: 31.552419354838708\n"]},{"name":"stderr","output_type":"stream","text":[" 27%|██▋       | 842/3125 [09:48<24:06,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 28%|██▊       | 868/3125 [10:04<23:52,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 868/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8151170669063446 \n","Training Accuracy per last 992 samples: 33.46774193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|██▉       | 930/3125 [10:43<23:08,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 930/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8171267355642011 \n","Training Accuracy per last 992 samples: 32.76209677419355\n"]},{"name":"stderr","output_type":"stream","text":[" 32%|███▏      | 985/3125 [11:19<22:43,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 32%|███▏      | 992/3125 [11:23<22:34,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 992/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8134358313775831 \n","Training Accuracy per last 992 samples: 33.36693548387097\n"]},{"name":"stderr","output_type":"stream","text":[" 33%|███▎      | 1023/3125 [11:43<22:04,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 34%|███▎      | 1050/3125 [12:01<21:54,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 34%|███▎      | 1054/3125 [12:03<21:56,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1054/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8227502146074849 \n","Training Accuracy per last 992 samples: 31.552419354838708\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▌      | 1116/3125 [12:42<21:09,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1116/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8098119920299899 \n","Training Accuracy per last 992 samples: 33.16532258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 38%|███▊      | 1178/3125 [13:22<20:36,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1178/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8120165794126449 \n","Training Accuracy per last 992 samples: 34.475806451612904\n"]},{"name":"stderr","output_type":"stream","text":[" 38%|███▊      | 1197/3125 [13:34<20:13,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 40%|███▉      | 1240/3125 [14:01<20:00,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1240/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8111045591292843 \n","Training Accuracy per last 992 samples: 34.274193548387096\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 1249/3125 [14:07<19:43,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 1250 complete! Training Loss : 0.817169612121582\n","Epoch 1, batch 1250 complete! Training Accuracy : 0.3272\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:39<00:00,  4.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 1250 complete! Validation Loss : 1.652966729525862\n","Epoch 1, batch 1250 complete! Validation Accuracy : 0.30669546436285094\n","Validation loss changed from 1.6544427981321839 to 1.652966729525862\n","Best validation accuracy improved from 0.30345572354211664 to 0.30669546436285094\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 1250/3125 [14:48<6:40:20, 12.81s/it]"]},{"name":"stdout","output_type":"stream","text":["The model has been saved in models/Mon Nov 15 13:26:19 2021_lr_2e-06_val_acc_0.3067_ep_1.pt\n"]},{"name":"stderr","output_type":"stream","text":[" 42%|████▏     | 1302/3125 [15:21<20:53,  1.45it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1302/3125 of epoch 1 complete. Loss per last 992 samples:: 0.809707764656313 \n","Training Accuracy per last 992 samples: 35.181451612903224\n"]},{"name":"stderr","output_type":"stream","text":[" 44%|████▎     | 1364/3125 [16:02<18:36,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1364/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8123254468364101 \n","Training Accuracy per last 992 samples: 32.96370967741935\n"]},{"name":"stderr","output_type":"stream","text":[" 44%|████▍     | 1368/3125 [16:05<18:36,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 46%|████▌     | 1426/3125 [16:42<18:01,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1426/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8150582467356036 \n","Training Accuracy per last 992 samples: 31.955645161290324\n"]},{"name":"stderr","output_type":"stream","text":[" 48%|████▊     | 1488/3125 [17:21<17:17,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1488/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8003310541952809 \n","Training Accuracy per last 992 samples: 34.07258064516129\n"]},{"name":"stderr","output_type":"stream","text":[" 48%|████▊     | 1513/3125 [17:37<16:57,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 49%|████▉     | 1544/3125 [17:56<16:40,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 50%|████▉     | 1550/3125 [18:00<16:42,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1550/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8087885456700479 \n","Training Accuracy per last 992 samples: 34.375\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 1569/3125 [18:13<18:47,  1.38it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 52%|█████▏    | 1612/3125 [18:43<17:37,  1.43it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1612/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8180684735698085 \n","Training Accuracy per last 992 samples: 31.25\n"]},{"name":"stderr","output_type":"stream","text":[" 54%|█████▎    | 1674/3125 [19:22<15:18,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1674/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8152954962945753 \n","Training Accuracy per last 992 samples: 31.552419354838708\n"]},{"name":"stderr","output_type":"stream","text":[" 56%|█████▌    | 1736/3125 [20:02<14:40,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1736/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8233074065177671 \n","Training Accuracy per last 992 samples: 33.971774193548384\n"]},{"name":"stderr","output_type":"stream","text":[" 57%|█████▋    | 1786/3125 [20:33<14:07,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 58%|█████▊    | 1798/3125 [20:41<14:01,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1798/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8227461538007182 \n","Training Accuracy per last 992 samples: 33.46774193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 59%|█████▉    | 1856/3125 [21:18<13:25,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 60%|█████▉    | 1860/3125 [21:20<13:23,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1860/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8137440220002206 \n","Training Accuracy per last 992 samples: 34.274193548387096\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|█████▉    | 1874/3125 [21:29<13:15,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 1875 complete! Training Loss : 0.8161221160888672\n","Epoch 1, batch 1875 complete! Training Accuracy : 0.3293\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:39<00:00,  4.45it/s]\n"," 60%|██████    | 1875/3125 [22:09<4:17:44, 12.37s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 1875 complete! Validation Loss : 1.6520519037356323\n","Epoch 1, batch 1875 complete! Validation Accuracy : 0.30345572354211664\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 1888/3125 [22:17<15:27,  1.33it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 61%|██████    | 1902/3125 [22:26<12:56,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 62%|██████▏   | 1922/3125 [22:39<12:41,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1922/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8049691723239037 \n","Training Accuracy per last 992 samples: 34.274193548387096\n"]},{"name":"stderr","output_type":"stream","text":[" 63%|██████▎   | 1963/3125 [23:05<12:12,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 63%|██████▎   | 1984/3125 [23:18<12:03,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1984/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8006563494282384 \n","Training Accuracy per last 992 samples: 34.67741935483871\n"]},{"name":"stderr","output_type":"stream","text":[" 65%|██████▌   | 2046/3125 [23:57<11:30,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2046/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8187888976066343 \n","Training Accuracy per last 992 samples: 32.358870967741936\n"]},{"name":"stderr","output_type":"stream","text":[" 66%|██████▌   | 2055/3125 [24:03<11:14,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 67%|██████▋   | 2108/3125 [24:36<10:45,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2108/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8205988484044229 \n","Training Accuracy per last 992 samples: 30.947580645161292\n"]},{"name":"stderr","output_type":"stream","text":[" 69%|██████▉   | 2151/3125 [25:04<10:13,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 69%|██████▉   | 2170/3125 [25:16<10:04,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2170/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8055740479500063 \n","Training Accuracy per last 992 samples: 33.568548387096776\n"]},{"name":"stderr","output_type":"stream","text":[" 70%|███████   | 2193/3125 [25:30<09:48,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 71%|███████▏  | 2232/3125 [25:55<09:24,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2232/3125 of epoch 1 complete. Loss per last 992 samples:: 0.818529067500945 \n","Training Accuracy per last 992 samples: 31.754032258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 73%|███████▎  | 2290/3125 [26:32<08:49,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 73%|███████▎  | 2294/3125 [26:34<08:50,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2294/3125 of epoch 1 complete. Loss per last 992 samples:: 0.824874508765436 \n","Training Accuracy per last 992 samples: 30.04032258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 75%|███████▌  | 2348/3125 [27:08<08:12,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 75%|███████▌  | 2356/3125 [27:13<08:07,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2356/3125 of epoch 1 complete. Loss per last 992 samples:: 0.802215330062374 \n","Training Accuracy per last 992 samples: 35.28225806451613\n"]},{"name":"stderr","output_type":"stream","text":[" 76%|███████▌  | 2364/3125 [27:18<08:02,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 77%|███████▋  | 2418/3125 [27:53<07:28,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2418/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8139521691106981 \n","Training Accuracy per last 992 samples: 33.266129032258064\n"]},{"name":"stderr","output_type":"stream","text":[" 79%|███████▉  | 2480/3125 [28:32<06:49,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2480/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8127445713166268 \n","Training Accuracy per last 992 samples: 33.770161290322584\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|███████▉  | 2499/3125 [28:44<06:34,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 2500 complete! Training Loss : 0.8150390907287598\n","Epoch 1, batch 2500 complete! Training Accuracy : 0.329175\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 2500 complete! Validation Loss : 1.6438858207614941\n","Epoch 1, batch 2500 complete! Validation Accuracy : 0.3102951763858891\n","Validation loss changed from 1.652966729525862 to 1.6438858207614941\n","Best validation accuracy improved from 0.30669546436285094 to 0.3102951763858891\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 2500/3125 [29:24<2:10:41, 12.55s/it]"]},{"name":"stdout","output_type":"stream","text":["The model has been saved in models/Mon Nov 15 13:40:56 2021_lr_2e-06_val_acc_0.3103_ep_1.pt\n"]},{"name":"stderr","output_type":"stream","text":[" 81%|████████▏ | 2542/3125 [29:51<06:09,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2542/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8105902517995527 \n","Training Accuracy per last 992 samples: 32.76209677419355\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 2587/3125 [30:19<05:39,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 83%|████████▎ | 2604/3125 [30:30<05:30,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2604/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8047065734863281 \n","Training Accuracy per last 992 samples: 35.98790322580645\n"]},{"name":"stderr","output_type":"stream","text":[" 85%|████████▌ | 2666/3125 [31:09<04:51,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2666/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8204586582799112 \n","Training Accuracy per last 992 samples: 32.45967741935484\n"]},{"name":"stderr","output_type":"stream","text":[" 86%|████████▌ | 2687/3125 [31:23<04:36,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 87%|████████▋ | 2728/3125 [31:49<04:11,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2728/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8115294056553994 \n","Training Accuracy per last 992 samples: 33.064516129032256\n"]},{"name":"stderr","output_type":"stream","text":[" 87%|████████▋ | 2734/3125 [31:52<04:09,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 89%|████████▉ | 2790/3125 [32:28<03:32,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2790/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8079990879181893 \n","Training Accuracy per last 992 samples: 33.266129032258064\n"]},{"name":"stderr","output_type":"stream","text":[" 91%|█████████▏| 2852/3125 [33:07<02:53,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2852/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8084670036069809 \n","Training Accuracy per last 992 samples: 33.46774193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 93%|█████████▎| 2914/3125 [33:46<02:13,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2914/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8034784870762979 \n","Training Accuracy per last 992 samples: 33.971774193548384\n"]},{"name":"stderr","output_type":"stream","text":[" 95%|█████████▌| 2976/3125 [34:26<01:34,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2976/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8168342959496283 \n","Training Accuracy per last 992 samples: 32.66129032258065\n"]},{"name":"stderr","output_type":"stream","text":[" 96%|█████████▌| 3007/3125 [34:45<01:14,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 97%|█████████▋| 3038/3125 [35:05<00:55,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 3038/3125 of epoch 1 complete. Loss per last 992 samples:: 0.8020767088859312 \n","Training Accuracy per last 992 samples: 34.07258064516129\n"]},{"name":"stderr","output_type":"stream","text":[" 98%|█████████▊| 3073/3125 [35:27<00:32,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 99%|█████████▊| 3081/3125 [35:32<00:27,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 99%|█████████▉| 3100/3125 [35:44<00:15,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 3100/3125 of epoch 1 complete. Loss per last 992 samples:: 0.816224867297757 \n","Training Accuracy per last 992 samples: 33.87096774193548\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 3124/3125 [35:59<00:00,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 3125 complete! Training Loss : 0.8142411608886718\n","Epoch 1, batch 3125 complete! Training Accuracy : 0.3306125715200256\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:39<00:00,  4.45it/s]\n","100%|██████████| 3125/3125 [36:38<00:00,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 3125 complete! Validation Loss : 1.6421179058908046\n","Epoch 1, batch 3125 complete! Validation Accuracy : 0.3045356371490281\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 62/3125 [00:39<32:22,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 62/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7999661353326613 \n","Training Accuracy per last 992 samples: 35.58467741935484\n"]},{"name":"stderr","output_type":"stream","text":["  3%|▎         | 81/3125 [00:51<32:00,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  4%|▍         | 124/3125 [01:18<31:40,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 124/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7951858889672064 \n","Training Accuracy per last 992 samples: 35.08064516129032\n"]},{"name":"stderr","output_type":"stream","text":["  6%|▌         | 186/3125 [01:57<31:19,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 186/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7905854871196132 \n","Training Accuracy per last 992 samples: 35.78629032258065\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 248/3125 [02:37<30:31,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 248/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7968611563405683 \n","Training Accuracy per last 992 samples: 36.49193548387097\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|▉         | 310/3125 [03:16<29:45,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 310/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7851091815579322 \n","Training Accuracy per last 992 samples: 36.29032258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|█         | 317/3125 [03:21<29:35,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 12%|█▏        | 372/3125 [03:56<29:05,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 372/3125 of epoch 2 complete. Loss per last 992 samples:: 0.8039958707747921 \n","Training Accuracy per last 992 samples: 32.66129032258065\n"]},{"name":"stderr","output_type":"stream","text":[" 14%|█▍        | 434/3125 [04:35<28:24,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 434/3125 of epoch 2 complete. Loss per last 992 samples:: 0.8014826005504977 \n","Training Accuracy per last 992 samples: 35.58467741935484\n"]},{"name":"stderr","output_type":"stream","text":[" 15%|█▍        | 454/3125 [04:47<28:14,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 16%|█▌        | 496/3125 [05:15<29:22,  1.49it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 496/3125 of epoch 2 complete. Loss per last 992 samples:: 0.8181792228452621 \n","Training Accuracy per last 992 samples: 33.266129032258064\n"]},{"name":"stderr","output_type":"stream","text":[" 18%|█▊        | 558/3125 [05:55<27:02,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 558/3125 of epoch 2 complete. Loss per last 992 samples:: 0.8007399343675182 \n","Training Accuracy per last 992 samples: 34.07258064516129\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|█▉        | 620/3125 [06:34<26:30,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 620/3125 of epoch 2 complete. Loss per last 992 samples:: 0.8070545196533203 \n","Training Accuracy per last 992 samples: 32.66129032258065\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|█▉        | 624/3125 [06:37<26:35,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 625 complete! Training Loss : 0.7998273223876953\n","Epoch 2, batch 625 complete! Training Accuracy : 0.3474\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.46it/s]\n"," 20%|██        | 625/3125 [07:17<8:33:58, 12.34s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 625 complete! Validation Loss : 1.6401872306034482\n","Epoch 2, batch 625 complete! Validation Accuracy : 0.3070554355651548\n"]},{"name":"stderr","output_type":"stream","text":[" 22%|██▏       | 682/3125 [07:53<25:51,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 682/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7940030251779864 \n","Training Accuracy per last 992 samples: 35.28225806451613\n"]},{"name":"stderr","output_type":"stream","text":[" 22%|██▏       | 695/3125 [08:01<25:32,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 24%|██▍       | 744/3125 [08:32<25:10,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 744/3125 of epoch 2 complete. Loss per last 992 samples:: 0.8070516278666835 \n","Training Accuracy per last 992 samples: 35.58467741935484\n"]},{"name":"stderr","output_type":"stream","text":[" 26%|██▌       | 806/3125 [09:11<24:28,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 806/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7940333581739857 \n","Training Accuracy per last 992 samples: 34.87903225806452\n"]},{"name":"stderr","output_type":"stream","text":[" 28%|██▊       | 864/3125 [09:48<23:56,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 28%|██▊       | 868/3125 [09:50<24:25,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 868/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7991277633174774 \n","Training Accuracy per last 992 samples: 33.66935483870968\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|██▉       | 930/3125 [10:30<23:09,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 930/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7948383823517831 \n","Training Accuracy per last 992 samples: 33.66935483870968\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|███       | 943/3125 [10:38<22:58,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 32%|███▏      | 992/3125 [11:09<22:32,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 992/3125 of epoch 2 complete. Loss per last 992 samples:: 0.804549063405683 \n","Training Accuracy per last 992 samples: 36.08870967741935\n"]},{"name":"stderr","output_type":"stream","text":[" 33%|███▎      | 1043/3125 [11:41<21:52,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 34%|███▎      | 1054/3125 [11:48<21:54,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1054/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7856895077613092 \n","Training Accuracy per last 992 samples: 35.483870967741936\n"]},{"name":"stderr","output_type":"stream","text":[" 35%|███▌      | 1108/3125 [12:22<21:15,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 36%|███▌      | 1116/3125 [12:27<21:17,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1116/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7915101820422757 \n","Training Accuracy per last 992 samples: 35.58467741935484\n"]},{"name":"stderr","output_type":"stream","text":[" 38%|███▊      | 1178/3125 [13:07<20:33,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1178/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7846529560704385 \n","Training Accuracy per last 992 samples: 36.189516129032256\n"]},{"name":"stderr","output_type":"stream","text":[" 39%|███▉      | 1219/3125 [13:33<20:00,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 40%|███▉      | 1240/3125 [13:46<19:55,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1240/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7943699129166142 \n","Training Accuracy per last 992 samples: 34.475806451612904\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 1249/3125 [13:52<19:44,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 1250 complete! Training Loss : 0.797597819519043\n","Epoch 2, batch 1250 complete! Training Accuracy : 0.34895\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:39<00:00,  4.46it/s]\n"," 40%|████      | 1250/3125 [14:31<6:25:53, 12.35s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 1250 complete! Validation Loss : 1.6400300826149425\n","Epoch 2, batch 1250 complete! Validation Accuracy : 0.30813534917206625\n"]},{"name":"stderr","output_type":"stream","text":[" 41%|████      | 1278/3125 [14:49<19:33,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 42%|████▏     | 1302/3125 [15:04<19:12,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1302/3125 of epoch 2 complete. Loss per last 992 samples:: 0.8021357136387979 \n","Training Accuracy per last 992 samples: 34.07258064516129\n"]},{"name":"stderr","output_type":"stream","text":[" 44%|████▎     | 1364/3125 [15:43<18:34,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1364/3125 of epoch 2 complete. Loss per last 992 samples:: 0.79362303210843 \n","Training Accuracy per last 992 samples: 37.096774193548384\n"]},{"name":"stderr","output_type":"stream","text":[" 44%|████▍     | 1368/3125 [15:46<18:37,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 44%|████▍     | 1380/3125 [15:54<18:25,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 46%|████▌     | 1424/3125 [16:21<18:02,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 46%|████▌     | 1426/3125 [16:23<18:08,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1426/3125 of epoch 2 complete. Loss per last 992 samples:: 0.8036310749669229 \n","Training Accuracy per last 992 samples: 34.17338709677419\n"]},{"name":"stderr","output_type":"stream","text":[" 48%|████▊     | 1488/3125 [17:02<17:16,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1488/3125 of epoch 2 complete. Loss per last 992 samples:: 0.8001918177450856 \n","Training Accuracy per last 992 samples: 32.66129032258065\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|████▉     | 1550/3125 [17:41<16:38,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1550/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7948797287479523 \n","Training Accuracy per last 992 samples: 34.375\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|████▉     | 1557/3125 [17:46<16:28,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 51%|█████     | 1591/3125 [18:07<16:04,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 52%|█████▏    | 1612/3125 [18:20<15:58,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1612/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7770339596656061 \n","Training Accuracy per last 992 samples: 38.50806451612903\n"]},{"name":"stderr","output_type":"stream","text":[" 54%|█████▎    | 1674/3125 [18:59<15:16,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1674/3125 of epoch 2 complete. Loss per last 992 samples:: 0.795456301781439 \n","Training Accuracy per last 992 samples: 36.29032258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 55%|█████▌    | 1726/3125 [19:32<14:47,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 56%|█████▌    | 1736/3125 [19:39<14:38,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1736/3125 of epoch 2 complete. Loss per last 992 samples:: 0.8058359699864541 \n","Training Accuracy per last 992 samples: 33.46774193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 57%|█████▋    | 1777/3125 [20:05<14:08,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 58%|█████▊    | 1798/3125 [20:18<13:56,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1798/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7939530034219066 \n","Training Accuracy per last 992 samples: 35.685483870967744\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|█████▉    | 1860/3125 [20:57<13:20,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1860/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7921547735891035 \n","Training Accuracy per last 992 samples: 34.778225806451616\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|█████▉    | 1874/3125 [21:06<13:12,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 1875 complete! Training Loss : 0.796677958170573\n","Epoch 2, batch 1875 complete! Training Accuracy : 0.3501\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:39<00:00,  4.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 1875 complete! Validation Loss : 1.6389749461206897\n","Epoch 2, batch 1875 complete! Validation Accuracy : 0.31533477321814257\n","Validation loss changed from 1.6438858207614941 to 1.6389749461206897\n","Best validation accuracy improved from 0.3102951763858891 to 0.31533477321814257\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 1875/3125 [21:46<4:21:56, 12.57s/it]"]},{"name":"stdout","output_type":"stream","text":["The model has been saved in models/Mon Nov 15 14:09:57 2021_lr_2e-06_val_acc_0.3153_ep_2.pt\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 1886/3125 [21:53<18:00,  1.15it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 62%|██████▏   | 1922/3125 [22:16<12:42,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1922/3125 of epoch 2 complete. Loss per last 992 samples:: 0.779514035870952 \n","Training Accuracy per last 992 samples: 35.78629032258065\n"]},{"name":"stderr","output_type":"stream","text":[" 63%|██████▎   | 1984/3125 [22:55<12:03,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1984/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7966483946769468 \n","Training Accuracy per last 992 samples: 34.17338709677419\n"]},{"name":"stderr","output_type":"stream","text":[" 65%|██████▌   | 2046/3125 [23:35<11:24,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2046/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7933062891806325 \n","Training Accuracy per last 992 samples: 38.810483870967744\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 2083/3125 [23:58<10:53,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 67%|██████▋   | 2108/3125 [24:14<10:42,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2108/3125 of epoch 2 complete. Loss per last 992 samples:: 0.8021314374862178 \n","Training Accuracy per last 992 samples: 32.76209677419355\n"]},{"name":"stderr","output_type":"stream","text":[" 68%|██████▊   | 2129/3125 [24:27<10:26,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 69%|██████▊   | 2145/3125 [24:37<10:15,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 69%|██████▉   | 2151/3125 [24:41<10:12,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 69%|██████▉   | 2170/3125 [24:53<10:02,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2170/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7904472966347972 \n","Training Accuracy per last 992 samples: 34.274193548387096\n"]},{"name":"stderr","output_type":"stream","text":[" 71%|███████▏  | 2232/3125 [25:32<09:22,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2232/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7819442749023438 \n","Training Accuracy per last 992 samples: 35.181451612903224\n"]},{"name":"stderr","output_type":"stream","text":[" 73%|███████▎  | 2294/3125 [26:11<08:44,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2294/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7969596001409716 \n","Training Accuracy per last 992 samples: 34.274193548387096\n"]},{"name":"stderr","output_type":"stream","text":[" 75%|███████▌  | 2356/3125 [26:50<08:06,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2356/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7879353800127583 \n","Training Accuracy per last 992 samples: 35.08064516129032\n"]},{"name":"stderr","output_type":"stream","text":[" 77%|███████▋  | 2393/3125 [27:13<07:44,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 77%|███████▋  | 2418/3125 [27:30<07:30,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2418/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7886881059215914 \n","Training Accuracy per last 992 samples: 35.98790322580645\n"]},{"name":"stderr","output_type":"stream","text":[" 78%|███████▊  | 2439/3125 [27:43<07:13,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 78%|███████▊  | 2446/3125 [27:47<07:10,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 79%|███████▉  | 2480/3125 [28:09<06:48,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2480/3125 of epoch 2 complete. Loss per last 992 samples:: 0.8019606067288306 \n","Training Accuracy per last 992 samples: 34.979838709677416\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|███████▉  | 2499/3125 [28:21<06:35,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 2500 complete! Training Loss : 0.7956896041870117\n","Epoch 2, batch 2500 complete! Training Accuracy : 0.3501\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:39<00:00,  4.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 2500 complete! Validation Loss : 1.6355625897988506\n","Epoch 2, batch 2500 complete! Validation Accuracy : 0.3174946004319654\n","Validation loss changed from 1.6389749461206897 to 1.6355625897988506\n","Best validation accuracy improved from 0.31533477321814257 to 0.3174946004319654\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 2500/3125 [29:01<2:10:42, 12.55s/it]"]},{"name":"stdout","output_type":"stream","text":["The model has been saved in models/Mon Nov 15 14:17:12 2021_lr_2e-06_val_acc_0.3175_ep_2.pt\n"]},{"name":"stderr","output_type":"stream","text":[" 81%|████████  | 2516/3125 [29:11<06:50,  1.48it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 81%|████████  | 2535/3125 [29:23<06:12,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 81%|████████▏ | 2542/3125 [29:28<06:11,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2542/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7916816896007907 \n","Training Accuracy per last 992 samples: 35.58467741935484\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 2604/3125 [30:07<05:31,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2604/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7928450799757435 \n","Training Accuracy per last 992 samples: 35.78629032258065\n"]},{"name":"stderr","output_type":"stream","text":[" 85%|████████▌ | 2658/3125 [30:41<04:56,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 85%|████████▌ | 2666/3125 [30:46<04:51,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2666/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7875590170583417 \n","Training Accuracy per last 992 samples: 36.29032258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 87%|████████▋ | 2728/3125 [31:26<04:11,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2728/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7913342445127426 \n","Training Accuracy per last 992 samples: 36.99596774193548\n"]},{"name":"stderr","output_type":"stream","text":[" 88%|████████▊ | 2745/3125 [31:36<03:58,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 89%|████████▉ | 2776/3125 [31:56<03:40,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 89%|████████▉ | 2790/3125 [32:05<03:32,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2790/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7963988704066123 \n","Training Accuracy per last 992 samples: 33.66935483870968\n"]},{"name":"stderr","output_type":"stream","text":[" 90%|█████████ | 2817/3125 [32:22<03:13,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 91%|█████████▏| 2852/3125 [32:44<02:53,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2852/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7847963456184633 \n","Training Accuracy per last 992 samples: 35.38306451612903\n"]},{"name":"stderr","output_type":"stream","text":[" 93%|█████████▎| 2914/3125 [33:23<02:14,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2914/3125 of epoch 2 complete. Loss per last 992 samples:: 0.8054877558062153 \n","Training Accuracy per last 992 samples: 33.568548387096776\n"]},{"name":"stderr","output_type":"stream","text":[" 95%|█████████▌| 2976/3125 [34:03<01:34,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2976/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7883517972884639 \n","Training Accuracy per last 992 samples: 38.104838709677416\n"]},{"name":"stderr","output_type":"stream","text":[" 96%|█████████▌| 3006/3125 [34:22<01:15,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 97%|█████████▋| 3038/3125 [34:42<00:55,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 3038/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7882723654470136 \n","Training Accuracy per last 992 samples: 34.17338709677419\n"]},{"name":"stderr","output_type":"stream","text":[" 98%|█████████▊| 3057/3125 [34:54<00:42,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 99%|█████████▉| 3100/3125 [35:21<00:15,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 3100/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7941751787739415 \n","Training Accuracy per last 992 samples: 36.08870967741935\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 3124/3125 [35:36<00:00,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 3125 complete! Training Loss : 0.7948805023193359\n","Epoch 2, batch 3125 complete! Training Accuracy : 0.35123834673708637\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 3125 complete! Validation Loss : 1.6348722611350575\n","Epoch 2, batch 3125 complete! Validation Accuracy : 0.3210943124550036\n","Validation loss changed from 1.6355625897988506 to 1.6348722611350575\n","Best validation accuracy improved from 0.3174946004319654 to 0.3210943124550036\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 3125/3125 [36:16<00:00,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["The model has been saved in models/Mon Nov 15 14:24:26 2021_lr_2e-06_val_acc_0.3211_ep_2.pt\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 62/3125 [00:39<32:24,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 62/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7778379994053994 \n","Training Accuracy per last 992 samples: 37.903225806451616\n"]},{"name":"stderr","output_type":"stream","text":["  3%|▎         | 96/3125 [01:01<32:15,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  3%|▎         | 103/3125 [01:05<31:51,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  4%|▍         | 124/3125 [01:18<31:42,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 124/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7829411414361769 \n","Training Accuracy per last 992 samples: 34.274193548387096\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 125/3125 [01:19<31:42,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  4%|▍         | 135/3125 [01:25<31:32,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  4%|▍         | 136/3125 [01:26<31:44,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  5%|▌         | 171/3125 [01:48<31:18,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  6%|▌         | 186/3125 [01:58<31:11,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 186/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7945540028233682 \n","Training Accuracy per last 992 samples: 36.08870967741935\n"]},{"name":"stderr","output_type":"stream","text":["  6%|▋         | 197/3125 [02:05<31:06,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  8%|▊         | 243/3125 [02:34<30:17,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  8%|▊         | 248/3125 [02:38<30:39,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 248/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7898263008363785 \n","Training Accuracy per last 992 samples: 36.49193548387097\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|▉         | 310/3125 [03:17<29:42,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 310/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7914351801718434 \n","Training Accuracy per last 992 samples: 37.600806451612904\n"]},{"name":"stderr","output_type":"stream","text":[" 12%|█▏        | 372/3125 [03:56<29:05,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 372/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7760858228129726 \n","Training Accuracy per last 992 samples: 38.608870967741936\n"]},{"name":"stderr","output_type":"stream","text":[" 14%|█▍        | 434/3125 [04:35<28:26,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 434/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7823241449171497 \n","Training Accuracy per last 992 samples: 37.5\n"]},{"name":"stderr","output_type":"stream","text":[" 16%|█▌        | 496/3125 [05:14<27:43,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 496/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7774892314787833 \n","Training Accuracy per last 992 samples: 39.11290322580645\n"]},{"name":"stderr","output_type":"stream","text":[" 18%|█▊        | 558/3125 [05:54<27:09,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 558/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7820597617856918 \n","Training Accuracy per last 992 samples: 36.08870967741935\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|█▉        | 620/3125 [06:33<26:30,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 620/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7672659350979713 \n","Training Accuracy per last 992 samples: 40.020161290322584\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|█▉        | 624/3125 [06:36<26:32,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 625 complete! Training Loss : 0.781925912475586\n","Epoch 3, batch 625 complete! Training Accuracy : 0.3741\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:39<00:00,  4.46it/s]\n"," 20%|██        | 625/3125 [07:15<8:34:26, 12.35s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 625 complete! Validation Loss : 1.6370835578304597\n","Epoch 3, batch 625 complete! Validation Accuracy : 0.31929445644348453\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 635/3125 [07:22<39:56,  1.04it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 21%|██        | 658/3125 [07:36<26:04,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 22%|██▏       | 682/3125 [07:51<25:50,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 682/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7722319941366872 \n","Training Accuracy per last 992 samples: 37.5\n"]},{"name":"stderr","output_type":"stream","text":[" 23%|██▎       | 705/3125 [08:06<25:27,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 23%|██▎       | 713/3125 [08:11<25:19,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 24%|██▍       | 744/3125 [08:31<25:13,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 744/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7885550222089214 \n","Training Accuracy per last 992 samples: 36.59274193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 26%|██▌       | 806/3125 [09:10<24:32,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 806/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7726971410935924 \n","Training Accuracy per last 992 samples: 38.00403225806452\n"]},{"name":"stderr","output_type":"stream","text":[" 28%|██▊       | 868/3125 [09:49<23:48,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 868/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7758666623023248 \n","Training Accuracy per last 992 samples: 37.096774193548384\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|██▉       | 930/3125 [10:28<23:16,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 930/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7701946996873424 \n","Training Accuracy per last 992 samples: 37.096774193548384\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|██▉       | 931/3125 [10:29<23:12,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 30%|███       | 940/3125 [10:35<23:07,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 32%|███▏      | 992/3125 [11:07<22:35,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 992/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7719082063244235 \n","Training Accuracy per last 992 samples: 38.608870967741936\n"]},{"name":"stderr","output_type":"stream","text":[" 33%|███▎      | 1019/3125 [11:25<22:05,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 34%|███▎      | 1054/3125 [11:47<21:50,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1054/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7861291823848602 \n","Training Accuracy per last 992 samples: 38.104838709677416\n"]},{"name":"stderr","output_type":"stream","text":[" 34%|███▍      | 1070/3125 [11:57<21:39,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 36%|███▌      | 1116/3125 [12:26<21:15,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1116/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7928160390546245 \n","Training Accuracy per last 992 samples: 35.88709677419355\n"]},{"name":"stderr","output_type":"stream","text":[" 37%|███▋      | 1151/3125 [12:48<20:43,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 38%|███▊      | 1178/3125 [13:05<20:31,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1178/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7605213657502206 \n","Training Accuracy per last 992 samples: 38.91129032258065\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 1240/3125 [13:44<19:52,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1240/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7728097054266161 \n","Training Accuracy per last 992 samples: 37.80241935483871\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 1249/3125 [13:50<19:44,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 1250 complete! Training Loss : 0.779389729309082\n","Epoch 3, batch 1250 complete! Training Accuracy : 0.37475\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.46it/s]\n"," 40%|████      | 1250/3125 [14:30<6:25:14, 12.33s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 1250 complete! Validation Loss : 1.6373305046695403\n","Epoch 3, batch 1250 complete! Validation Accuracy : 0.3167746580273578\n"]},{"name":"stderr","output_type":"stream","text":[" 42%|████▏     | 1302/3125 [15:03<19:14,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1302/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7854911127398091 \n","Training Accuracy per last 992 samples: 36.693548387096776\n"]},{"name":"stderr","output_type":"stream","text":[" 42%|████▏     | 1319/3125 [15:13<19:02,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 44%|████▎     | 1364/3125 [15:42<18:38,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1364/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7766187729374054 \n","Training Accuracy per last 992 samples: 38.20564516129032\n"]},{"name":"stderr","output_type":"stream","text":[" 46%|████▌     | 1426/3125 [16:21<17:59,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1426/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7779229071832472 \n","Training Accuracy per last 992 samples: 35.483870967741936\n"]},{"name":"stderr","output_type":"stream","text":[" 47%|████▋     | 1474/3125 [16:51<17:22,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 48%|████▊     | 1488/3125 [17:00<17:12,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1488/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7764272074545583 \n","Training Accuracy per last 992 samples: 38.810483870967744\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|████▉     | 1550/3125 [17:39<16:34,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1550/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7799510648173671 \n","Training Accuracy per last 992 samples: 34.979838709677416\n"]},{"name":"stderr","output_type":"stream","text":[" 52%|█████▏    | 1612/3125 [18:18<15:54,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1612/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7604140312440933 \n","Training Accuracy per last 992 samples: 38.91129032258065\n"]},{"name":"stderr","output_type":"stream","text":[" 52%|█████▏    | 1639/3125 [18:35<15:32,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 54%|█████▎    | 1674/3125 [18:57<15:15,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1674/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7766187114100302 \n","Training Accuracy per last 992 samples: 36.895161290322584\n"]},{"name":"stderr","output_type":"stream","text":[" 56%|█████▌    | 1736/3125 [19:36<14:38,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1736/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7651861252323273 \n","Training Accuracy per last 992 samples: 37.29838709677419\n"]},{"name":"stderr","output_type":"stream","text":[" 58%|█████▊    | 1798/3125 [20:15<13:57,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1798/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7709682218490108 \n","Training Accuracy per last 992 samples: 35.181451612903224\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|█████▉    | 1860/3125 [20:54<13:18,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1860/3125 of epoch 3 complete. Loss per last 992 samples:: 0.761092524374685 \n","Training Accuracy per last 992 samples: 38.104838709677416\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|█████▉    | 1874/3125 [21:03<13:08,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 1875 complete! Training Loss : 0.776993999226888\n","Epoch 3, batch 1875 complete! Training Accuracy : 0.3737666666666667\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.47it/s]\n"," 60%|██████    | 1875/3125 [21:43<4:16:35, 12.32s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 1875 complete! Validation Loss : 1.6339686602011494\n","Epoch 3, batch 1875 complete! Validation Accuracy : 0.31569474442044637\n"]},{"name":"stderr","output_type":"stream","text":[" 61%|██████    | 1903/3125 [22:01<12:48,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 62%|██████▏   | 1922/3125 [22:12<12:39,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1922/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7728691101074219 \n","Training Accuracy per last 992 samples: 38.40725806451613\n"]},{"name":"stderr","output_type":"stream","text":[" 63%|██████▎   | 1962/3125 [22:38<12:12,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 63%|██████▎   | 1984/3125 [22:52<11:59,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1984/3125 of epoch 3 complete. Loss per last 992 samples:: 0.769301014561807 \n","Training Accuracy per last 992 samples: 39.11290322580645\n"]},{"name":"stderr","output_type":"stream","text":[" 65%|██████▌   | 2046/3125 [23:31<11:20,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2046/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7701392327585528 \n","Training Accuracy per last 992 samples: 35.483870967741936\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 2108/3125 [24:10<10:41,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2108/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7734051981279927 \n","Training Accuracy per last 992 samples: 36.693548387096776\n"]},{"name":"stderr","output_type":"stream","text":[" 69%|██████▉   | 2170/3125 [24:49<10:02,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2170/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7788025640672253 \n","Training Accuracy per last 992 samples: 37.29838709677419\n"]},{"name":"stderr","output_type":"stream","text":[" 70%|██████▉   | 2183/3125 [24:57<09:52,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 71%|███████▏  | 2232/3125 [25:28<09:23,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2232/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7777790869435957 \n","Training Accuracy per last 992 samples: 38.40725806451613\n"]},{"name":"stderr","output_type":"stream","text":[" 73%|███████▎  | 2281/3125 [25:59<08:49,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 73%|███████▎  | 2284/3125 [26:00<08:53,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 73%|███████▎  | 2294/3125 [26:07<08:44,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2294/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7758704769995904 \n","Training Accuracy per last 992 samples: 37.096774193548384\n"]},{"name":"stderr","output_type":"stream","text":[" 74%|███████▍  | 2314/3125 [26:19<08:32,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 75%|███████▌  | 2356/3125 [26:46<08:04,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2356/3125 of epoch 3 complete. Loss per last 992 samples:: 0.777286006558326 \n","Training Accuracy per last 992 samples: 37.29838709677419\n"]},{"name":"stderr","output_type":"stream","text":[" 77%|███████▋  | 2418/3125 [27:25<07:25,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2418/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7559880595053395 \n","Training Accuracy per last 992 samples: 38.00403225806452\n"]},{"name":"stderr","output_type":"stream","text":[" 79%|███████▉  | 2480/3125 [28:04<06:47,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2480/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7756157844297348 \n","Training Accuracy per last 992 samples: 36.08870967741935\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|███████▉  | 2499/3125 [28:16<06:32,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 2500 complete! Training Loss : 0.7758928543090821\n","Epoch 3, batch 2500 complete! Training Accuracy : 0.373675\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.47it/s]\n"," 80%|████████  | 2500/3125 [28:56<2:08:19, 12.32s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 2500 complete! Validation Loss : 1.6367075251436782\n","Epoch 3, batch 2500 complete! Validation Accuracy : 0.3171346292296616\n"]},{"name":"stderr","output_type":"stream","text":[" 81%|████████▏ | 2542/3125 [29:22<06:08,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2542/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7671785354614258 \n","Training Accuracy per last 992 samples: 40.32258064516129\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 2604/3125 [30:01<05:28,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2604/3125 of epoch 3 complete. Loss per last 992 samples:: 0.783258899565666 \n","Training Accuracy per last 992 samples: 37.903225806451616\n"]},{"name":"stderr","output_type":"stream","text":[" 85%|████████▌ | 2666/3125 [30:40<04:50,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2666/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7836802082677041 \n","Training Accuracy per last 992 samples: 36.391129032258064\n"]},{"name":"stderr","output_type":"stream","text":[" 87%|████████▋ | 2728/3125 [31:19<04:10,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2728/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7760532133040889 \n","Training Accuracy per last 992 samples: 39.41532258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 89%|████████▉ | 2788/3125 [31:57<03:33,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 89%|████████▉ | 2790/3125 [31:58<03:33,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2790/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7618457425025201 \n","Training Accuracy per last 992 samples: 39.01209677419355\n"]},{"name":"stderr","output_type":"stream","text":[" 91%|█████████▏| 2852/3125 [32:37<02:52,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2852/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7820018645255796 \n","Training Accuracy per last 992 samples: 35.78629032258065\n"]},{"name":"stderr","output_type":"stream","text":[" 92%|█████████▏| 2880/3125 [32:55<02:34,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 92%|█████████▏| 2883/3125 [32:57<02:32,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 93%|█████████▎| 2898/3125 [33:06<02:23,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 93%|█████████▎| 2914/3125 [33:16<02:13,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2914/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7846772901473507 \n","Training Accuracy per last 992 samples: 35.88709677419355\n"]},{"name":"stderr","output_type":"stream","text":[" 94%|█████████▍| 2930/3125 [33:26<02:02,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 95%|█████████▌| 2976/3125 [33:55<01:34,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2976/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7588129966489731 \n","Training Accuracy per last 992 samples: 39.21370967741935\n"]},{"name":"stderr","output_type":"stream","text":[" 96%|█████████▌| 3001/3125 [34:11<01:17,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 97%|█████████▋| 3038/3125 [34:35<00:54,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 3038/3125 of epoch 3 complete. Loss per last 992 samples:: 0.760645374175041 \n","Training Accuracy per last 992 samples: 38.50806451612903\n"]},{"name":"stderr","output_type":"stream","text":[" 99%|█████████▉| 3094/3125 [35:10<00:19,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 99%|█████████▉| 3095/3125 [35:10<00:18,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 99%|█████████▉| 3100/3125 [35:14<00:15,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 3100/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7661144810338174 \n","Training Accuracy per last 992 samples: 35.483870967741936\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 3124/3125 [35:29<00:00,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 3125 complete! Training Loss : 0.775129165649414\n","Epoch 3, batch 3125 complete! Training Accuracy : 0.3744448445564758\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:39<00:00,  4.46it/s]\n","100%|██████████| 3125/3125 [36:08<00:00,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 3125 complete! Validation Loss : 1.636303430316092\n","Epoch 3, batch 3125 complete! Validation Accuracy : 0.3207343412526998\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 62/3125 [00:39<32:11,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 62/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7738644384568737 \n","Training Accuracy per last 992 samples: 38.70967741935484\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 124/3125 [01:18<31:30,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 124/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7586200160364951 \n","Training Accuracy per last 992 samples: 38.70967741935484\n"]},{"name":"stderr","output_type":"stream","text":["  6%|▌         | 186/3125 [01:57<30:55,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 186/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7560695217501733 \n","Training Accuracy per last 992 samples: 37.600806451612904\n"]},{"name":"stderr","output_type":"stream","text":["  7%|▋         | 232/3125 [02:26<30:26,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  8%|▊         | 248/3125 [02:36<30:15,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 248/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7628177212130639 \n","Training Accuracy per last 992 samples: 39.41532258064516\n"]},{"name":"stderr","output_type":"stream","text":["  9%|▊         | 266/3125 [02:47<30:03,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 10%|▉         | 310/3125 [03:15<29:36,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 310/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7695460165700605 \n","Training Accuracy per last 992 samples: 38.50806451612903\n"]},{"name":"stderr","output_type":"stream","text":[" 11%|█         | 343/3125 [03:36<29:09,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 12%|█▏        | 367/3125 [03:51<28:52,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 12%|█▏        | 372/3125 [03:54<29:02,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 372/3125 of epoch 4 complete. Loss per last 992 samples:: 0.754267446456417 \n","Training Accuracy per last 992 samples: 42.13709677419355\n"]},{"name":"stderr","output_type":"stream","text":[" 14%|█▍        | 434/3125 [04:34<31:30,  1.42it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 434/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7647554028418756 \n","Training Accuracy per last 992 samples: 38.20564516129032\n"]},{"name":"stderr","output_type":"stream","text":[" 16%|█▌        | 496/3125 [05:14<27:54,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 496/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7736088537400768 \n","Training Accuracy per last 992 samples: 37.600806451612904\n"]},{"name":"stderr","output_type":"stream","text":[" 18%|█▊        | 558/3125 [05:54<28:43,  1.49it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 558/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7520021930817635 \n","Training Accuracy per last 992 samples: 40.524193548387096\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|█▉        | 620/3125 [06:34<26:29,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 620/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7663456393826392 \n","Training Accuracy per last 992 samples: 39.818548387096776\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|█▉        | 624/3125 [06:36<26:29,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, batch 625 complete! Training Loss : 0.7627730316162109\n","Epoch 4, batch 625 complete! Training Accuracy : 0.3915\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:39<00:00,  4.46it/s]\n"," 20%|██        | 625/3125 [07:16<8:34:40, 12.35s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, batch 625 complete! Validation Loss : 1.6380320581896552\n","Epoch 4, batch 625 complete! Validation Accuracy : 0.32001439884809213\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 631/3125 [07:20<1:23:37,  2.01s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 21%|██        | 649/3125 [07:31<26:11,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 21%|██▏       | 665/3125 [07:41<25:51,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 22%|██▏       | 682/3125 [07:52<25:51,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 682/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7669771871259136 \n","Training Accuracy per last 992 samples: 37.600806451612904\n"]},{"name":"stderr","output_type":"stream","text":[" 22%|██▏       | 698/3125 [08:02<25:39,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 24%|██▍       | 744/3125 [08:31<25:12,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 744/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7640423313263924 \n","Training Accuracy per last 992 samples: 38.608870967741936\n"]},{"name":"stderr","output_type":"stream","text":[" 26%|██▌       | 806/3125 [09:10<24:30,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 806/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7430794931227162 \n","Training Accuracy per last 992 samples: 40.524193548387096\n"]},{"name":"stderr","output_type":"stream","text":[" 27%|██▋       | 859/3125 [09:44<23:47,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 28%|██▊       | 868/3125 [09:50<23:54,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 868/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7446298599243164 \n","Training Accuracy per last 992 samples: 41.229838709677416\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|██▉       | 930/3125 [10:29<23:10,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 930/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7344472023748583 \n","Training Accuracy per last 992 samples: 41.33064516129032\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|███       | 938/3125 [10:34<23:13,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 32%|███▏      | 992/3125 [11:08<22:29,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 992/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7628174751035629 \n","Training Accuracy per last 992 samples: 38.104838709677416\n"]},{"name":"stderr","output_type":"stream","text":[" 34%|███▎      | 1054/3125 [11:47<21:54,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1054/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7809548224172285 \n","Training Accuracy per last 992 samples: 38.00403225806452\n"]},{"name":"stderr","output_type":"stream","text":[" 35%|███▌      | 1098/3125 [12:15<21:26,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 36%|███▌      | 1116/3125 [12:27<21:13,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1116/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7402540945237682 \n","Training Accuracy per last 992 samples: 43.04435483870968\n"]},{"name":"stderr","output_type":"stream","text":[" 38%|███▊      | 1178/3125 [13:06<20:31,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1178/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7531246062247984 \n","Training Accuracy per last 992 samples: 40.020161290322584\n"]},{"name":"stderr","output_type":"stream","text":[" 38%|███▊      | 1194/3125 [13:16<20:22,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 39%|███▊      | 1210/3125 [13:26<20:12,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 40%|███▉      | 1240/3125 [13:45<19:52,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1240/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7545523489675214 \n","Training Accuracy per last 992 samples: 38.810483870967744\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 1249/3125 [13:51<19:39,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, batch 1250 complete! Training Loss : 0.7589549423217773\n","Epoch 4, batch 1250 complete! Training Accuracy : 0.3942\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.46it/s]\n"," 40%|████      | 1250/3125 [14:30<6:25:18, 12.33s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, batch 1250 complete! Validation Loss : 1.6420056573275863\n","Epoch 4, batch 1250 complete! Validation Accuracy : 0.31893448524118073\n"]},{"name":"stderr","output_type":"stream","text":[" 42%|████▏     | 1302/3125 [15:03<19:14,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1302/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7634276420839371 \n","Training Accuracy per last 992 samples: 38.810483870967744\n"]},{"name":"stderr","output_type":"stream","text":[" 44%|████▎     | 1364/3125 [15:43<18:36,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1364/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7511364721482799 \n","Training Accuracy per last 992 samples: 38.608870967741936\n"]},{"name":"stderr","output_type":"stream","text":[" 46%|████▌     | 1426/3125 [16:22<17:54,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1426/3125 of epoch 4 complete. Loss per last 992 samples:: 0.750015627953314 \n","Training Accuracy per last 992 samples: 39.91935483870968\n"]},{"name":"stderr","output_type":"stream","text":[" 48%|████▊     | 1488/3125 [17:01<17:19,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1488/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7564373323994298 \n","Training Accuracy per last 992 samples: 40.42338709677419\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|████▉     | 1550/3125 [17:40<16:38,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1550/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7582792774323495 \n","Training Accuracy per last 992 samples: 40.12096774193548\n"]},{"name":"stderr","output_type":"stream","text":[" 52%|█████▏    | 1612/3125 [18:20<16:00,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1612/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7374014700612714 \n","Training Accuracy per last 992 samples: 41.33064516129032\n"]},{"name":"stderr","output_type":"stream","text":[" 54%|█████▎    | 1674/3125 [18:59<15:20,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1674/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7437574632706181 \n","Training Accuracy per last 992 samples: 40.42338709677419\n"]},{"name":"stderr","output_type":"stream","text":[" 56%|█████▌    | 1736/3125 [19:38<14:42,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1736/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7300680222049836 \n","Training Accuracy per last 992 samples: 44.25403225806452\n"]},{"name":"stderr","output_type":"stream","text":[" 58%|█████▊    | 1798/3125 [20:17<14:01,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1798/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7553565732894405 \n","Training Accuracy per last 992 samples: 39.91935483870968\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|█████▉    | 1860/3125 [20:57<13:21,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1860/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7622828637399981 \n","Training Accuracy per last 992 samples: 39.71774193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|█████▉    | 1874/3125 [21:05<13:12,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, batch 1875 complete! Training Loss : 0.7560785949707032\n","Epoch 4, batch 1875 complete! Training Accuracy : 0.3972\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:39<00:00,  4.46it/s]\n"," 60%|██████    | 1875/3125 [21:45<4:17:02, 12.34s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, batch 1875 complete! Validation Loss : 1.6409168462643677\n","Epoch 4, batch 1875 complete! Validation Accuracy : 0.32001439884809213\n"]},{"name":"stderr","output_type":"stream","text":[" 62%|██████▏   | 1922/3125 [22:15<12:44,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1922/3125 of epoch 4 complete. Loss per last 992 samples:: 0.754141669119558 \n","Training Accuracy per last 992 samples: 38.50806451612903\n"]},{"name":"stderr","output_type":"stream","text":[" 62%|██████▏   | 1940/3125 [22:26<12:27,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 63%|██████▎   | 1977/3125 [22:50<12:00,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 63%|██████▎   | 1984/3125 [22:54<12:01,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1984/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7440144169715143 \n","Training Accuracy per last 992 samples: 40.725806451612904\n"]},{"name":"stderr","output_type":"stream","text":[" 64%|██████▎   | 1985/3125 [22:55<11:59,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 65%|██████▌   | 2046/3125 [23:33<11:19,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2046/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7441288117439516 \n","Training Accuracy per last 992 samples: 38.20564516129032\n"]},{"name":"stderr","output_type":"stream","text":[" 66%|██████▌   | 2055/3125 [23:39<11:12,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 67%|██████▋   | 2108/3125 [24:12<10:41,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2108/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7362782570623583 \n","Training Accuracy per last 992 samples: 42.33870967741935\n"]},{"name":"stderr","output_type":"stream","text":[" 69%|██████▉   | 2170/3125 [24:51<10:01,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2170/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7586996324600712 \n","Training Accuracy per last 992 samples: 38.91129032258065\n"]},{"name":"stderr","output_type":"stream","text":[" 71%|███████▏  | 2232/3125 [25:30<09:23,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2232/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7480793922178207 \n","Training Accuracy per last 992 samples: 40.32258064516129\n"]},{"name":"stderr","output_type":"stream","text":[" 72%|███████▏  | 2245/3125 [25:38<09:13,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 73%|███████▎  | 2294/3125 [26:09<08:44,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2294/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7473423865533644 \n","Training Accuracy per last 992 samples: 40.92741935483871\n"]},{"name":"stderr","output_type":"stream","text":[" 73%|███████▎  | 2296/3125 [26:10<08:47,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 74%|███████▍  | 2305/3125 [26:16<08:35,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 74%|███████▍  | 2306/3125 [26:17<08:39,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 75%|███████▌  | 2356/3125 [26:48<08:05,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2356/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7604697442823841 \n","Training Accuracy per last 992 samples: 39.314516129032256\n"]},{"name":"stderr","output_type":"stream","text":[" 77%|███████▋  | 2418/3125 [27:27<07:25,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2418/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7558308570615707 \n","Training Accuracy per last 992 samples: 39.41532258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 79%|███████▉  | 2480/3125 [28:06<06:46,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2480/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7537513086872716 \n","Training Accuracy per last 992 samples: 41.12903225806452\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|███████▉  | 2492/3125 [28:14<06:39,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 80%|███████▉  | 2499/3125 [28:18<06:34,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, batch 2500 complete! Training Loss : 0.7550749172210693\n","Epoch 4, batch 2500 complete! Training Accuracy : 0.397325\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:39<00:00,  4.46it/s]\n"," 80%|████████  | 2500/3125 [28:58<2:08:39, 12.35s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, batch 2500 complete! Validation Loss : 1.6416520743534482\n","Epoch 4, batch 2500 complete! Validation Accuracy : 0.3210943124550036\n"]},{"name":"stderr","output_type":"stream","text":[" 81%|████████▏ | 2542/3125 [29:24<06:08,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2542/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7490658913889239 \n","Training Accuracy per last 992 samples: 39.11290322580645\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 2604/3125 [30:04<05:29,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2604/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7213598066760648 \n","Training Accuracy per last 992 samples: 42.943548387096776\n"]},{"name":"stderr","output_type":"stream","text":[" 85%|████████▌ | 2657/3125 [30:37<04:54,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 85%|████████▌ | 2662/3125 [30:40<04:53,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 85%|████████▌ | 2666/3125 [30:43<04:52,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2666/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7527799298686366 \n","Training Accuracy per last 992 samples: 42.13709677419355\n"]},{"name":"stderr","output_type":"stream","text":[" 87%|████████▋ | 2728/3125 [31:22<04:10,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2728/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7512078746672599 \n","Training Accuracy per last 992 samples: 39.41532258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 89%|████████▉ | 2777/3125 [31:53<03:38,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 89%|████████▉ | 2790/3125 [32:01<03:30,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2790/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7387939576179751 \n","Training Accuracy per last 992 samples: 40.725806451612904\n"]},{"name":"stderr","output_type":"stream","text":[" 91%|█████████▏| 2852/3125 [32:40<02:52,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2852/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7449314978814894 \n","Training Accuracy per last 992 samples: 42.33870967741935\n"]},{"name":"stderr","output_type":"stream","text":[" 93%|█████████▎| 2914/3125 [33:19<02:12,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2914/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7488854008336221 \n","Training Accuracy per last 992 samples: 41.733870967741936\n"]},{"name":"stderr","output_type":"stream","text":[" 94%|█████████▎| 2922/3125 [33:24<02:08,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 95%|█████████▌| 2973/3125 [33:56<01:35,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 95%|█████████▌| 2975/3125 [33:57<01:34,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 95%|█████████▌| 2976/3125 [33:58<01:34,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2976/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7403198365242251 \n","Training Accuracy per last 992 samples: 42.439516129032256\n"]},{"name":"stderr","output_type":"stream","text":[" 97%|█████████▋| 3026/3125 [34:30<01:02,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 97%|█████████▋| 3031/3125 [34:33<00:59,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 97%|█████████▋| 3038/3125 [34:37<00:54,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 3038/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7537665213308027 \n","Training Accuracy per last 992 samples: 39.516129032258064\n"]},{"name":"stderr","output_type":"stream","text":[" 98%|█████████▊| 3061/3125 [34:52<00:40,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 98%|█████████▊| 3075/3125 [35:00<00:31,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 99%|█████████▉| 3092/3125 [35:11<00:20,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 99%|█████████▉| 3100/3125 [35:16<00:15,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 3100/3125 of epoch 4 complete. Loss per last 992 samples:: 0.7429614836169828 \n","Training Accuracy per last 992 samples: 39.71774193548387\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 3124/3125 [35:32<00:00,  1.46it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, batch 3125 complete! Training Loss : 0.752724210510254\n","Epoch 4, batch 3125 complete! Training Accuracy : 0.40043212099387826\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:39<00:00,  4.39it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, batch 3125 complete! Validation Loss : 1.6435490750718391\n","Epoch 4, batch 3125 complete! Validation Accuracy : 0.3275737940964723\n","Validation loss changed from 1.6348722611350575 to 1.6435490750718391\n","Best validation accuracy improved from 0.3210943124550036 to 0.3275737940964723\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 3125/3125 [36:12<00:00,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["The model has been saved in models/Mon Nov 15 15:36:48 2021_lr_2e-06_val_acc_0.3276_ep_4.pt\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 62/3125 [00:39<32:20,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 62/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7274415416102256 \n","Training Accuracy per last 992 samples: 43.75\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 124/3125 [01:18<31:37,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 124/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7477572348810011 \n","Training Accuracy per last 992 samples: 39.818548387096776\n"]},{"name":"stderr","output_type":"stream","text":["  5%|▍         | 143/3125 [01:30<31:23,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  6%|▌         | 173/3125 [01:49<31:07,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  6%|▌         | 186/3125 [01:57<31:05,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 186/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7480737624629852 \n","Training Accuracy per last 992 samples: 41.53225806451613\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 248/3125 [02:36<30:15,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 248/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7452965397988597 \n","Training Accuracy per last 992 samples: 39.71774193548387\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 261/3125 [02:45<29:57,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 10%|▉         | 310/3125 [03:16<29:35,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 310/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7441766185145224 \n","Training Accuracy per last 992 samples: 41.12903225806452\n"]},{"name":"stderr","output_type":"stream","text":[" 11%|█         | 335/3125 [03:31<29:11,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 12%|█▏        | 369/3125 [03:53<28:53,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 12%|█▏        | 372/3125 [03:55<28:57,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 372/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7365369489116054 \n","Training Accuracy per last 992 samples: 42.03629032258065\n"]},{"name":"stderr","output_type":"stream","text":[" 13%|█▎        | 410/3125 [04:19<28:35,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 14%|█▍        | 434/3125 [04:34<28:19,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 434/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7038818174792875 \n","Training Accuracy per last 992 samples: 45.86693548387097\n"]},{"name":"stderr","output_type":"stream","text":[" 16%|█▌        | 496/3125 [05:13<27:41,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 496/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7302311928041519 \n","Training Accuracy per last 992 samples: 42.439516129032256\n"]},{"name":"stderr","output_type":"stream","text":[" 16%|█▌        | 497/3125 [05:13<27:32,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 16%|█▌        | 502/3125 [05:16<27:36,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 17%|█▋        | 529/3125 [05:33<27:12,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 18%|█▊        | 558/3125 [05:52<27:01,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 558/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7341519017373362 \n","Training Accuracy per last 992 samples: 40.92741935483871\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|█▉        | 620/3125 [06:31<26:24,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 620/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7323008352710355 \n","Training Accuracy per last 992 samples: 42.03629032258065\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|█▉        | 624/3125 [06:33<26:23,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 5, batch 625 complete! Training Loss : 0.7351427291870117\n","Epoch 5, batch 625 complete! Training Accuracy : 0.4198\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:39<00:00,  4.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5, batch 625 complete! Validation Loss : 1.6465853987068966\n","Epoch 5, batch 625 complete! Validation Accuracy : 0.32901367890568756\n","Validation loss changed from 1.6435490750718391 to 1.6465853987068966\n","Best validation accuracy improved from 0.3275737940964723 to 0.32901367890568756\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 625/3125 [07:14<8:43:41, 12.57s/it]"]},{"name":"stdout","output_type":"stream","text":["The model has been saved in models/Mon Nov 15 15:44:02 2021_lr_2e-06_val_acc_0.329_ep_5.pt\n"]},{"name":"stderr","output_type":"stream","text":[" 22%|██▏       | 682/3125 [07:50<25:42,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 682/3125 of epoch 5 complete. Loss per last 992 samples:: 0.724743535441737 \n","Training Accuracy per last 992 samples: 43.346774193548384\n"]},{"name":"stderr","output_type":"stream","text":[" 22%|██▏       | 695/3125 [07:58<25:28,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 23%|██▎       | 711/3125 [08:08<25:17,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 24%|██▍       | 744/3125 [08:29<25:02,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 744/3125 of epoch 5 complete. Loss per last 992 samples:: 0.729935799875567 \n","Training Accuracy per last 992 samples: 43.24596774193548\n"]},{"name":"stderr","output_type":"stream","text":[" 26%|██▌       | 806/3125 [09:08<24:27,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 806/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7226207794681672 \n","Training Accuracy per last 992 samples: 43.145161290322584\n"]},{"name":"stderr","output_type":"stream","text":[" 28%|██▊       | 868/3125 [09:47<23:49,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 868/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7194640559534873 \n","Training Accuracy per last 992 samples: 43.95161290322581\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|██▉       | 930/3125 [10:26<23:08,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 930/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7308092732583323 \n","Training Accuracy per last 992 samples: 38.70967741935484\n"]},{"name":"stderr","output_type":"stream","text":[" 32%|███▏      | 992/3125 [11:05<22:27,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 992/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7300240301316784 \n","Training Accuracy per last 992 samples: 42.439516129032256\n"]},{"name":"stderr","output_type":"stream","text":[" 33%|███▎      | 1040/3125 [11:35<21:58,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 34%|███▎      | 1054/3125 [11:44<21:49,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1054/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7359967385568926 \n","Training Accuracy per last 992 samples: 41.83467741935484\n"]},{"name":"stderr","output_type":"stream","text":[" 34%|███▍      | 1066/3125 [11:52<21:39,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 36%|███▌      | 1116/3125 [12:23<21:09,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1116/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7558531914987872 \n","Training Accuracy per last 992 samples: 40.32258064516129\n"]},{"name":"stderr","output_type":"stream","text":[" 37%|███▋      | 1145/3125 [12:41<20:43,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 38%|███▊      | 1178/3125 [13:02<20:33,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1178/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7182661179573305 \n","Training Accuracy per last 992 samples: 43.145161290322584\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 1240/3125 [13:41<19:49,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1240/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7258721782315162 \n","Training Accuracy per last 992 samples: 41.63306451612903\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 1249/3125 [13:47<19:37,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 5, batch 1250 complete! Training Loss : 0.7317644439697265\n","Epoch 5, batch 1250 complete! Training Accuracy : 0.42085\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:39<00:00,  4.46it/s]\n"," 40%|████      | 1250/3125 [14:27<6:25:51, 12.35s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 5, batch 1250 complete! Validation Loss : 1.6533090876436782\n","Epoch 5, batch 1250 complete! Validation Accuracy : 0.32181425485961124\n"]},{"name":"stderr","output_type":"stream","text":[" 41%|████      | 1288/3125 [14:50<19:19,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 42%|████▏     | 1302/3125 [14:59<19:43,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1302/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7232651864328692 \n","Training Accuracy per last 992 samples: 40.82661290322581\n"]},{"name":"stderr","output_type":"stream","text":[" 44%|████▎     | 1364/3125 [15:41<20:07,  1.46it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1364/3125 of epoch 5 complete. Loss per last 992 samples:: 0.738902215034731 \n","Training Accuracy per last 992 samples: 40.12096774193548\n"]},{"name":"stderr","output_type":"stream","text":[" 45%|████▍     | 1405/3125 [16:07<18:13,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 46%|████▌     | 1426/3125 [16:21<18:27,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1426/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7195507172615297 \n","Training Accuracy per last 992 samples: 42.13709677419355\n"]},{"name":"stderr","output_type":"stream","text":[" 48%|████▊     | 1488/3125 [17:01<18:01,  1.51it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1488/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7449665377216954 \n","Training Accuracy per last 992 samples: 40.12096774193548\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|████▉     | 1550/3125 [17:43<17:59,  1.46it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1550/3125 of epoch 5 complete. Loss per last 992 samples:: 0.718829708714639 \n","Training Accuracy per last 992 samples: 43.75\n"]},{"name":"stderr","output_type":"stream","text":[" 52%|█████▏    | 1612/3125 [18:23<16:07,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1612/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7244475580030872 \n","Training Accuracy per last 992 samples: 43.145161290322584\n"]},{"name":"stderr","output_type":"stream","text":[" 54%|█████▎    | 1674/3125 [19:03<15:58,  1.51it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1674/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7190800020771642 \n","Training Accuracy per last 992 samples: 45.564516129032256\n"]},{"name":"stderr","output_type":"stream","text":[" 54%|█████▍    | 1702/3125 [19:21<16:13,  1.46it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 56%|█████▌    | 1736/3125 [19:43<14:37,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1736/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7395894450526084 \n","Training Accuracy per last 992 samples: 40.221774193548384\n"]},{"name":"stderr","output_type":"stream","text":[" 58%|█████▊    | 1798/3125 [20:26<15:54,  1.39it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1798/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7611856768208165 \n","Training Accuracy per last 992 samples: 36.99596774193548\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|█████▉    | 1860/3125 [21:10<14:54,  1.41it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1860/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7200048508182648 \n","Training Accuracy per last 992 samples: 43.04435483870968\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|█████▉    | 1874/3125 [21:20<14:41,  1.42it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 5, batch 1875 complete! Training Loss : 0.7318073862711588\n","Epoch 5, batch 1875 complete! Training Accuracy : 0.41896666666666665\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:43<00:00,  3.99it/s]\n"," 60%|██████    | 1875/3125 [22:04<4:47:16, 13.79s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 5, batch 1875 complete! Validation Loss : 1.6563678609913792\n","Epoch 5, batch 1875 complete! Validation Accuracy : 0.32181425485961124\n"]},{"name":"stderr","output_type":"stream","text":[" 62%|██████▏   | 1922/3125 [22:37<14:11,  1.41it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1922/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7445549503449471 \n","Training Accuracy per last 992 samples: 42.23790322580645\n"]},{"name":"stderr","output_type":"stream","text":[" 62%|██████▏   | 1935/3125 [22:47<15:02,  1.32it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 63%|██████▎   | 1957/3125 [23:03<13:53,  1.40it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 63%|██████▎   | 1984/3125 [23:23<13:49,  1.38it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1984/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7569305819849814 \n","Training Accuracy per last 992 samples: 40.020161290322584\n"]},{"name":"stderr","output_type":"stream","text":[" 64%|██████▍   | 2010/3125 [23:41<13:07,  1.42it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 65%|██████▌   | 2046/3125 [24:07<12:51,  1.40it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2046/3125 of epoch 5 complete. Loss per last 992 samples:: 0.6951747402068107 \n","Training Accuracy per last 992 samples: 46.471774193548384\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 2093/3125 [24:40<12:17,  1.40it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 67%|██████▋   | 2108/3125 [24:51<12:25,  1.36it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2108/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7449833962225145 \n","Training Accuracy per last 992 samples: 40.32258064516129\n"]},{"name":"stderr","output_type":"stream","text":[" 69%|██████▉   | 2170/3125 [25:33<10:52,  1.46it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2170/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7187176058369298 \n","Training Accuracy per last 992 samples: 44.354838709677416\n"]},{"name":"stderr","output_type":"stream","text":[" 71%|███████▏  | 2232/3125 [26:13<09:29,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2232/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7436325626988565 \n","Training Accuracy per last 992 samples: 42.03629032258065\n"]},{"name":"stderr","output_type":"stream","text":[" 72%|███████▏  | 2235/3125 [26:15<09:23,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 73%|███████▎  | 2294/3125 [26:56<09:42,  1.43it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2294/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7528427185550812 \n","Training Accuracy per last 992 samples: 41.229838709677416\n"]},{"name":"stderr","output_type":"stream","text":[" 74%|███████▍  | 2325/3125 [27:17<09:15,  1.44it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 75%|███████▍  | 2341/3125 [27:29<09:20,  1.40it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 75%|███████▌  | 2356/3125 [27:40<09:02,  1.42it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2356/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7127922734906597 \n","Training Accuracy per last 992 samples: 44.75806451612903\n"]},{"name":"stderr","output_type":"stream","text":[" 77%|███████▋  | 2391/3125 [28:05<09:10,  1.33it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 77%|███████▋  | 2418/3125 [28:23<07:39,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2418/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7302496817804152 \n","Training Accuracy per last 992 samples: 40.725806451612904\n"]},{"name":"stderr","output_type":"stream","text":[" 79%|███████▉  | 2480/3125 [29:03<06:54,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2480/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7329399047359344 \n","Training Accuracy per last 992 samples: 42.641129032258064\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|███████▉  | 2499/3125 [29:16<06:35,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 5, batch 2500 complete! Training Loss : 0.732119764328003\n","Epoch 5, batch 2500 complete! Training Accuracy : 0.42055\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:39<00:00,  4.42it/s]\n"," 80%|████████  | 2500/3125 [29:56<2:09:46, 12.46s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 5, batch 2500 complete! Validation Loss : 1.656494140625\n","Epoch 5, batch 2500 complete! Validation Accuracy : 0.31965442764578833\n"]},{"name":"stderr","output_type":"stream","text":[" 81%|████████▏ | 2542/3125 [30:22<06:17,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2542/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7196329024530226 \n","Training Accuracy per last 992 samples: 44.05241935483871\n"]},{"name":"stderr","output_type":"stream","text":[" 82%|████████▏ | 2553/3125 [30:29<06:10,  1.55it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 82%|████████▏ | 2570/3125 [30:41<05:56,  1.56it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 82%|████████▏ | 2571/3125 [30:41<05:53,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 83%|████████▎ | 2604/3125 [31:03<05:56,  1.46it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2604/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7136307685605942 \n","Training Accuracy per last 992 samples: 45.46370967741935\n"]},{"name":"stderr","output_type":"stream","text":[" 85%|████████▌ | 2666/3125 [31:44<05:08,  1.49it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2666/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7419220247576314 \n","Training Accuracy per last 992 samples: 39.71774193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 86%|████████▋ | 2703/3125 [32:08<04:34,  1.54it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 87%|████████▋ | 2728/3125 [32:24<04:13,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2728/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7384412519393428 \n","Training Accuracy per last 992 samples: 40.625\n"]},{"name":"stderr","output_type":"stream","text":[" 87%|████████▋ | 2729/3125 [32:25<04:10,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 88%|████████▊ | 2749/3125 [32:37<03:58,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 88%|████████▊ | 2758/3125 [32:43<03:51,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 89%|████████▉ | 2790/3125 [33:03<03:32,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2790/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7416529809274981 \n","Training Accuracy per last 992 samples: 42.23790322580645\n"]},{"name":"stderr","output_type":"stream","text":[" 91%|█████████▏| 2852/3125 [33:43<02:55,  1.55it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2852/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7083020979358304 \n","Training Accuracy per last 992 samples: 43.95161290322581\n"]},{"name":"stderr","output_type":"stream","text":[" 93%|█████████▎| 2914/3125 [34:23<02:16,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2914/3125 of epoch 5 complete. Loss per last 992 samples:: 0.735921444431428 \n","Training Accuracy per last 992 samples: 42.13709677419355\n"]},{"name":"stderr","output_type":"stream","text":[" 94%|█████████▎| 2927/3125 [34:32<02:05,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 95%|█████████▌| 2976/3125 [35:03<01:37,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2976/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7209109029462261 \n","Training Accuracy per last 992 samples: 42.54032258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 95%|█████████▌| 2977/3125 [35:04<01:35,  1.54it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 97%|█████████▋| 3038/3125 [35:44<00:57,  1.52it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 3038/3125 of epoch 5 complete. Loss per last 992 samples:: 0.7455670295223114 \n","Training Accuracy per last 992 samples: 40.42338709677419\n"]},{"name":"stderr","output_type":"stream","text":[" 98%|█████████▊| 3063/3125 [36:00<00:41,  1.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 99%|█████████▉| 3100/3125 [36:24<00:16,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 3100/3125 of epoch 5 complete. Loss per last 992 samples:: 0.713006773302632 \n","Training Accuracy per last 992 samples: 41.935483870967744\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 3124/3125 [36:40<00:00,  1.51it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 5, batch 3125 complete! Training Loss : 0.7311534359741211\n","Epoch 5, batch 3125 complete! Training Accuracy : 0.42093786260152843\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:40<00:00,  4.34it/s]\n","100%|██████████| 3125/3125 [37:20<00:00,  1.39it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 5, batch 3125 complete! Validation Loss : 1.6534774604885059\n","Epoch 5, batch 3125 complete! Validation Accuracy : 0.3232541396688265\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["train_bert(net, criterion, opti, LEARNING_RATE, lr_scheduler, train_loader, val_loader, EPOCHS, iters_to_accumulate)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  2%|▏         | 62/3125 [00:43<35:24,  1.44it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 62/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7610993539133379 \n","Training Accuracy per last 992 samples: 38.608870967741936\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 124/3125 [01:27<34:13,  1.46it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 124/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7680441641038463 \n","Training Accuracy per last 992 samples: 37.096774193548384\n"]},{"name":"stderr","output_type":"stream","text":["  6%|▌         | 186/3125 [02:10<34:38,  1.41it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 186/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7591177725022838 \n","Training Accuracy per last 992 samples: 37.600806451612904\n"]},{"name":"stderr","output_type":"stream","text":["  7%|▋         | 210/3125 [02:27<34:19,  1.42it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  7%|▋         | 225/3125 [02:38<33:35,  1.44it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  8%|▊         | 240/3125 [02:48<33:41,  1.43it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  8%|▊         | 248/3125 [02:54<33:44,  1.42it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 248/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7564150287259009 \n","Training Accuracy per last 992 samples: 41.229838709677416\n"]},{"name":"stderr","output_type":"stream","text":["  9%|▉         | 277/3125 [03:14<33:20,  1.42it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 10%|▉         | 310/3125 [03:37<32:59,  1.42it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 310/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7839771086169828 \n","Training Accuracy per last 992 samples: 35.483870967741936\n"]},{"name":"stderr","output_type":"stream","text":[" 12%|█▏        | 372/3125 [04:21<32:11,  1.43it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 372/3125 of epoch 1 complete. Loss per last 992 samples:: 0.759388800590269 \n","Training Accuracy per last 992 samples: 40.020161290322584\n"]},{"name":"stderr","output_type":"stream","text":[" 14%|█▍        | 434/3125 [05:04<31:50,  1.41it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 434/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7703494410361013 \n","Training Accuracy per last 992 samples: 37.399193548387096\n"]},{"name":"stderr","output_type":"stream","text":[" 16%|█▌        | 496/3125 [05:48<30:37,  1.43it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 496/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7649664417389901 \n","Training Accuracy per last 992 samples: 37.096774193548384\n"]},{"name":"stderr","output_type":"stream","text":[" 18%|█▊        | 558/3125 [06:31<29:47,  1.44it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 558/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7636646455334078 \n","Training Accuracy per last 992 samples: 38.40725806451613\n"]},{"name":"stderr","output_type":"stream","text":[" 19%|█▉        | 604/3125 [07:03<29:37,  1.42it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 20%|█▉        | 620/3125 [07:14<29:22,  1.42it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 620/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7688890426389633 \n","Training Accuracy per last 992 samples: 37.600806451612904\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|█▉        | 624/3125 [07:17<29:01,  1.44it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 625 complete! Training Loss : 0.7651525039672852\n","Epoch 1, batch 625 complete! Training Accuracy : 0.3812\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:42<00:00,  4.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 625 complete! Validation Loss : 1.609692102191092\n","Epoch 1, batch 625 complete! Validation Accuracy : 0.3408927285817135\n","Validation loss changed from inf to 1.609692102191092\n","Best validation accuracy improved from 0 to 0.3408927285817135\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 625/3125 [08:02<9:35:12, 13.81s/it]"]},{"name":"stdout","output_type":"stream","text":["The model has been saved in models/Sun Nov 14 23:26:39 2021_lr_2e-06_val_acc_0.3409_ep_1.pt\n"]},{"name":"stderr","output_type":"stream","text":[" 22%|██▏       | 682/3125 [08:41<28:58,  1.41it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 682/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7649715485111359 \n","Training Accuracy per last 992 samples: 39.818548387096776\n"]},{"name":"stderr","output_type":"stream","text":[" 23%|██▎       | 713/3125 [09:03<27:51,  1.44it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 24%|██▍       | 744/3125 [09:25<27:53,  1.42it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 744/3125 of epoch 1 complete. Loss per last 992 samples:: 0.754766248887585 \n","Training Accuracy per last 992 samples: 40.725806451612904\n"]},{"name":"stderr","output_type":"stream","text":[" 26%|██▌       | 806/3125 [10:09<27:25,  1.41it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 806/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7728978741553522 \n","Training Accuracy per last 992 samples: 34.979838709677416\n"]},{"name":"stderr","output_type":"stream","text":[" 27%|██▋       | 855/3125 [10:43<26:35,  1.42it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 28%|██▊       | 868/3125 [10:52<26:28,  1.42it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 868/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7633215073616274 \n","Training Accuracy per last 992 samples: 38.91129032258065\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|██▉       | 930/3125 [11:36<25:51,  1.41it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 930/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7595854420815745 \n","Training Accuracy per last 992 samples: 38.40725806451613\n"]},{"name":"stderr","output_type":"stream","text":[" 32%|███▏      | 985/3125 [12:15<24:51,  1.43it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 32%|███▏      | 992/3125 [12:20<25:17,  1.41it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 992/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7534224294847057 \n","Training Accuracy per last 992 samples: 41.63306451612903\n"]},{"name":"stderr","output_type":"stream","text":[" 34%|███▎      | 1054/3125 [13:03<24:28,  1.41it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1054/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7562687166275517 \n","Training Accuracy per last 992 samples: 39.01209677419355\n"]},{"name":"stderr","output_type":"stream","text":[" 35%|███▍      | 1083/3125 [13:24<23:38,  1.44it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 36%|███▌      | 1116/3125 [13:47<23:21,  1.43it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1116/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7668566242341073 \n","Training Accuracy per last 992 samples: 38.00403225806452\n"]},{"name":"stderr","output_type":"stream","text":[" 38%|███▊      | 1178/3125 [14:31<22:50,  1.42it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1178/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7573388930289976 \n","Training Accuracy per last 992 samples: 37.70161290322581\n"]},{"name":"stderr","output_type":"stream","text":[" 38%|███▊      | 1184/3125 [14:35<22:29,  1.44it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 39%|███▊      | 1205/3125 [14:50<22:14,  1.44it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 40%|███▉      | 1240/3125 [15:14<22:02,  1.42it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1240/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7560096863777407 \n","Training Accuracy per last 992 samples: 37.903225806451616\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 1249/3125 [15:20<21:36,  1.45it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 1250 complete! Training Loss : 0.7630685493469238\n","Epoch 1, batch 1250 complete! Training Accuracy : 0.38395\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:43<00:00,  4.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 1250 complete! Validation Loss : 1.6073573320761494\n","Epoch 1, batch 1250 complete! Validation Accuracy : 0.3516918646508279\n","Validation loss changed from 1.609692102191092 to 1.6073573320761494\n","Best validation accuracy improved from 0.3408927285817135 to 0.3516918646508279\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 1250/3125 [16:05<7:13:14, 13.86s/it]"]},{"name":"stdout","output_type":"stream","text":["The model has been saved in models/Sun Nov 14 23:34:43 2021_lr_2e-06_val_acc_0.3517_ep_1.pt\n"]},{"name":"stderr","output_type":"stream","text":[" 42%|████▏     | 1297/3125 [16:38<21:35,  1.41it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 42%|████▏     | 1302/3125 [16:41<21:35,  1.41it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1302/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7581932621617471 \n","Training Accuracy per last 992 samples: 38.306451612903224\n"]},{"name":"stderr","output_type":"stream","text":[" 43%|████▎     | 1341/3125 [17:09<20:47,  1.43it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 44%|████▎     | 1364/3125 [17:25<20:48,  1.41it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1364/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7522482718190839 \n","Training Accuracy per last 992 samples: 39.516129032258064\n"]},{"name":"stderr","output_type":"stream","text":[" 45%|████▌     | 1416/3125 [18:01<19:45,  1.44it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 46%|████▌     | 1426/3125 [18:08<19:57,  1.42it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1426/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7662668843423167 \n","Training Accuracy per last 992 samples: 38.50806451612903\n"]},{"name":"stderr","output_type":"stream","text":[" 48%|████▊     | 1488/3125 [18:52<19:02,  1.43it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1488/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7633981397075038 \n","Training Accuracy per last 992 samples: 38.00403225806452\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|████▉     | 1550/3125 [19:35<18:10,  1.44it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1550/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7678376782325006 \n","Training Accuracy per last 992 samples: 40.42338709677419\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|████▉     | 1554/3125 [19:38<18:26,  1.42it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 50%|█████     | 1576/3125 [19:54<18:12,  1.42it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 52%|█████▏    | 1612/3125 [20:19<16:30,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1612/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7452465180427797 \n","Training Accuracy per last 992 samples: 39.818548387096776\n"]},{"name":"stderr","output_type":"stream","text":[" 53%|█████▎    | 1644/3125 [20:39<15:39,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 54%|█████▎    | 1674/3125 [20:59<16:12,  1.49it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1674/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7379825038294638 \n","Training Accuracy per last 992 samples: 41.63306451612903\n"]},{"name":"stderr","output_type":"stream","text":[" 55%|█████▍    | 1708/3125 [21:21<15:43,  1.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 56%|█████▌    | 1736/3125 [21:39<15:43,  1.47it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1736/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7633992472002583 \n","Training Accuracy per last 992 samples: 38.306451612903224\n"]},{"name":"stderr","output_type":"stream","text":[" 56%|█████▋    | 1758/3125 [21:53<14:29,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 58%|█████▊    | 1798/3125 [22:18<14:01,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1798/3125 of epoch 1 complete. Loss per last 992 samples:: 0.757744312286377 \n","Training Accuracy per last 992 samples: 40.524193548387096\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|█████▉    | 1860/3125 [22:58<13:25,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1860/3125 of epoch 1 complete. Loss per last 992 samples:: 0.770726450027958 \n","Training Accuracy per last 992 samples: 39.41532258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|█████▉    | 1874/3125 [23:07<13:15,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 1875 complete! Training Loss : 0.7614534962972005\n","Epoch 1, batch 1875 complete! Training Accuracy : 0.38766666666666666\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.48it/s]\n"," 60%|██████    | 1875/3125 [23:46<4:16:03, 12.29s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 1875 complete! Validation Loss : 1.6061478538074712\n","Epoch 1, batch 1875 complete! Validation Accuracy : 0.34557235421166305\n"]},{"name":"stderr","output_type":"stream","text":[" 62%|██████▏   | 1922/3125 [24:16<12:43,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1922/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7642035330495527 \n","Training Accuracy per last 992 samples: 38.50806451612903\n"]},{"name":"stderr","output_type":"stream","text":[" 62%|██████▏   | 1927/3125 [24:19<12:40,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 63%|██████▎   | 1967/3125 [24:45<12:11,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 63%|██████▎   | 1984/3125 [24:55<12:05,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1984/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7468494599865328 \n","Training Accuracy per last 992 samples: 39.71774193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 65%|██████▌   | 2046/3125 [25:35<11:27,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2046/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7394945698399698 \n","Training Accuracy per last 992 samples: 41.53225806451613\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 2108/3125 [26:14<10:46,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2108/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7535068142798639 \n","Training Accuracy per last 992 samples: 39.21370967741935\n"]},{"name":"stderr","output_type":"stream","text":[" 69%|██████▉   | 2170/3125 [26:53<10:05,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2170/3125 of epoch 1 complete. Loss per last 992 samples:: 0.756716912792575 \n","Training Accuracy per last 992 samples: 38.810483870967744\n"]},{"name":"stderr","output_type":"stream","text":[" 71%|███████▏  | 2232/3125 [27:33<09:26,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2232/3125 of epoch 1 complete. Loss per last 992 samples:: 0.754191767784857 \n","Training Accuracy per last 992 samples: 41.733870967741936\n"]},{"name":"stderr","output_type":"stream","text":[" 73%|███████▎  | 2294/3125 [28:12<08:47,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2294/3125 of epoch 1 complete. Loss per last 992 samples:: 0.752709819424537 \n","Training Accuracy per last 992 samples: 39.91935483870968\n"]},{"name":"stderr","output_type":"stream","text":[" 75%|███████▌  | 2356/3125 [28:51<08:07,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2356/3125 of epoch 1 complete. Loss per last 992 samples:: 0.751659054909983 \n","Training Accuracy per last 992 samples: 40.625\n"]},{"name":"stderr","output_type":"stream","text":[" 77%|███████▋  | 2418/3125 [29:31<07:30,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2418/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7582994891751197 \n","Training Accuracy per last 992 samples: 38.306451612903224\n"]},{"name":"stderr","output_type":"stream","text":[" 78%|███████▊  | 2451/3125 [29:52<07:20,  1.53it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 79%|███████▉  | 2480/3125 [30:10<06:50,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2480/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7401442681589434 \n","Training Accuracy per last 992 samples: 43.54838709677419\n"]},{"name":"stderr","output_type":"stream","text":[" 79%|███████▉  | 2482/3125 [30:12<06:52,  1.56it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 80%|███████▉  | 2489/3125 [30:16<06:43,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 80%|███████▉  | 2499/3125 [30:22<06:35,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 2500 complete! Training Loss : 0.7589632827758789\n","Epoch 1, batch 2500 complete! Training Accuracy : 0.39115\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:40<00:00,  4.26it/s]\n"," 80%|████████  | 2500/3125 [31:04<2:14:12, 12.88s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 2500 complete! Validation Loss : 1.6087071210488506\n","Epoch 1, batch 2500 complete! Validation Accuracy : 0.3441324694024478\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 2512/3125 [31:11<08:13,  1.24it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 81%|████████  | 2533/3125 [31:25<06:21,  1.55it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 81%|████████▏ | 2542/3125 [31:31<06:11,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2542/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7334115582127725 \n","Training Accuracy per last 992 samples: 42.84274193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 2584/3125 [31:58<05:44,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 83%|████████▎ | 2604/3125 [32:10<05:31,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2604/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7447869085496471 \n","Training Accuracy per last 992 samples: 39.71774193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 2605/3125 [32:11<05:30,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 85%|████████▌ | 2666/3125 [32:50<04:51,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2666/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7440088025985225 \n","Training Accuracy per last 992 samples: 40.32258064516129\n"]},{"name":"stderr","output_type":"stream","text":[" 86%|████████▋ | 2700/3125 [33:11<04:30,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 87%|████████▋ | 2706/3125 [33:15<04:27,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 87%|████████▋ | 2728/3125 [33:29<04:12,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2728/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7579369391164472 \n","Training Accuracy per last 992 samples: 39.41532258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 88%|████████▊ | 2738/3125 [33:36<04:06,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 89%|████████▉ | 2790/3125 [34:09<03:33,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2790/3125 of epoch 1 complete. Loss per last 992 samples:: 0.738769777359501 \n","Training Accuracy per last 992 samples: 39.91935483870968\n"]},{"name":"stderr","output_type":"stream","text":[" 91%|█████████▏| 2852/3125 [34:48<02:53,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2852/3125 of epoch 1 complete. Loss per last 992 samples:: 0.755156732374622 \n","Training Accuracy per last 992 samples: 40.221774193548384\n"]},{"name":"stderr","output_type":"stream","text":[" 92%|█████████▏| 2860/3125 [34:53<02:48,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 93%|█████████▎| 2914/3125 [35:27<02:14,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2914/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7325109051119897 \n","Training Accuracy per last 992 samples: 41.028225806451616\n"]},{"name":"stderr","output_type":"stream","text":[" 95%|█████████▌| 2976/3125 [36:07<01:34,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2976/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7538574280277375 \n","Training Accuracy per last 992 samples: 40.12096774193548\n"]},{"name":"stderr","output_type":"stream","text":[" 96%|█████████▋| 3014/3125 [36:31<01:10,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 97%|█████████▋| 3038/3125 [36:46<00:55,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 3038/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7584363875850555 \n","Training Accuracy per last 992 samples: 39.818548387096776\n"]},{"name":"stderr","output_type":"stream","text":[" 98%|█████████▊| 3068/3125 [37:05<00:36,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 99%|█████████▉| 3100/3125 [37:25<00:15,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 3100/3125 of epoch 1 complete. Loss per last 992 samples:: 0.7301204435286983 \n","Training Accuracy per last 992 samples: 41.229838709677416\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 3124/3125 [37:41<00:00,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 3125 complete! Training Loss : 0.7560006820678711\n","Epoch 1, batch 3125 complete! Training Accuracy : 0.3938902892809987\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.47it/s]\n","100%|██████████| 3125/3125 [38:20<00:00,  1.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 3125 complete! Validation Loss : 1.6083731815732758\n","Epoch 1, batch 3125 complete! Validation Accuracy : 0.34485241180705545\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 15/3125 [00:09<32:54,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  2%|▏         | 62/3125 [00:39<32:27,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 62/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7333872856632355 \n","Training Accuracy per last 992 samples: 40.625\n"]},{"name":"stderr","output_type":"stream","text":["  3%|▎         | 84/3125 [00:53<33:42,  1.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  4%|▍         | 124/3125 [01:19<31:40,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 124/3125 of epoch 2 complete. Loss per last 992 samples:: 0.729388544636388 \n","Training Accuracy per last 992 samples: 41.63306451612903\n"]},{"name":"stderr","output_type":"stream","text":["  6%|▌         | 186/3125 [01:58<32:29,  1.51it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 186/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7248190756767027 \n","Training Accuracy per last 992 samples: 42.54032258064516\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 248/3125 [02:39<30:35,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 248/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7324972460346837 \n","Training Accuracy per last 992 samples: 42.439516129032256\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|▉         | 308/3125 [03:17<29:50,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 10%|▉         | 310/3125 [03:18<30:06,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 310/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7351908837595293 \n","Training Accuracy per last 992 samples: 41.33064516129032\n"]},{"name":"stderr","output_type":"stream","text":[" 12%|█▏        | 372/3125 [03:57<29:09,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 372/3125 of epoch 2 complete. Loss per last 992 samples:: 0.747664543890184 \n","Training Accuracy per last 992 samples: 39.314516129032256\n"]},{"name":"stderr","output_type":"stream","text":[" 14%|█▎        | 424/3125 [04:30<28:37,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 14%|█▍        | 431/3125 [04:35<28:26,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 14%|█▍        | 434/3125 [04:37<28:40,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 434/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7353779423621393 \n","Training Accuracy per last 992 samples: 42.84274193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 14%|█▍        | 445/3125 [04:44<28:13,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 16%|█▌        | 496/3125 [05:16<27:46,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 496/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7254980148807648 \n","Training Accuracy per last 992 samples: 40.625\n"]},{"name":"stderr","output_type":"stream","text":[" 16%|█▋        | 513/3125 [05:27<27:29,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 18%|█▊        | 548/3125 [05:49<27:14,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 18%|█▊        | 558/3125 [05:55<27:14,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 558/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7366076131020823 \n","Training Accuracy per last 992 samples: 41.935483870967744\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|█▉        | 620/3125 [06:35<26:34,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 620/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7285291764043993 \n","Training Accuracy per last 992 samples: 42.439516129032256\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|█▉        | 624/3125 [06:37<26:37,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 625 complete! Training Loss : 0.7328383392333985\n","Epoch 2, batch 625 complete! Training Accuracy : 0.4161\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.48it/s]\n"," 20%|██        | 625/3125 [07:17<8:32:26, 12.30s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 625 complete! Validation Loss : 1.623883126795977\n","Epoch 2, batch 625 complete! Validation Accuracy : 0.34737221022318215\n"]},{"name":"stderr","output_type":"stream","text":[" 21%|██        | 658/3125 [07:38<26:07,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 22%|██▏       | 682/3125 [07:53<25:53,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 682/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7484652919154013 \n","Training Accuracy per last 992 samples: 39.71774193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 24%|██▍       | 744/3125 [08:32<25:14,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 744/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7220353772563319 \n","Training Accuracy per last 992 samples: 42.54032258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 25%|██▍       | 774/3125 [08:51<24:56,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 26%|██▌       | 806/3125 [09:12<24:31,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 806/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7155658352759576 \n","Training Accuracy per last 992 samples: 44.25403225806452\n"]},{"name":"stderr","output_type":"stream","text":[" 28%|██▊       | 868/3125 [09:51<23:58,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 868/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7234187279978106 \n","Training Accuracy per last 992 samples: 43.145161290322584\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|██▉       | 930/3125 [10:30<23:14,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 930/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7328688406175182 \n","Training Accuracy per last 992 samples: 42.439516129032256\n"]},{"name":"stderr","output_type":"stream","text":[" 32%|███▏      | 992/3125 [11:10<22:33,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 992/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7190512687929215 \n","Training Accuracy per last 992 samples: 45.16129032258065\n"]},{"name":"stderr","output_type":"stream","text":[" 34%|███▎      | 1054/3125 [11:49<21:53,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1054/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7478212541149508 \n","Training Accuracy per last 992 samples: 42.23790322580645\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▌      | 1116/3125 [12:28<21:19,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1116/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7054605484008789 \n","Training Accuracy per last 992 samples: 45.66532258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▌      | 1132/3125 [12:38<21:04,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 37%|███▋      | 1162/3125 [12:57<20:47,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 38%|███▊      | 1178/3125 [13:08<20:39,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1178/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7164092371540685 \n","Training Accuracy per last 992 samples: 44.75806451612903\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 1240/3125 [13:47<20:00,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1240/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7417937709439185 \n","Training Accuracy per last 992 samples: 41.028225806451616\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 1249/3125 [13:53<19:51,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 1250 complete! Training Loss : 0.7300102935791015\n","Epoch 2, batch 1250 complete! Training Accuracy : 0.42335\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.47it/s]\n"," 40%|████      | 1250/3125 [14:32<6:24:41, 12.31s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 1250 complete! Validation Loss : 1.6213631465517242\n","Epoch 2, batch 1250 complete! Validation Accuracy : 0.34773218142548595\n"]},{"name":"stderr","output_type":"stream","text":[" 42%|████▏     | 1302/3125 [15:05<19:17,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1302/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7425293460969002 \n","Training Accuracy per last 992 samples: 41.733870967741936\n"]},{"name":"stderr","output_type":"stream","text":[" 44%|████▎     | 1364/3125 [15:44<18:39,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1364/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7174041501937374 \n","Training Accuracy per last 992 samples: 43.145161290322584\n"]},{"name":"stderr","output_type":"stream","text":[" 46%|████▌     | 1426/3125 [16:24<17:59,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1426/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7233656298729682 \n","Training Accuracy per last 992 samples: 43.346774193548384\n"]},{"name":"stderr","output_type":"stream","text":[" 47%|████▋     | 1457/3125 [16:43<17:33,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 48%|████▊     | 1488/3125 [17:03<17:20,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1488/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7447508535077495 \n","Training Accuracy per last 992 samples: 41.431451612903224\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|████▉     | 1550/3125 [17:43<16:39,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1550/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7349313612907163 \n","Training Accuracy per last 992 samples: 42.74193548387097\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|████▉     | 1555/3125 [17:46<16:33,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 52%|█████▏    | 1612/3125 [18:22<16:02,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1612/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7186440190961284 \n","Training Accuracy per last 992 samples: 42.54032258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 53%|█████▎    | 1671/3125 [18:59<15:21,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 54%|█████▎    | 1674/3125 [19:01<15:30,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1674/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7379371273902154 \n","Training Accuracy per last 992 samples: 40.725806451612904\n"]},{"name":"stderr","output_type":"stream","text":[" 55%|█████▌    | 1732/3125 [19:38<14:47,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 56%|█████▌    | 1736/3125 [19:41<14:47,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1736/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7235710697789346 \n","Training Accuracy per last 992 samples: 43.346774193548384\n"]},{"name":"stderr","output_type":"stream","text":[" 56%|█████▌    | 1745/3125 [19:46<14:33,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 56%|█████▌    | 1749/3125 [19:49<14:33,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 57%|█████▋    | 1783/3125 [20:11<14:07,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 58%|█████▊    | 1798/3125 [20:20<14:05,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1798/3125 of epoch 2 complete. Loss per last 992 samples:: 0.745527898111651 \n","Training Accuracy per last 992 samples: 38.70967741935484\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|█████▉    | 1860/3125 [20:59<13:25,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1860/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7340788995065997 \n","Training Accuracy per last 992 samples: 42.74193548387097\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|█████▉    | 1874/3125 [21:08<13:16,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 1875 complete! Training Loss : 0.7308152002970377\n","Epoch 2, batch 1875 complete! Training Accuracy : 0.4222666666666667\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.48it/s]\n"," 60%|██████    | 1875/3125 [21:48<4:15:56, 12.29s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 1875 complete! Validation Loss : 1.6136685075431034\n","Epoch 2, batch 1875 complete! Validation Accuracy : 0.34233261339092874\n"]},{"name":"stderr","output_type":"stream","text":[" 62%|██████▏   | 1922/3125 [22:18<12:45,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1922/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7348712182814076 \n","Training Accuracy per last 992 samples: 44.153225806451616\n"]},{"name":"stderr","output_type":"stream","text":[" 63%|██████▎   | 1984/3125 [22:57<12:06,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1984/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7113695759927073 \n","Training Accuracy per last 992 samples: 45.96774193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 64%|██████▍   | 2000/3125 [23:07<11:54,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 65%|██████▌   | 2046/3125 [23:36<11:24,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2046/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7240251725719821 \n","Training Accuracy per last 992 samples: 41.63306451612903\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 2087/3125 [24:02<10:56,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 67%|██████▋   | 2108/3125 [24:16<10:46,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2108/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7339702729255922 \n","Training Accuracy per last 992 samples: 42.74193548387097\n"]},{"name":"stderr","output_type":"stream","text":[" 69%|██████▉   | 2151/3125 [24:43<10:16,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 69%|██████▉   | 2155/3125 [24:46<10:16,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 69%|██████▉   | 2170/3125 [24:55<10:07,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2170/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7105693201864919 \n","Training Accuracy per last 992 samples: 44.556451612903224\n"]},{"name":"stderr","output_type":"stream","text":[" 71%|███████▏  | 2232/3125 [25:35<09:28,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2232/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7312626069591891 \n","Training Accuracy per last 992 samples: 42.439516129032256\n"]},{"name":"stderr","output_type":"stream","text":[" 73%|███████▎  | 2275/3125 [26:02<08:58,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 73%|███████▎  | 2294/3125 [26:14<08:48,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2294/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7303098555534117 \n","Training Accuracy per last 992 samples: 42.03629032258065\n"]},{"name":"stderr","output_type":"stream","text":[" 75%|███████▌  | 2356/3125 [26:53<08:08,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2356/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7111959611215899 \n","Training Accuracy per last 992 samples: 42.943548387096776\n"]},{"name":"stderr","output_type":"stream","text":[" 77%|███████▋  | 2418/3125 [27:33<07:29,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2418/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7389088907549458 \n","Training Accuracy per last 992 samples: 40.524193548387096\n"]},{"name":"stderr","output_type":"stream","text":[" 79%|███████▉  | 2480/3125 [28:12<06:49,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2480/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7104197932827857 \n","Training Accuracy per last 992 samples: 43.54838709677419\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|███████▉  | 2499/3125 [28:24<06:35,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 2500 complete! Training Loss : 0.7289873950958252\n","Epoch 2, batch 2500 complete! Training Accuracy : 0.4242\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.48it/s]\n"," 80%|████████  | 2500/3125 [29:03<2:07:58, 12.29s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 2500 complete! Validation Loss : 1.6223172593390804\n","Epoch 2, batch 2500 complete! Validation Accuracy : 0.3513318934485241\n"]},{"name":"stderr","output_type":"stream","text":[" 81%|████████  | 2532/3125 [29:24<06:17,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 81%|████████▏ | 2542/3125 [29:30<06:12,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2542/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7230786969584804 \n","Training Accuracy per last 992 samples: 41.431451612903224\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 2599/3125 [30:07<05:39,  1.55it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 83%|████████▎ | 2604/3125 [30:10<05:35,  1.55it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2604/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7140776572688934 \n","Training Accuracy per last 992 samples: 44.556451612903224\n"]},{"name":"stderr","output_type":"stream","text":[" 84%|████████▎ | 2616/3125 [30:18<05:39,  1.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 85%|████████▌ | 2666/3125 [30:50<04:51,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2666/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7248784342119771 \n","Training Accuracy per last 992 samples: 42.23790322580645\n"]},{"name":"stderr","output_type":"stream","text":[" 86%|████████▌ | 2679/3125 [30:59<04:41,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 87%|████████▋ | 2728/3125 [31:30<04:11,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2728/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7321410948230375 \n","Training Accuracy per last 992 samples: 42.13709677419355\n"]},{"name":"stderr","output_type":"stream","text":[" 88%|████████▊ | 2741/3125 [31:39<04:29,  1.42it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 89%|████████▉ | 2777/3125 [32:02<03:39,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 89%|████████▉ | 2790/3125 [32:10<03:33,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2790/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7106773622574345 \n","Training Accuracy per last 992 samples: 44.25403225806452\n"]},{"name":"stderr","output_type":"stream","text":[" 91%|█████████▏| 2852/3125 [32:49<02:53,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2852/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7182660718117991 \n","Training Accuracy per last 992 samples: 42.943548387096776\n"]},{"name":"stderr","output_type":"stream","text":[" 91%|█████████▏| 2855/3125 [32:51<02:51,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 92%|█████████▏| 2885/3125 [33:10<02:32,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 93%|█████████▎| 2902/3125 [33:21<02:22,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 93%|█████████▎| 2914/3125 [33:29<02:14,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2914/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7302676631558326 \n","Training Accuracy per last 992 samples: 41.431451612903224\n"]},{"name":"stderr","output_type":"stream","text":[" 95%|█████████▌| 2976/3125 [34:08<01:34,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2976/3125 of epoch 2 complete. Loss per last 992 samples:: 0.7303770742108745 \n","Training Accuracy per last 992 samples: 41.12903225806452\n"]},{"name":"stderr","output_type":"stream","text":[" 97%|█████████▋| 3038/3125 [34:47<00:55,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 3038/3125 of epoch 2 complete. Loss per last 992 samples:: 0.720366693312122 \n","Training Accuracy per last 992 samples: 43.649193548387096\n"]},{"name":"stderr","output_type":"stream","text":[" 99%|█████████▉| 3100/3125 [35:27<00:15,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 3100/3125 of epoch 2 complete. Loss per last 992 samples:: 0.748045152233493 \n","Training Accuracy per last 992 samples: 40.524193548387096\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 3111/3125 [35:34<00:08,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","100%|█████████▉| 3124/3125 [35:42<00:00,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 3125 complete! Training Loss : 0.728048815612793\n","Epoch 2, batch 3125 complete! Training Accuracy : 0.42457888208698435\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.48it/s]\n","100%|██████████| 3125/3125 [36:21<00:00,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 3125 complete! Validation Loss : 1.6145861395474137\n","Epoch 2, batch 3125 complete! Validation Accuracy : 0.35025197984161266\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 27/3125 [00:17<32:43,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  2%|▏         | 56/3125 [00:35<32:42,  1.56it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  2%|▏         | 62/3125 [00:39<32:37,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 62/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7061862330282888 \n","Training Accuracy per last 992 samples: 44.65725806451613\n"]},{"name":"stderr","output_type":"stream","text":["  3%|▎         | 106/3125 [01:07<31:56,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  4%|▍         | 124/3125 [01:18<31:49,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 124/3125 of epoch 3 complete. Loss per last 992 samples:: 0.6999043187787456 \n","Training Accuracy per last 992 samples: 43.54838709677419\n"]},{"name":"stderr","output_type":"stream","text":["  5%|▌         | 165/3125 [01:44<31:13,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  5%|▌         | 170/3125 [01:48<31:32,  1.56it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  6%|▌         | 186/3125 [01:58<31:12,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 186/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7184882625456779 \n","Training Accuracy per last 992 samples: 41.83467741935484\n"]},{"name":"stderr","output_type":"stream","text":["  7%|▋         | 229/3125 [02:25<30:34,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  8%|▊         | 248/3125 [02:37<30:06,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 248/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7161491917025659 \n","Training Accuracy per last 992 samples: 43.850806451612904\n"]},{"name":"stderr","output_type":"stream","text":["  9%|▉         | 276/3125 [02:55<30:10,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 10%|▉         | 310/3125 [03:17<29:49,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 310/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7203068733215332 \n","Training Accuracy per last 992 samples: 44.75806451612903\n"]},{"name":"stderr","output_type":"stream","text":[" 12%|█▏        | 372/3125 [03:56<29:10,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 372/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7011250219037456 \n","Training Accuracy per last 992 samples: 46.068548387096776\n"]},{"name":"stderr","output_type":"stream","text":[" 13%|█▎        | 397/3125 [04:12<28:43,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 13%|█▎        | 402/3125 [04:15<29:01,  1.56it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 14%|█▍        | 434/3125 [04:35<28:27,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 434/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7118570881505166 \n","Training Accuracy per last 992 samples: 43.75\n"]},{"name":"stderr","output_type":"stream","text":[" 14%|█▍        | 443/3125 [04:41<28:22,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 16%|█▌        | 496/3125 [05:15<27:53,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 496/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7097242109237178 \n","Training Accuracy per last 992 samples: 44.65725806451613\n"]},{"name":"stderr","output_type":"stream","text":[" 18%|█▊        | 558/3125 [05:54<27:15,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 558/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7105631366852792 \n","Training Accuracy per last 992 samples: 43.24596774193548\n"]},{"name":"stderr","output_type":"stream","text":[" 19%|█▉        | 589/3125 [06:14<26:46,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 20%|█▉        | 620/3125 [06:34<26:32,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 620/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7070591834283644 \n","Training Accuracy per last 992 samples: 46.068548387096776\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|█▉        | 624/3125 [06:36<26:41,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 625 complete! Training Loss : 0.7096828918457031\n","Epoch 3, batch 625 complete! Training Accuracy : 0.4431\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.48it/s]\n"," 20%|██        | 625/3125 [07:16<8:31:58, 12.29s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 625 complete! Validation Loss : 1.6301914960488506\n","Epoch 3, batch 625 complete! Validation Accuracy : 0.3419726421886249\n"]},{"name":"stderr","output_type":"stream","text":[" 22%|██▏       | 682/3125 [07:52<25:55,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 682/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7134603838766774 \n","Training Accuracy per last 992 samples: 42.54032258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 23%|██▎       | 734/3125 [08:26<25:16,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 24%|██▍       | 744/3125 [08:32<25:14,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 744/3125 of epoch 3 complete. Loss per last 992 samples:: 0.7168877201695596 \n","Training Accuracy per last 992 samples: 43.850806451612904\n"]},{"name":"stderr","output_type":"stream","text":[" 26%|██▌       | 806/3125 [09:13<24:55,  1.55it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 806/3125 of epoch 3 complete. Loss per last 992 samples:: 0.6960253715515137 \n","Training Accuracy per last 992 samples: 46.068548387096776\n"]},{"name":"stderr","output_type":"stream","text":[" 26%|██▋       | 828/3125 [09:27<24:48,  1.54it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 28%|██▊       | 867/3125 [09:53<24:04,  1.56it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 28%|██▊       | 868/3125 [09:53<24:13,  1.55it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 868/3125 of epoch 3 complete. Loss per last 992 samples:: 0.6915907090710055 \n","Training Accuracy per last 992 samples: 44.65725806451613\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|██▉       | 930/3125 [10:34<24:06,  1.52it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 930/3125 of epoch 3 complete. Loss per last 992 samples:: 0.6904686189466908 \n","Training Accuracy per last 992 samples: 46.37096774193548\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|███       | 945/3125 [10:43<23:10,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 32%|███▏      | 992/3125 [11:13<22:33,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 992/3125 of epoch 3 complete. Loss per last 992 samples:: 0.712004953815091 \n","Training Accuracy per last 992 samples: 44.65725806451613\n"]},{"name":"stderr","output_type":"stream","text":[" 34%|███▎      | 1054/3125 [11:53<23:24,  1.47it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1054/3125 of epoch 3 complete. Loss per last 992 samples:: 0.707031003890499 \n","Training Accuracy per last 992 samples: 45.96774193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 35%|███▌      | 1104/3125 [12:28<22:50,  1.48it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_322793/241346441.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_constant_schedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopti\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_bert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopti\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miters_to_accumulate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_322793/819859485.py\u001b[0m in \u001b[0;36mtrain_bert\u001b[0;34m(net, criterion, opti, lr, lr_scheduler, train_loader, val_loader, epochs, iters_to_accumulate)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# Backpropagating the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m# Scales loss.  Calls backward() on scaled loss to create scaled gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0miters_to_accumulate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/nn/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/nn/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["LEARNING_RATE = 2e-6\n","opti = AdamW(net.parameters(), lr=LEARNING_RATE, weight_decay=1e-2)\n","num_warmup_steps = 0 # The number of steps for the warmup phase.\n","iters_to_accumulate = 2\n","num_training_steps = EPOCHS * len(train_loader)  # The total number of training steps\n","t_total = (len(train_loader) // iters_to_accumulate) * EPOCHS  # Necessary to take into account Gradient accumulation\n","#lr_scheduler = get_linear_schedule_with_warmup(optimizer=opti, num_warmup_steps=num_warmup_steps, num_training_steps=t_total)\n","lr_scheduler = get_constant_schedule(optimizer=opti)\n","\n","train_bert(net, criterion, opti, LEARNING_RATE, lr_scheduler, train_loader, val_loader, EPOCHS, iters_to_accumulate)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  2%|▏         | 62/3125 [00:43<35:30,  1.44it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 62/3125 of epoch 1 complete. Loss per last 992 samples:: 0.6214367189714985 \n","Training Accuracy per last 992 samples: 54.83870967741935\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 124/3125 [01:27<35:22,  1.41it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 124/3125 of epoch 1 complete. Loss per last 992 samples:: 0.6185389334155668 \n","Training Accuracy per last 992 samples: 55.04032258064516\n"]},{"name":"stderr","output_type":"stream","text":["  5%|▌         | 164/3125 [01:55<34:49,  1.42it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  6%|▌         | 186/3125 [02:10<34:12,  1.43it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 186/3125 of epoch 1 complete. Loss per last 992 samples:: 0.6090505276956866 \n","Training Accuracy per last 992 samples: 52.82258064516129\n"]},{"name":"stderr","output_type":"stream","text":["  7%|▋         | 204/3125 [02:23<32:19,  1.51it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  8%|▊         | 248/3125 [02:53<33:39,  1.42it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 248/3125 of epoch 1 complete. Loss per last 992 samples:: 0.5911861696550923 \n","Training Accuracy per last 992 samples: 55.645161290322584\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 257/3125 [02:59<31:54,  1.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  8%|▊         | 258/3125 [03:00<32:25,  1.47it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  9%|▉         | 294/3125 [03:25<33:32,  1.41it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 10%|▉         | 310/3125 [03:36<32:29,  1.44it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 310/3125 of epoch 1 complete. Loss per last 992 samples:: 0.6034306018583236 \n","Training Accuracy per last 992 samples: 53.62903225806452\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|▉         | 312/3125 [03:37<32:35,  1.44it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 11%|█         | 330/3125 [03:50<33:06,  1.41it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 12%|█▏        | 372/3125 [04:17<29:09,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 372/3125 of epoch 1 complete. Loss per last 992 samples:: 0.6131325844795473 \n","Training Accuracy per last 992 samples: 52.318548387096776\n"]},{"name":"stderr","output_type":"stream","text":[" 14%|█▍        | 434/3125 [04:57<28:46,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 434/3125 of epoch 1 complete. Loss per last 992 samples:: 0.5761086017854752 \n","Training Accuracy per last 992 samples: 56.653225806451616\n"]},{"name":"stderr","output_type":"stream","text":[" 16%|█▌        | 496/3125 [05:37<27:45,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 496/3125 of epoch 1 complete. Loss per last 992 samples:: 0.5857461037174347 \n","Training Accuracy per last 992 samples: 55.141129032258064\n"]},{"name":"stderr","output_type":"stream","text":[" 18%|█▊        | 558/3125 [06:17<27:13,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 558/3125 of epoch 1 complete. Loss per last 992 samples:: 0.5733816085323211 \n","Training Accuracy per last 992 samples: 56.75403225806452\n"]},{"name":"stderr","output_type":"stream","text":[" 18%|█▊        | 566/3125 [06:22<27:07,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 20%|█▉        | 620/3125 [06:56<26:31,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 620/3125 of epoch 1 complete. Loss per last 992 samples:: 0.6052008598081527 \n","Training Accuracy per last 992 samples: 55.141129032258064\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|█▉        | 624/3125 [06:58<26:39,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 625 complete! Training Loss : 0.5993100273132325\n","Epoch 1, batch 625 complete! Training Accuracy : 0.5486\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 625 complete! Validation Loss : 1.6871941226652298\n","Epoch 1, batch 625 complete! Validation Accuracy : 0.3488120950323974\n","Validation loss changed from inf to 1.6871941226652298\n","Best validation accuracy improved from 0 to 0.3488120950323974\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 625/3125 [07:39<8:41:15, 12.51s/it]"]},{"name":"stdout","output_type":"stream","text":["The model has been saved in models/Sun Nov 14 22:34:56 2021_lr_2e-06_val_acc_0.3488_ep_1.pt\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 629/3125 [07:41<2:25:01,  3.49s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 22%|██▏       | 682/3125 [08:15<25:51,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 682/3125 of epoch 1 complete. Loss per last 992 samples:: 0.5940260502599901 \n","Training Accuracy per last 992 samples: 54.33467741935484\n"]},{"name":"stderr","output_type":"stream","text":[" 24%|██▍       | 744/3125 [08:54<25:16,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 744/3125 of epoch 1 complete. Loss per last 992 samples:: 0.5825750058697116 \n","Training Accuracy per last 992 samples: 56.45161290322581\n"]},{"name":"stderr","output_type":"stream","text":[" 26%|██▌       | 806/3125 [09:33<24:30,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 806/3125 of epoch 1 complete. Loss per last 992 samples:: 0.5911016079687303 \n","Training Accuracy per last 992 samples: 55.74596774193548\n"]},{"name":"stderr","output_type":"stream","text":[" 27%|██▋       | 842/3125 [09:56<24:10,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 28%|██▊       | 868/3125 [10:12<23:49,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 868/3125 of epoch 1 complete. Loss per last 992 samples:: 0.5730136440646264 \n","Training Accuracy per last 992 samples: 56.653225806451616\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|██▉       | 930/3125 [10:52<23:10,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 930/3125 of epoch 1 complete. Loss per last 992 samples:: 0.5690419673919678 \n","Training Accuracy per last 992 samples: 58.266129032258064\n"]},{"name":"stderr","output_type":"stream","text":[" 32%|███▏      | 985/3125 [11:26<22:32,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 32%|███▏      | 992/3125 [11:31<22:38,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 992/3125 of epoch 1 complete. Loss per last 992 samples:: 0.5751503513705346 \n","Training Accuracy per last 992 samples: 58.36693548387097\n"]},{"name":"stderr","output_type":"stream","text":[" 33%|███▎      | 1023/3125 [11:51<22:06,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 34%|███▎      | 1050/3125 [12:08<21:59,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 34%|███▎      | 1054/3125 [12:10<22:01,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1054/3125 of epoch 1 complete. Loss per last 992 samples:: 0.5644834041595459 \n","Training Accuracy per last 992 samples: 58.87096774193548\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▌      | 1116/3125 [12:49<21:15,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1116/3125 of epoch 1 complete. Loss per last 992 samples:: 0.528858527060478 \n","Training Accuracy per last 992 samples: 62.096774193548384\n"]},{"name":"stderr","output_type":"stream","text":[" 38%|███▊      | 1178/3125 [13:29<20:40,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1178/3125 of epoch 1 complete. Loss per last 992 samples:: 0.5588470197493031 \n","Training Accuracy per last 992 samples: 59.375\n"]},{"name":"stderr","output_type":"stream","text":[" 38%|███▊      | 1197/3125 [13:41<20:14,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 40%|███▉      | 1240/3125 [14:08<19:56,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1240/3125 of epoch 1 complete. Loss per last 992 samples:: 0.5283479229096444 \n","Training Accuracy per last 992 samples: 60.78629032258065\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 1249/3125 [14:14<19:43,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 1250 complete! Training Loss : 0.5828206815719604\n","Epoch 1, batch 1250 complete! Training Accuracy : 0.5643\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.47it/s]\n"," 40%|████      | 1250/3125 [14:53<6:24:51, 12.32s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 1250 complete! Validation Loss : 1.7221960308908046\n","Epoch 1, batch 1250 complete! Validation Accuracy : 0.3484521238300936\n"]},{"name":"stderr","output_type":"stream","text":[" 42%|████▏     | 1302/3125 [15:26<19:16,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1302/3125 of epoch 1 complete. Loss per last 992 samples:: 0.5154892090828188 \n","Training Accuracy per last 992 samples: 62.096774193548384\n"]},{"name":"stderr","output_type":"stream","text":[" 44%|████▎     | 1364/3125 [16:06<18:37,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1364/3125 of epoch 1 complete. Loss per last 992 samples:: 0.5110480785369873 \n","Training Accuracy per last 992 samples: 62.80241935483871\n"]},{"name":"stderr","output_type":"stream","text":[" 44%|████▍     | 1368/3125 [16:08<18:41,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 46%|████▌     | 1426/3125 [16:45<18:03,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1426/3125 of epoch 1 complete. Loss per last 992 samples:: 0.5246500430568573 \n","Training Accuracy per last 992 samples: 60.98790322580645\n"]},{"name":"stderr","output_type":"stream","text":[" 48%|████▊     | 1488/3125 [17:24<17:17,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1488/3125 of epoch 1 complete. Loss per last 992 samples:: 0.4934180628868841 \n","Training Accuracy per last 992 samples: 65.42338709677419\n"]},{"name":"stderr","output_type":"stream","text":[" 48%|████▊     | 1513/3125 [17:40<16:56,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 49%|████▉     | 1544/3125 [18:00<16:44,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 50%|████▉     | 1550/3125 [18:04<16:44,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1550/3125 of epoch 1 complete. Loss per last 992 samples:: 0.4998467968356225 \n","Training Accuracy per last 992 samples: 63.50806451612903\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 1569/3125 [18:16<16:18,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 52%|█████▏    | 1612/3125 [18:43<16:00,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1612/3125 of epoch 1 complete. Loss per last 992 samples:: 0.5188684309682539 \n","Training Accuracy per last 992 samples: 60.38306451612903\n"]},{"name":"stderr","output_type":"stream","text":[" 54%|█████▎    | 1674/3125 [19:22<15:18,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1674/3125 of epoch 1 complete. Loss per last 992 samples:: 0.4888909016886065 \n","Training Accuracy per last 992 samples: 64.61693548387096\n"]},{"name":"stderr","output_type":"stream","text":[" 56%|█████▌    | 1736/3125 [20:01<14:39,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1736/3125 of epoch 1 complete. Loss per last 992 samples:: 0.4955076786779588 \n","Training Accuracy per last 992 samples: 63.70967741935484\n"]},{"name":"stderr","output_type":"stream","text":[" 57%|█████▋    | 1786/3125 [20:33<14:09,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 58%|█████▊    | 1798/3125 [20:41<14:01,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1798/3125 of epoch 1 complete. Loss per last 992 samples:: 0.4795080154172836 \n","Training Accuracy per last 992 samples: 65.82661290322581\n"]},{"name":"stderr","output_type":"stream","text":[" 59%|█████▉    | 1856/3125 [21:17<13:25,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 60%|█████▉    | 1860/3125 [21:20<13:26,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1860/3125 of epoch 1 complete. Loss per last 992 samples:: 0.48986785642562375 \n","Training Accuracy per last 992 samples: 65.5241935483871\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|█████▉    | 1874/3125 [21:29<13:16,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 1875 complete! Training Loss : 0.5553137950897217\n","Epoch 1, batch 1875 complete! Training Accuracy : 0.5886\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.47it/s]\n"," 60%|██████    | 1875/3125 [22:08<4:16:26, 12.31s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 1875 complete! Validation Loss : 1.7712795213721264\n","Epoch 1, batch 1875 complete! Validation Accuracy : 0.3466522678185745\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 1888/3125 [22:17<15:25,  1.34it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 61%|██████    | 1902/3125 [22:26<12:55,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 62%|██████▏   | 1922/3125 [22:38<12:46,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1922/3125 of epoch 1 complete. Loss per last 992 samples:: 0.4492277560695525 \n","Training Accuracy per last 992 samples: 69.15322580645162\n"]},{"name":"stderr","output_type":"stream","text":[" 63%|██████▎   | 1963/3125 [23:04<12:13,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 63%|██████▎   | 1984/3125 [23:18<12:06,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1984/3125 of epoch 1 complete. Loss per last 992 samples:: 0.4765874878052742 \n","Training Accuracy per last 992 samples: 66.53225806451613\n"]},{"name":"stderr","output_type":"stream","text":[" 65%|██████▌   | 2046/3125 [23:57<11:23,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2046/3125 of epoch 1 complete. Loss per last 992 samples:: 0.48298352764498803 \n","Training Accuracy per last 992 samples: 64.91935483870968\n"]},{"name":"stderr","output_type":"stream","text":[" 66%|██████▌   | 2055/3125 [24:02<11:14,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 67%|██████▋   | 2108/3125 [24:36<10:43,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2108/3125 of epoch 1 complete. Loss per last 992 samples:: 0.47178030014038086 \n","Training Accuracy per last 992 samples: 65.3225806451613\n"]},{"name":"stderr","output_type":"stream","text":[" 69%|██████▉   | 2151/3125 [25:03<10:16,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 69%|██████▉   | 2170/3125 [25:15<10:05,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2170/3125 of epoch 1 complete. Loss per last 992 samples:: 0.42337943661597466 \n","Training Accuracy per last 992 samples: 69.65725806451613\n"]},{"name":"stderr","output_type":"stream","text":[" 70%|███████   | 2193/3125 [25:30<09:49,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 71%|███████▏  | 2232/3125 [25:55<09:25,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2232/3125 of epoch 1 complete. Loss per last 992 samples:: 0.42610583766814203 \n","Training Accuracy per last 992 samples: 70.96774193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 73%|███████▎  | 2290/3125 [26:31<08:48,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 73%|███████▎  | 2294/3125 [26:34<08:52,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2294/3125 of epoch 1 complete. Loss per last 992 samples:: 0.4800132551500874 \n","Training Accuracy per last 992 samples: 67.33870967741936\n"]},{"name":"stderr","output_type":"stream","text":[" 75%|███████▌  | 2348/3125 [27:08<08:13,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 75%|███████▌  | 2356/3125 [27:13<08:08,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2356/3125 of epoch 1 complete. Loss per last 992 samples:: 0.44249872622951386 \n","Training Accuracy per last 992 samples: 68.95161290322581\n"]},{"name":"stderr","output_type":"stream","text":[" 76%|███████▌  | 2364/3125 [27:18<08:03,  1.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 77%|███████▋  | 2418/3125 [27:52<07:28,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2418/3125 of epoch 1 complete. Loss per last 992 samples:: 0.4402955501310287 \n","Training Accuracy per last 992 samples: 68.24596774193549\n"]},{"name":"stderr","output_type":"stream","text":[" 79%|███████▉  | 2480/3125 [28:32<06:50,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2480/3125 of epoch 1 complete. Loss per last 992 samples:: 0.4529415561306861 \n","Training Accuracy per last 992 samples: 67.03629032258064\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|███████▉  | 2499/3125 [28:44<06:34,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 2500 complete! Training Loss : 0.5297765692710876\n","Epoch 1, batch 2500 complete! Training Accuracy : 0.611325\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.46it/s]\n"," 80%|████████  | 2500/3125 [29:23<2:08:24, 12.33s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 2500 complete! Validation Loss : 1.8111642420977012\n","Epoch 1, batch 2500 complete! Validation Accuracy : 0.3466522678185745\n"]},{"name":"stderr","output_type":"stream","text":[" 81%|████████▏ | 2542/3125 [29:50<06:09,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2542/3125 of epoch 1 complete. Loss per last 992 samples:: 0.4373557759869483 \n","Training Accuracy per last 992 samples: 69.45564516129032\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 2587/3125 [30:19<05:46,  1.55it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 83%|████████▎ | 2604/3125 [30:31<05:57,  1.46it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2604/3125 of epoch 1 complete. Loss per last 992 samples:: 0.42626028291640744 \n","Training Accuracy per last 992 samples: 69.15322580645162\n"]},{"name":"stderr","output_type":"stream","text":[" 85%|████████▌ | 2666/3125 [31:11<04:50,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2666/3125 of epoch 1 complete. Loss per last 992 samples:: 0.42907781754770585 \n","Training Accuracy per last 992 samples: 70.06048387096774\n"]},{"name":"stderr","output_type":"stream","text":[" 86%|████████▌ | 2687/3125 [31:24<04:36,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 87%|████████▋ | 2728/3125 [31:51<04:33,  1.45it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2728/3125 of epoch 1 complete. Loss per last 992 samples:: 0.42968591567008724 \n","Training Accuracy per last 992 samples: 69.0524193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 87%|████████▋ | 2734/3125 [31:55<04:42,  1.38it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 89%|████████▉ | 2790/3125 [32:35<04:00,  1.40it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2790/3125 of epoch 1 complete. Loss per last 992 samples:: 0.4295997773447344 \n","Training Accuracy per last 992 samples: 69.45564516129032\n"]},{"name":"stderr","output_type":"stream","text":[" 91%|█████████▏| 2852/3125 [33:17<03:14,  1.40it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2852/3125 of epoch 1 complete. Loss per last 992 samples:: 0.40889857661339546 \n","Training Accuracy per last 992 samples: 72.27822580645162\n"]},{"name":"stderr","output_type":"stream","text":[" 93%|█████████▎| 2914/3125 [33:58<02:13,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2914/3125 of epoch 1 complete. Loss per last 992 samples:: 0.4280027574108493 \n","Training Accuracy per last 992 samples: 68.6491935483871\n"]},{"name":"stderr","output_type":"stream","text":[" 95%|█████████▌| 2976/3125 [34:37<01:34,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 2976/3125 of epoch 1 complete. Loss per last 992 samples:: 0.3959941364103748 \n","Training Accuracy per last 992 samples: 72.78225806451613\n"]},{"name":"stderr","output_type":"stream","text":[" 96%|█████████▌| 3007/3125 [34:57<01:14,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 97%|█████████▋| 3038/3125 [35:17<00:55,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 3038/3125 of epoch 1 complete. Loss per last 992 samples:: 0.39719551224862376 \n","Training Accuracy per last 992 samples: 72.37903225806451\n"]},{"name":"stderr","output_type":"stream","text":[" 98%|█████████▊| 3073/3125 [35:39<00:32,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 99%|█████████▊| 3081/3125 [35:44<00:27,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 99%|█████████▉| 3100/3125 [35:56<00:15,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 3100/3125 of epoch 1 complete. Loss per last 992 samples:: 0.3843638435486824 \n","Training Accuracy per last 992 samples: 72.98387096774194\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 3124/3125 [36:11<00:00,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 3125 complete! Training Loss : 0.5068772456359864\n","Epoch 1, batch 3125 complete! Training Accuracy : 0.6303164886168127\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:39<00:00,  4.46it/s]\n","100%|██████████| 3125/3125 [36:50<00:00,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 3125 complete! Validation Loss : 1.856335870150862\n","Epoch 1, batch 3125 complete! Validation Accuracy : 0.34485241180705545\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 62/3125 [00:39<32:29,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 62/3125 of epoch 2 complete. Loss per last 992 samples:: 0.4020694032792122 \n","Training Accuracy per last 992 samples: 72.27822580645162\n"]},{"name":"stderr","output_type":"stream","text":["  3%|▎         | 81/3125 [00:51<31:59,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  4%|▍         | 124/3125 [01:18<31:50,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 124/3125 of epoch 2 complete. Loss per last 992 samples:: 0.41774459423557403 \n","Training Accuracy per last 992 samples: 69.85887096774194\n"]},{"name":"stderr","output_type":"stream","text":["  6%|▌         | 186/3125 [01:57<31:06,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 186/3125 of epoch 2 complete. Loss per last 992 samples:: 0.40032361399742866 \n","Training Accuracy per last 992 samples: 71.06854838709677\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 248/3125 [02:37<30:25,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 248/3125 of epoch 2 complete. Loss per last 992 samples:: 0.41647063147637153 \n","Training Accuracy per last 992 samples: 72.27822580645162\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|▉         | 310/3125 [03:16<29:43,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 310/3125 of epoch 2 complete. Loss per last 992 samples:: 0.3558226554624496 \n","Training Accuracy per last 992 samples: 76.61290322580645\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|█         | 317/3125 [03:20<29:33,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 12%|█▏        | 372/3125 [03:55<29:02,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 372/3125 of epoch 2 complete. Loss per last 992 samples:: 0.3741429774991928 \n","Training Accuracy per last 992 samples: 74.59677419354838\n"]},{"name":"stderr","output_type":"stream","text":[" 14%|█▍        | 434/3125 [04:34<28:30,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 434/3125 of epoch 2 complete. Loss per last 992 samples:: 0.3682494701877717 \n","Training Accuracy per last 992 samples: 76.31048387096774\n"]},{"name":"stderr","output_type":"stream","text":[" 15%|█▍        | 454/3125 [04:47<28:14,  1.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 16%|█▌        | 496/3125 [05:13<27:45,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 496/3125 of epoch 2 complete. Loss per last 992 samples:: 0.372306393038842 \n","Training Accuracy per last 992 samples: 75.3024193548387\n"]},{"name":"stderr","output_type":"stream","text":[" 18%|█▊        | 558/3125 [05:53<27:02,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 558/3125 of epoch 2 complete. Loss per last 992 samples:: 0.37744210996935446 \n","Training Accuracy per last 992 samples: 74.29435483870968\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|█▉        | 620/3125 [06:32<26:27,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 620/3125 of epoch 2 complete. Loss per last 992 samples:: 0.37759902400355183 \n","Training Accuracy per last 992 samples: 74.8991935483871\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|█▉        | 624/3125 [06:34<26:26,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 625 complete! Training Loss : 0.38613200912475587\n","Epoch 2, batch 625 complete! Training Accuracy : 0.7375\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.46it/s]\n"," 20%|██        | 625/3125 [07:14<8:33:39, 12.33s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 625 complete! Validation Loss : 1.8939840382543103\n","Epoch 2, batch 625 complete! Validation Accuracy : 0.34521238300935925\n"]},{"name":"stderr","output_type":"stream","text":[" 22%|██▏       | 682/3125 [07:50<25:48,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 682/3125 of epoch 2 complete. Loss per last 992 samples:: 0.3619112276261853 \n","Training Accuracy per last 992 samples: 76.31048387096774\n"]},{"name":"stderr","output_type":"stream","text":[" 22%|██▏       | 695/3125 [07:58<25:29,  1.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 24%|██▍       | 744/3125 [08:30<25:51,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 744/3125 of epoch 2 complete. Loss per last 992 samples:: 0.37762102965385685 \n","Training Accuracy per last 992 samples: 73.99193548387096\n"]},{"name":"stderr","output_type":"stream","text":[" 26%|██▌       | 806/3125 [09:11<25:19,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 806/3125 of epoch 2 complete. Loss per last 992 samples:: 0.37970111831541986 \n","Training Accuracy per last 992 samples: 73.99193548387096\n"]},{"name":"stderr","output_type":"stream","text":[" 27%|██▋       | 850/3125 [09:39<25:52,  1.47it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n","\u001b[0;32m/tmp/ipykernel_315575/241346441.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[1;32m      8\u001b[0m \u001b[0mlr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_constant_schedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopti\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_bert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopti\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miters_to_accumulate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_315575/819859485.py\u001b[0m in \u001b[0;36mtrain_bert\u001b[0;34m(net, criterion, opti, lr, lr_scheduler, train_loader, val_loader, epochs, iters_to_accumulate)\u001b[0m\n","\u001b[1;32m     47\u001b[0m             \u001b[0;31m# Backpropagating the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[1;32m     48\u001b[0m             \u001b[0;31m# Scales loss.  Calls backward() on scaled loss to create scaled gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[1;32m     51\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0miters_to_accumulate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\n","\u001b[0;32m~/anaconda3/envs/nn/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n","\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n","\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\n","\u001b[0;32m~/anaconda3/envs/nn/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n","\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n","\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n","\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["LEARNING_RATE = 2e-6\n","opti = AdamW(net.parameters(), lr=LEARNING_RATE, weight_decay=1e-2)\n","num_warmup_steps = 0 # The number of steps for the warmup phase.\n","iters_to_accumulate = 2\n","num_training_steps = EPOCHS * len(train_loader)  # The total number of training steps\n","t_total = (len(train_loader) // iters_to_accumulate) * EPOCHS  # Necessary to take into account Gradient accumulation\n","#lr_scheduler = get_linear_schedule_with_warmup(optimizer=opti, num_warmup_steps=num_warmup_steps, num_training_steps=t_total)\n","lr_scheduler = get_constant_schedule(optimizer=opti)\n","\n","train_bert(net, criterion, opti, LEARNING_RATE, lr_scheduler, train_loader, val_loader, EPOCHS, iters_to_accumulate)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["{'input_ids': [0, 31414, 232, 2], 'attention_mask': [1, 1, 1, 1]}"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer(\"Hello world\")"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["torch.save(net.state_dict(), 'models/final_model.pt')"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":[" 37%|███▋      | 71/193 [00:16<00:27,  4.43it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","100%|██████████| 193/193 [00:43<00:00,  4.41it/s]\n"]}],"source":["test_set = FriendsDataset(dataframe=df_test, tokenizer=tokenizer, max_length=MAX_LEN)\n","test_loader = DataLoader(test_set, batch_size=VALID_BATCH_SIZE, shuffle=False, num_workers=1)\n","def predict(net, device, dataloader):\n","    net.eval()\n","    predictions = []\n","\n","    with torch.no_grad():\n","        for it, (seq, attn_masks, token_type_ids) in enumerate(tqdm(dataloader)):\n","            seq, attn_masks, token_type_ids = \\\n","                seq.to(device), attn_masks.to(device), token_type_ids.to(device)\n","            logits = net(seq, attn_masks, token_type_ids)\n","            max_logits, argmax_idx = torch.max(logits.data, dim=1)\n","            predictions.extend(argmax_idx.tolist())\n","    del logits\n","    return predictions\n","preds = predict(net, device, test_loader)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>other_speaker</th>\n","      <th>friend_response</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Но я безработный, моя музыка - это все, что у ...</td>\n","      <td>Меня застрелят. Любой совет?</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Посмотри. Пятьсот семнадцать коробок!</td>\n","      <td>Боже мой, как ты это сделал?</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Хорошо. Хорошо. Помогло бы, если бы я подошел ...</td>\n","      <td>Это было бы очень полезно!</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Росс, чего ты так долго?</td>\n","      <td>Простите, это как будто не для быстрого отдыха!</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Так кто ты?</td>\n","      <td>Ну, наши имена действительно Моника и Чендлер....</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3081</th>\n","      <td>3081</td>\n","      <td>Дело не только в барабанах. Каждые пять минут ...</td>\n","      <td>Понимаете, именно так нормальные люди должны р...</td>\n","    </tr>\n","    <tr>\n","      <th>3082</th>\n","      <td>3082</td>\n","      <td>Кажется, я случайно использовал коробки Моники...</td>\n","      <td>Боже, все испорчено! Папа, она будет раздавлена!</td>\n","    </tr>\n","    <tr>\n","      <th>3083</th>\n","      <td>3083</td>\n","      <td>ну знаете, вот почему через несколько лет расп...</td>\n","      <td>Ой, это так здорово.</td>\n","    </tr>\n","    <tr>\n","      <th>3084</th>\n","      <td>3084</td>\n","      <td>Он переспал с тобой, а потом никогда тебе не з...</td>\n","      <td>А я просто хотела нового папу для Дэви и Бекки.</td>\n","    </tr>\n","    <tr>\n","      <th>3085</th>\n","      <td>3085</td>\n","      <td>Я знаю, разве он не классный? Так приятно нако...</td>\n","      <td>Ну, может он скоро уедет, как в классную поезд...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3086 rows × 3 columns</p>\n","</div>"],"text/plain":["        Id                                      other_speaker  \\\n","0        0  Но я безработный, моя музыка - это все, что у ...   \n","1        1              Посмотри. Пятьсот семнадцать коробок!   \n","2        2  Хорошо. Хорошо. Помогло бы, если бы я подошел ...   \n","3        3                           Росс, чего ты так долго?   \n","4        4                                        Так кто ты?   \n","...    ...                                                ...   \n","3081  3081  Дело не только в барабанах. Каждые пять минут ...   \n","3082  3082  Кажется, я случайно использовал коробки Моники...   \n","3083  3083  ну знаете, вот почему через несколько лет расп...   \n","3084  3084  Он переспал с тобой, а потом никогда тебе не з...   \n","3085  3085  Я знаю, разве он не классный? Так приятно нако...   \n","\n","                                        friend_response  \n","0                          Меня застрелят. Любой совет?  \n","1                          Боже мой, как ты это сделал?  \n","2                            Это было бы очень полезно!  \n","3       Простите, это как будто не для быстрого отдыха!  \n","4     Ну, наши имена действительно Моника и Чендлер....  \n","...                                                 ...  \n","3081  Понимаете, именно так нормальные люди должны р...  \n","3082   Боже, все испорчено! Папа, она будет раздавлена!  \n","3083                               Ой, это так здорово.  \n","3084    А я просто хотела нового папу для Дэви и Бекки.  \n","3085  Ну, может он скоро уедет, как в классную поезд...  \n","\n","[3086 rows x 3 columns]"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["df_test"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Category</th>\n","    </tr>\n","    <tr>\n","      <th>Id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ФИБИ</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>МОНИКА</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>РЕЙЧЕЛ</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>РОСС</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ЧЕНДЛЕР</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3081</th>\n","      <td>ФИБИ</td>\n","    </tr>\n","    <tr>\n","      <th>3082</th>\n","      <td>МОНИКА</td>\n","    </tr>\n","    <tr>\n","      <th>3083</th>\n","      <td>РЕЙЧЕЛ</td>\n","    </tr>\n","    <tr>\n","      <th>3084</th>\n","      <td>МОНИКА</td>\n","    </tr>\n","    <tr>\n","      <th>3085</th>\n","      <td>РЕЙЧЕЛ</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3086 rows × 1 columns</p>\n","</div>"],"text/plain":["     Category\n","Id           \n","0        ФИБИ\n","1      МОНИКА\n","2      РЕЙЧЕЛ\n","3        РОСС\n","4     ЧЕНДЛЕР\n","...       ...\n","3081     ФИБИ\n","3082   МОНИКА\n","3083   РЕЙЧЕЛ\n","3084   МОНИКА\n","3085   РЕЙЧЕЛ\n","\n","[3086 rows x 1 columns]"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["answers = pd.DataFrame(\n","    names_to_cats.inverse_transform(preds), \n","    index=df_test.Id, columns=[\"Category\"])\n","answers.to_csv('submission1.csv')\n","answers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bxhl6QhJlbfE"},"outputs":[],"source":["from transformers import get_constant_schedule\n","opti = AdamW(net.parameters(), lr=LEARNING_RATE, weight_decay=1e-2)\n","lr_scheduler = get_constant_schedule(optimizer=opti)\n","train_set = FriendsDataset(dataframe=df_train.iloc[5000:], tokenizer=tokenizer, max_length=MAX_LEN)\n","\n","val_set = FriendsDataset(dataframe=df_val, tokenizer=tokenizer, max_length=MAX_LEN)\n","# Creating instances of training and validation dataloaders\n","train_loader = DataLoader(train_set, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_set, batch_size=VALID_BATCH_SIZE, shuffle=False, num_workers=2)\n","\n","train_bert(net, criterion, opti, LEARNING_RATE, lr_scheduler, train_loader, val_loader, EPOCHS, iters_to_accumulate)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":939,"status":"ok","timestamp":1636033344945,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"r6o9XkFVL6qD","outputId":"2c4ae139-f975-4f8c-e7b0-88897023e72e"},"outputs":[{"data":{"text/plain":["(1.7879175646551724, 0.1861051115910727)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["val_loss, val_accuracy"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":268,"status":"ok","timestamp":1636042247525,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"BnAB6Udp9Z-1"},"outputs":[],"source":["import gc\n","gc.collect()\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":448,"status":"ok","timestamp":1636024184045,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"VEInewq0pYTk","outputId":"f8944075-b0f8-41a9-8378-f5fc6d1f90fb"},"outputs":[{"data":{"text/plain":["8506.769408"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.get_device_properties(0).total_memory / 1e6"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11448,"status":"ok","timestamp":1635932769348,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"zYNBGqTwpoHn","outputId":"74b194fd-8d8b-4c9f-a35c-9d95859f2c6d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Gen RAM Free: 11.1 GB  | Proc size: 5.1 GB\n","GPU RAM Free: 10137MB | Used: 1304MB | Util  11% | Total 11441MB\n"]}],"source":["# Check that we are using 100% of GPU memory footprint support libraries/code\n","# from https://github.com/patrickvonplaten/notebooks/blob/master/PyTorch_Reformer.ipynb\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip -q install gputil\n","!pip -q install psutil\n","!pip -q install humanize\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isn’t guaranteed\n","gpu = GPUs[0]\n","def printm():\n"," process = psutil.Process(os.getpid())\n"," print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n"," print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm()\n"," #!kill -9 -1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":452,"status":"ok","timestamp":1635932801898,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"e9gyehyY6n8C","outputId":"0e7574a4-b8d7-44fa-8f06-717912d52d5a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Gen RAM Free: 11.1 GB  | Proc size: 5.1 GB\n","GPU RAM Free: 10137MB | Used: 1304MB | Util  11% | Total 11441MB\n"]}],"source":["printm()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v1kSrbCvMNDf"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNFzSvllZcK0G034IIhIOS7","collapsed_sections":[],"mount_file_id":"144h_eAZbCarOnrPb3zxIWY7HYm27TGhi","name":"FriendsPredictNLP","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0344eb1638a44fc0bd8be3d2b5aafc99":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2cbc04f6abc4b45b5374f424dd88efa","placeholder":"​","style":"IPY_MODEL_91647e75ea5e4c16a11046fda73ba026","value":" 521/521 [00:00&lt;00:00, 12.4kB/s]"}},"0f3925eaafb9438ab0f6b27c356cfe99":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82b0759acdb845ea9859d2f96ce0e5d3","placeholder":"​","style":"IPY_MODEL_487d23c4e2b64adda4a945df313d1ed1","value":" 1.70M/1.70M [00:00&lt;00:00, 7.10MB/s]"}},"121075183d2441ddb2e99f849d2e9686":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f4f04df6382427288c4e9422e4fbf7d","placeholder":"​","style":"IPY_MODEL_e3aeb80a52bf4ccdb69330b3ebce4355","value":" 683M/683M [00:23&lt;00:00, 32.0MB/s]"}},"158f6d85beec4b33bdc422ee9e115808":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e6a2c5306764e31bea3a9e37121ff8c","placeholder":"​","style":"IPY_MODEL_faaf710ce2cc471c9370811df2f54ba6","value":" 655/655 [00:00&lt;00:00, 15.7kB/s]"}},"192f33925dd045d792b38a2444794a10":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21bf688381ef4a8495a3a6981a84ef8d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_939389df612a4f23b8ab42d6dccd6c8d","max":323,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6c7f0e73512743efb870026d6677531e","value":323}},"269978945c9c48d280cd1eb1ddf2f7fc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d185bee7972497296fc31ba5c0d54d6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e6a2c5306764e31bea3a9e37121ff8c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"317c759beaf6494db054eae9162ccfb2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32acd792c0bf45419a87561dc4ccdb4c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d8a373f8b1a4da3841d55ed5fd62935":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b968066f8f924c309860b111ae0816a4","IPY_MODEL_98ff0c5dbe8049c588ef631dfbc08ef8","IPY_MODEL_121075183d2441ddb2e99f849d2e9686"],"layout":"IPY_MODEL_5435b27f9fab4fcd9f0cf0fe1f11db71"}},"4718ae66701049229c66c8506b3efe1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_65cbb712ea2f4dab90ba6600d8440c0b","placeholder":"​","style":"IPY_MODEL_d70b870ad108499e8651b57c9e9be34b","value":"Downloading: 100%"}},"487d23c4e2b64adda4a945df313d1ed1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e0b4d1769974ba88e49d4fb02e2c4a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"52e9ba2a4d974b15ae4b6ab1232dc256":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5435b27f9fab4fcd9f0cf0fe1f11db71":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54feb1dd180f4bf8b47c18713336d41c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58564c36a43e4f3ab99a0e153cb5e480":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58c863f270ac42c3b195987575a8bc9a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5e3622f69800454d9704f414226d5869":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5fa6528c3aa5487e87edb8797ebf465e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"632a7169fbd74159b11d92ab6cbacfa7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6502e372ae624b618f6248ee2ea778b6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65cbb712ea2f4dab90ba6600d8440c0b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c7b0a0b13b3450fa83c21af7c8525a2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c7f0e73512743efb870026d6677531e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6cd8338fff6a4f469d417911e8b8142b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54feb1dd180f4bf8b47c18713336d41c","placeholder":"​","style":"IPY_MODEL_7148c15a118641d3a9488fd981cc3bf3","value":"Downloading: 100%"}},"7148c15a118641d3a9488fd981cc3bf3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"717056921033432aa1612afdd7aab763":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d900d48dde840e0824e409582df0dd2","placeholder":"​","style":"IPY_MODEL_58564c36a43e4f3ab99a0e153cb5e480","value":"Downloading: 100%"}},"73c9f7d056704fd2ac03cb76d6f36df5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d83773323bd4e90bc86003c4220a662","placeholder":"​","style":"IPY_MODEL_df27936694364ed583b70df9a0870a08","value":"Downloading: 100%"}},"769e20765ef64788b8de218a9853c99e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77b7765f0fe04c8a976230fb2eb01065":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"784667efc3604b52a7a3e90afeeba909":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79f29a0c5f01482dbbb7700bd7b573a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4718ae66701049229c66c8506b3efe1b","IPY_MODEL_bddc64019a20420589041d59a8ac1e86","IPY_MODEL_158f6d85beec4b33bdc422ee9e115808"],"layout":"IPY_MODEL_d469fb245e2244848f21d12c9897e0e8"}},"7d83773323bd4e90bc86003c4220a662":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f4f04df6382427288c4e9422e4fbf7d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82b0759acdb845ea9859d2f96ce0e5d3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"830958dc67714696a237fc7a051931bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85aa7a96758841a3bb30895cf30d9912":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88b743167cd44b318de6a3998f466556":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d900d48dde840e0824e409582df0dd2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e60d43dcd7e4df9a554b7b8ed28c56d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7c1b532fc64473eab127d4f73c4ffd7","placeholder":"​","style":"IPY_MODEL_192f33925dd045d792b38a2444794a10","value":"Downloading: 100%"}},"91647e75ea5e4c16a11046fda73ba026":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"939389df612a4f23b8ab42d6dccd6c8d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"972de0d98911484dad5f2c7b560d973c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_269978945c9c48d280cd1eb1ddf2f7fc","max":521,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f543e115e78f40f7bc9813a76b5ba862","value":521}},"98ff0c5dbe8049c588ef631dfbc08ef8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e55762599f664a0fa5288de998af11c1","max":716133354,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ef630b6fc27b4750839918ef7ac13c6c","value":716133354}},"a56c41e3f2744ba6b2f5cd408a86e6d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8e60d43dcd7e4df9a554b7b8ed28c56d","IPY_MODEL_ebbe8ae171e94413be8fcc944c05b28b","IPY_MODEL_c280900ff8ba4cc8a2dbf30daad33a4b"],"layout":"IPY_MODEL_d15f42cd6e9d427c99f12b45ba2b04e1"}},"a7c1b532fc64473eab127d4f73c4ffd7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a825221a71434b82be79352ad867c68a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a89df2c0f77a445eb9a12550fcaed50d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6cd8338fff6a4f469d417911e8b8142b","IPY_MODEL_edd582160bd349c68d35b5461b9771c2","IPY_MODEL_f1868ee80eff44af8596b13875f7cddd"],"layout":"IPY_MODEL_ee730afc554f486591437c1c9de33490"}},"adef346525b5428cb77ce85b67b7de02":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f32062e1b8f74b2ba3ebb65244b8345d","IPY_MODEL_21bf688381ef4a8495a3a6981a84ef8d","IPY_MODEL_d601368d185f4c2f8de3b222976c42ef"],"layout":"IPY_MODEL_632a7169fbd74159b11d92ab6cbacfa7"}},"b968066f8f924c309860b111ae0816a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88b743167cd44b318de6a3998f466556","placeholder":"​","style":"IPY_MODEL_77b7765f0fe04c8a976230fb2eb01065","value":"Downloading: 100%"}},"b9b60187d34644bda94b224017bc450d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bddc64019a20420589041d59a8ac1e86":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d185bee7972497296fc31ba5c0d54d6","max":655,"min":0,"orientation":"horizontal","style":"IPY_MODEL_830958dc67714696a237fc7a051931bc","value":655}},"c280900ff8ba4cc8a2dbf30daad33a4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_317c759beaf6494db054eae9162ccfb2","placeholder":"​","style":"IPY_MODEL_4e0b4d1769974ba88e49d4fb02e2c4a2","value":" 1.70M/1.70M [00:00&lt;00:00, 3.07MB/s]"}},"d15f42cd6e9d427c99f12b45ba2b04e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3ce46e504bd4daf9ac3763a7cdc222f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d469fb245e2244848f21d12c9897e0e8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5ed4335e6bb418aaebd5316b616f54c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d601368d185f4c2f8de3b222976c42ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32acd792c0bf45419a87561dc4ccdb4c","placeholder":"​","style":"IPY_MODEL_769e20765ef64788b8de218a9853c99e","value":" 323/323 [00:00&lt;00:00, 7.17kB/s]"}},"d70b870ad108499e8651b57c9e9be34b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df27936694364ed583b70df9a0870a08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2cbc04f6abc4b45b5374f424dd88efa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3aeb80a52bf4ccdb69330b3ebce4355":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e55762599f664a0fa5288de998af11c1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e87825600783430391ed6af6be32c278":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_73c9f7d056704fd2ac03cb76d6f36df5","IPY_MODEL_972de0d98911484dad5f2c7b560d973c","IPY_MODEL_0344eb1638a44fc0bd8be3d2b5aafc99"],"layout":"IPY_MODEL_b9b60187d34644bda94b224017bc450d"}},"e9d9038ad82440aebdb0fb714add647d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_717056921033432aa1612afdd7aab763","IPY_MODEL_f010001c717b439797f738bb4353b74d","IPY_MODEL_0f3925eaafb9438ab0f6b27c356cfe99"],"layout":"IPY_MODEL_85aa7a96758841a3bb30895cf30d9912"}},"ebbe8ae171e94413be8fcc944c05b28b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6502e372ae624b618f6248ee2ea778b6","max":1780720,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d5ed4335e6bb418aaebd5316b616f54c","value":1780720}},"edd582160bd349c68d35b5461b9771c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_784667efc3604b52a7a3e90afeeba909","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_58c863f270ac42c3b195987575a8bc9a","value":112}},"ee730afc554f486591437c1c9de33490":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef630b6fc27b4750839918ef7ac13c6c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f010001c717b439797f738bb4353b74d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3ce46e504bd4daf9ac3763a7cdc222f","max":1780720,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5fa6528c3aa5487e87edb8797ebf465e","value":1780720}},"f1868ee80eff44af8596b13875f7cddd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c7b0a0b13b3450fa83c21af7c8525a2","placeholder":"​","style":"IPY_MODEL_5e3622f69800454d9704f414226d5869","value":" 112/112 [00:00&lt;00:00, 2.29kB/s]"}},"f32062e1b8f74b2ba3ebb65244b8345d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52e9ba2a4d974b15ae4b6ab1232dc256","placeholder":"​","style":"IPY_MODEL_a825221a71434b82be79352ad867c68a","value":"Downloading: 100%"}},"f543e115e78f40f7bc9813a76b5ba862":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"faaf710ce2cc471c9370811df2f54ba6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
