{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":304,"status":"ok","timestamp":1636037468369,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"jfX9Mo2IRKkS","outputId":"72476e94-f6d5-4f3f-9289-95aba0fefb20"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.9.7\n"]}],"source":["! python -V"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.12.3-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 626 kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /home/andrew/anaconda3/envs/nn/lib/python3.9/site-packages (from transformers) (1.21.2)\n","Collecting filelock\n","  Downloading filelock-3.3.2-py3-none-any.whl (9.7 kB)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (661 kB)\n","\u001b[K     |████████████████████████████████| 661 kB 9.8 MB/s \n","\u001b[?25hCollecting regex!=2019.12.17\n","  Downloading regex-2021.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n","\u001b[K     |████████████████████████████████| 762 kB 9.7 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.1.0-py3-none-any.whl (59 kB)\n","\u001b[K     |████████████████████████████████| 59 kB 4.7 MB/s \n","\u001b[?25hCollecting requests\n","  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 712 kB/s \n","\u001b[?25hCollecting tqdm>=4.27\n","  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n","\u001b[K     |████████████████████████████████| 76 kB 3.7 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 9.8 MB/s \n","\u001b[?25hCollecting packaging>=20.0\n","  Downloading packaging-21.2-py3-none-any.whl (40 kB)\n","\u001b[K     |████████████████████████████████| 40 kB 4.5 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 10.4 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /home/andrew/anaconda3/envs/nn/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Collecting pyparsing<3,>=2.0.2\n","  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 4.4 MB/s \n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /home/andrew/anaconda3/envs/nn/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n","Collecting charset-normalizer~=2.0.0\n","  Downloading charset_normalizer-2.0.7-py3-none-any.whl (38 kB)\n","Collecting urllib3<1.27,>=1.21.1\n","  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 10.4 MB/s \n","\u001b[?25hCollecting idna<4,>=2.5\n","  Downloading idna-3.3-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: joblib in /home/andrew/anaconda3/envs/nn/lib/python3.9/site-packages (from sacremoses->transformers) (1.1.0)\n","Collecting click\n","  Downloading click-8.0.3-py3-none-any.whl (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 4.7 MB/s \n","\u001b[?25hRequirement already satisfied: six in /home/andrew/anaconda3/envs/nn/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n","Installing collected packages: urllib3, pyparsing, idna, charset-normalizer, tqdm, requests, regex, pyyaml, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyparsing\n","    Found existing installation: pyparsing 3.0.4\n","    Uninstalling pyparsing-3.0.4:\n","      Successfully uninstalled pyparsing-3.0.4\n","Successfully installed charset-normalizer-2.0.7 click-8.0.3 filelock-3.3.2 huggingface-hub-0.1.0 idna-3.3 packaging-21.2 pyparsing-2.4.7 pyyaml-6.0 regex-2021.11.2 requests-2.26.0 sacremoses-0.0.46 tokenizers-0.10.3 tqdm-4.62.3 transformers-4.12.3 urllib3-1.26.7\n"]}],"source":["! pip install transformers"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":28083,"status":"ok","timestamp":1636037505252,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"JplCyr0VKrhP"},"outputs":[],"source":["import random \n","import time\n","import copy\n","\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","import torch\n","import torch.nn as nn\n","from torch.cuda.amp import autocast, GradScaler\n","\n","from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n","from transformers import BertTokenizer, BertModel, AdamW\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["True"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":209,"referenced_widgets":["adef346525b5428cb77ce85b67b7de02","632a7169fbd74159b11d92ab6cbacfa7","f32062e1b8f74b2ba3ebb65244b8345d","21bf688381ef4a8495a3a6981a84ef8d","d601368d185f4c2f8de3b222976c42ef","a825221a71434b82be79352ad867c68a","52e9ba2a4d974b15ae4b6ab1232dc256","6c7f0e73512743efb870026d6677531e","939389df612a4f23b8ab42d6dccd6c8d","769e20765ef64788b8de218a9853c99e","32acd792c0bf45419a87561dc4ccdb4c","79f29a0c5f01482dbbb7700bd7b573a7","d469fb245e2244848f21d12c9897e0e8","4718ae66701049229c66c8506b3efe1b","bddc64019a20420589041d59a8ac1e86","158f6d85beec4b33bdc422ee9e115808","d70b870ad108499e8651b57c9e9be34b","65cbb712ea2f4dab90ba6600d8440c0b","830958dc67714696a237fc7a051931bc","2d185bee7972497296fc31ba5c0d54d6","faaf710ce2cc471c9370811df2f54ba6","2e6a2c5306764e31bea3a9e37121ff8c","a56c41e3f2744ba6b2f5cd408a86e6d7","d15f42cd6e9d427c99f12b45ba2b04e1","8e60d43dcd7e4df9a554b7b8ed28c56d","ebbe8ae171e94413be8fcc944c05b28b","c280900ff8ba4cc8a2dbf30daad33a4b","192f33925dd045d792b38a2444794a10","a7c1b532fc64473eab127d4f73c4ffd7","d5ed4335e6bb418aaebd5316b616f54c","6502e372ae624b618f6248ee2ea778b6","4e0b4d1769974ba88e49d4fb02e2c4a2","317c759beaf6494db054eae9162ccfb2","a89df2c0f77a445eb9a12550fcaed50d","ee730afc554f486591437c1c9de33490","6cd8338fff6a4f469d417911e8b8142b","edd582160bd349c68d35b5461b9771c2","f1868ee80eff44af8596b13875f7cddd","7148c15a118641d3a9488fd981cc3bf3","54feb1dd180f4bf8b47c18713336d41c","58c863f270ac42c3b195987575a8bc9a","784667efc3604b52a7a3e90afeeba909","5e3622f69800454d9704f414226d5869","6c7b0a0b13b3450fa83c21af7c8525a2","e9d9038ad82440aebdb0fb714add647d","85aa7a96758841a3bb30895cf30d9912","717056921033432aa1612afdd7aab763","f010001c717b439797f738bb4353b74d","0f3925eaafb9438ab0f6b27c356cfe99","58564c36a43e4f3ab99a0e153cb5e480","8d900d48dde840e0824e409582df0dd2","5fa6528c3aa5487e87edb8797ebf465e","d3ce46e504bd4daf9ac3763a7cdc222f","487d23c4e2b64adda4a945df313d1ed1","82b0759acdb845ea9859d2f96ce0e5d3","e87825600783430391ed6af6be32c278","b9b60187d34644bda94b224017bc450d","73c9f7d056704fd2ac03cb76d6f36df5","972de0d98911484dad5f2c7b560d973c","0344eb1638a44fc0bd8be3d2b5aafc99","df27936694364ed583b70df9a0870a08","7d83773323bd4e90bc86003c4220a662","f543e115e78f40f7bc9813a76b5ba862","269978945c9c48d280cd1eb1ddf2f7fc","91647e75ea5e4c16a11046fda73ba026","e2cbc04f6abc4b45b5374f424dd88efa"]},"executionInfo":{"elapsed":4421,"status":"ok","timestamp":1636037509668,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"o24cy8ORGJjU","outputId":"2c57e157-d12e-41c3-9631-cd59f18b134b"},"outputs":[],"source":["#CHECKPOINT = \"sberbank-ai/sbert_large_nlu_ru\"\n","MAX_LEN = 256\n","TRAIN_BATCH_SIZE = 16\n","VALID_BATCH_SIZE = 16\n","EPOCHS = 3\n","LEARNING_RATE = 2e-05\n","#tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)\n","CHECKPOINT = \"sberbank-ai/ruBert-base\"\n","tokenizer = BertTokenizer.from_pretrained(CHECKPOINT)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1636037511385,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"iuShp08vL62l","outputId":"885c5ad6-61d9-40c9-ae33-5be1da37a048"},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/andrew/ml/friends-classification\n","mkdir: cannot create directory ‘models’: File exists\n","models\ttest.csv  train_data.csv  val_data.csv\n"]}],"source":["%cd friends-classification/\n","!mkdir models\n","! ls"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":459,"status":"ok","timestamp":1636037511841,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"acv7o-iyMo2n","outputId":"e1180782-7199-4b5b-ef05-41f2f3d4d114"},"outputs":[{"name":"stdout","output_type":"stream","text":["РОСС       0.176569\n","РЕЙЧЕЛ     0.176089\n","ЧЕНДЛЕР    0.170568\n","ДЖОУИ      0.166287\n","МОНИКА     0.160525\n","ФИБИ       0.149962\n","Name: label, dtype: float64\n","\n","РОСС       0.176746\n","РЕЙЧЕЛ     0.176026\n","ЧЕНДЛЕР    0.170626\n","ДЖОУИ      0.166307\n","МОНИКА     0.160547\n","ФИБИ       0.149748\n","Name: label, dtype: float64\n"]}],"source":["df_train = pd.read_csv('train_data.csv').rename({'Category': 'label'}, axis=1)\n","df_train.other_speaker.fillna('', inplace=True)\n","df_val = pd.read_csv('val_data.csv')\n","df_val.other_speaker.fillna('', inplace=True)\n","df_test = pd.read_csv('test.csv')\n","df_test.other_speaker.fillna('', inplace=True)\n","\n","# Encoding target variable\n","names_to_cats = LabelEncoder()\n","df_train['label_code'] = names_to_cats.fit_transform(df_train.label)\n","df_val['label_code'] = names_to_cats.transform(df_val.label)\n","df_full = pd.concat([df_train, df_val])\n","print(df_train[\"label\"].value_counts()/df_train.shape[0])\n","print()\n","print(df_val[\"label\"].value_counts()/df_val.shape[0])"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":436},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1636037511842,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"q87GsjIbOl_e","outputId":"382b8f47-59e7-47df-8e3c-c137d3c72bc1"},"outputs":[{"name":"stdout","output_type":"stream","text":["(24993, 5) (2778, 5) (3086, 3)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>other_speaker</th>\n","      <th>friend_response</th>\n","      <th>label</th>\n","      <th>label_code</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Ладно, а мы вообще не обедаем?</td>\n","      <td>Давай, пора стать серьезным, сбиться с толку. ...</td>\n","      <td>МОНИКА</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Ладно, ладно, послушай, я знаю, что сегодня ве...</td>\n","      <td>Ладно, вот и все! Слезь с нее!</td>\n","      <td>РОСС</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Ага. Знаешь, у меня есть все эти чувства, и я ...</td>\n","      <td>Хорошо, я видела довольно большого голубя.</td>\n","      <td>ДЖОУИ</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Боже мой! один пару минут назад, а теперь я.</td>\n","      <td>Постой, ты не можешь здесь рожать! То есть я н...</td>\n","      <td>МОНИКА</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Не такой, как он сам по себе, просто не такой,...</td>\n","      <td>Посмотрите, это художник, ранее известный как ...</td>\n","      <td>РОСС</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2773</th>\n","      <td>2773</td>\n","      <td>Что сегодня вечером?</td>\n","      <td>Это наше первое официальное свидание. Наше пер...</td>\n","      <td>РЕЙЧЕЛ</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2774</th>\n","      <td>2774</td>\n","      <td>Эй, а ты не переоделась?</td>\n","      <td>Да, и на этот раз вам лучше убедиться, что он ...</td>\n","      <td>РЕЙЧЕЛ</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2775</th>\n","      <td>2775</td>\n","      <td>Тебя там не было!</td>\n","      <td>Нет, но это, знаете, просто забавная картинка,...</td>\n","      <td>РОСС</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2776</th>\n","      <td>2776</td>\n","      <td>Вы говорите по телефону!</td>\n","      <td>Это была пожарная часть, у нас пожар был!</td>\n","      <td>РЕЙЧЕЛ</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2777</th>\n","      <td>2777</td>\n","      <td>Извините.</td>\n","      <td>По крайней мере, я заработал десять долларов н...</td>\n","      <td>РОСС</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2778 rows × 5 columns</p>\n","</div>"],"text/plain":["        Id                                      other_speaker  \\\n","0        0                     Ладно, а мы вообще не обедаем?   \n","1        1  Ладно, ладно, послушай, я знаю, что сегодня ве...   \n","2        2  Ага. Знаешь, у меня есть все эти чувства, и я ...   \n","3        3       Боже мой! один пару минут назад, а теперь я.   \n","4        4  Не такой, как он сам по себе, просто не такой,...   \n","...    ...                                                ...   \n","2773  2773                               Что сегодня вечером?   \n","2774  2774                           Эй, а ты не переоделась?   \n","2775  2775                                  Тебя там не было!   \n","2776  2776                           Вы говорите по телефону!   \n","2777  2777                                          Извините.   \n","\n","                                        friend_response   label  label_code  \n","0     Давай, пора стать серьезным, сбиться с толку. ...  МОНИКА           1  \n","1                        Ладно, вот и все! Слезь с нее!    РОСС           3  \n","2            Хорошо, я видела довольно большого голубя.   ДЖОУИ           0  \n","3     Постой, ты не можешь здесь рожать! То есть я н...  МОНИКА           1  \n","4     Посмотрите, это художник, ранее известный как ...    РОСС           3  \n","...                                                 ...     ...         ...  \n","2773  Это наше первое официальное свидание. Наше пер...  РЕЙЧЕЛ           2  \n","2774  Да, и на этот раз вам лучше убедиться, что он ...  РЕЙЧЕЛ           2  \n","2775  Нет, но это, знаете, просто забавная картинка,...    РОСС           3  \n","2776          Это была пожарная часть, у нас пожар был!  РЕЙЧЕЛ           2  \n","2777  По крайней мере, я заработал десять долларов н...    РОСС           3  \n","\n","[2778 rows x 5 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["print(df_train.shape, df_val.shape, df_test.shape)\n","df_val"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":264,"status":"ok","timestamp":1636041805080,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"6fwxjlLEGzIT"},"outputs":[],"source":["class FriendsDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_length=512, padding='max_length', \n","                 with_labels=True):\n","\n","        self.dataframe = dataframe  # pandas dataframe\n","        #Initialize the tokenizer\n","        self.tokenizer = tokenizer  \n","        self.padding = padding\n","        self.max_length = max_length\n","        \n","        self.with_labels = with_labels \n","        if 'label' not in self.dataframe.columns:\n","          self.with_labels = False\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, index):\n","\n","        # Selecting sentence1 and sentence2 at the specified index in the data frame\n","        sent1 = self.dataframe.other_speaker.iloc[index]\n","        sent2 = self.dataframe.friend_response.iloc[index]\n","\n","        # Tokenize the pair of sentences to get token ids, attention masks and token type ids\n","        encoded_pair = self.tokenizer(sent1, sent2, \n","                                      padding=self.padding,  # Pad to max_length\n","                                      truncation=True,  # Truncate to max_length\n","                                      max_length=self.max_length,  \n","                                      return_tensors='pt')  # Return torch.Tensor objects\n","        \n","        token_ids = encoded_pair['input_ids'].squeeze(0)  # tensor of token ids\n","        attn_masks = encoded_pair['attention_mask'].squeeze(0)  # binary tensor with \"0\" for padded values and \"1\" for the other values\n","        token_type_ids = encoded_pair['token_type_ids'].squeeze(0)  # binary tensor with \"0\" for the 1st sentence tokens & \"1\" for the 2nd sentence tokens\n","\n","        if self.with_labels:  # True if the dataset has labels\n","            label = self.dataframe.label_code.iloc[index]\n","            return token_ids, attn_masks, token_type_ids, label  \n","        else:\n","            return token_ids, attn_masks, token_type_ids"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1636011617187,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"qJWu9ZEGYwui","outputId":"b0920bbc-27cd-43ce-ebd6-15ab7ac953c5"},"outputs":[{"data":{"text/plain":["(tensor([  101, 20054,   126,  5075,   121,   118,  1024,  1114,   780,  1090,\n","          6724,   121,   107,   119,   672,  2289,   121,   693,   110,  3192,\n","          2555,   121,  1747,   693,   119,   672,  1385, 20345,   785,  3122,\n","         20900,   378,  1266,   121,   107,   736,  8501,   121,  1747,   693,\n","          1098,   672,  6474,  3269,   121,   119,  9268,   113,  4775,   780,\n","           121,   693,   119,   784, 34083, 21338,  1102,  3371,  3641, 46962,\n","          2774,   126,  1293, 18341,   121, 10302,   161,  4029, 16437,   121,\n","          4029,  3384,   121,  1293,   110,  5477,   133,   696,   121,   110,\n","          5477,  1098, 22819,   107,  1309,  3730,   121,   693,   795,  5190,\n","           126,   119,  9268,   113,  4775,   121,   693,   660,  3641, 40184,\n","          2774,   784, 34083, 21338,  1102,   818,   194,  4759,   194,  2775,\n","           680,   126,   785,  6568,  9229,  1336,   161,   102,  2184,   121,\n","           119,  7539,  3662,  8129, 64474,   126,   102,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0]),\n"," tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0]),\n"," tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0]),\n"," 0)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["FriendsDataset(df_val, tokenizer)[2]"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1636011617187,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"NCOVhXIwY8EQ","outputId":"adfd41dd-9c00-431d-d1b1-afdd0d7428d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'input_ids': [[101, 9006, 121, 106, 945, 2167, 672, 18111, 686, 161, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 9006, 121, 9006, 121, 24103, 378, 121, 119, 2289, 121, 693, 1806, 4331, 1231, 50085, 31392, 24625, 121, 750, 736, 818, 5409, 121, 119, 9268, 113, 4775, 5617, 121, 785, 947, 27480, 1499, 121, 107, 119, 1293, 3371, 52885, 114, 1905, 107, 45808, 1679, 121, 3823, 377, 378, 121, 6254, 2808, 121, 1293, 121, 1293, 67095, 1024, 126, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"]}],"source":["print(tokenizer.batch_encode_plus(df_val.other_speaker[:2].to_list(), padding=True))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1636011621059,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"XeQGWQHShk6g","outputId":"4f1b0520-0753-4b2b-c630-9f6d25aa5a68"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'input_ids': [[101, 9006, 121, 106, 945, 2167, 672, 18111, 686, 161, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 9006, 121, 9006, 121, 24103, 378, 121, 119, 2289, 121, 693, 1806, 4331, 1231, 50085, 31392, 24625, 121, 750, 736, 818, 5409, 121, 119, 9268, 113, 4775, 5617, 121, 785, 947, 27480, 1499, 121, 107, 119, 1293, 3371, 52885, 114, 1905, 107, 45808, 1679, 121, 3823, 377, 378, 121, 6254, 2808, 121, 1293, 121, 1293, 67095, 1024, 126, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'[CLS] ладно, а мы вообще не обедаем? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["encoded_input = tokenizer(df_val.other_speaker[:2].to_list(), padding=True)\n","print(encoded_input)\n","tokenizer.decode(encoded_input[\"input_ids\"][0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":273,"status":"ok","timestamp":1636011626459,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"A3MzcF4WhqPF","outputId":"4510c98f-3b98-4733-ef1c-72fc36133c5a"},"outputs":[{"data":{"text/plain":["['Ладно, а мы вообще не обедаем?',\n"," 'Ладно, ладно, послушай, я знаю, что сегодня веду себя мистером Несоответствующим, но это так тяжело, я имею в виду увидеть, как ты гуляешь, и я просто хочу прикоснуться к тебе и обнять тебя, давай, никого рядом, просто, просто поцелуй меня.']"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["df_val.other_speaker[:2].to_list()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"elapsed":544,"status":"ok","timestamp":1636011627375,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"ERDB6JyobclV","outputId":"0fe39def-fc13-40f3-fb72-c8dcfd8ecafe"},"outputs":[{"data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7fe6eb47fbd0>"]},"execution_count":14,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["seq_len = [len(i.split()) for i in df_train.other_speaker.fillna('')]\n","\n","pd.Series(seq_len).hist(bins = 30)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":469},"executionInfo":{"elapsed":644,"status":"ok","timestamp":1636011628318,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"8vdS5P-2az0b","outputId":"5e99479f-a945-443c-97a5-ec54b965acef"},"outputs":[{"data":{"text/plain":["17         4\n","18         7\n","19        14\n","20        26\n","21        48\n","       ...  \n","268    29293\n","269    29308\n","270    29329\n","271    29345\n","272    29365\n","Name: seq_len, Length: 256, dtype: int64"]},"execution_count":15,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["dfs_all = pd.concat([df_train, df_val, df_test])\n","dfs_all['seq_len'] = dfs_all.apply(lambda row: \n","                                   len(row['other_speaker'] + row['friend_response']), axis=1)\n","print(len(dfs_all), \"number of all dialogs in train, validation and test\")\n","[len(i.split()) for i in dfs_all.other_speaker]\n","dfs_all['seq_len'].hist(bins = 30)\n","dfs_all['seq_len'].value_counts().sort_index(ascending=True).cumsum().head(256)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1635935619917,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"sbhksA3xcLna","outputId":"107b86ad-8bb8-439f-b706-aa823fce7773"},"outputs":[{"data":{"text/plain":["count     24993\n","unique    21269\n","top        Что?\n","freq        263\n","Name: other_speaker, dtype: object"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["df_train.other_speaker.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Mdv07RUakHR"},"outputs":[],"source":["model = BertModel.from_pretrained(CHECKPOINT)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1635926776189,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"iagLgdpUbxzU","outputId":"8c46b13a-8ee1-4c58-8cd5-3f505169c983"},"outputs":[{"data":{"text/plain":["BertConfig {\n","  \"_name_or_path\": \"sberbank-ai/sbert_large_nlu_ru\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 120138\n","}"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["model.config"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1635926776190,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"eL0HT2PmSj3D","outputId":"1f3b9b1d-90ad-40fd-ea98-e7c729eb4ebb"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Ага. Знаешь, у меня есть все эти чувства, и я не знаю, что с ними делать, потому что я не могу встречаться как нормальный человек, и это нормально, потому что мне не нужны отношения, я имею в виду все, что я действительно хочу одну отличную ночь. Просто секс, понимаешь? Никаких условий, никаких отношений, просто с кем-то, с кем мне комфортно и кто знает, что он делает. Я имею в виду, что на одну прекрасную ночь действительно так… трудно… найти. Как прошел твой день?'"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["df_val.other_speaker[2]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1367,"status":"ok","timestamp":1635926777543,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"huooGHOoccF2","outputId":"9dcaf530-386d-424e-cadd-ec33483c4ba1"},"outputs":[{"name":"stdout","output_type":"stream","text":["BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 7.1882e-01, -5.3918e-03, -8.3920e-01,  ...,  3.3451e-01,\n","          -3.1676e-01, -5.1034e-01],\n","         [ 5.5719e-01, -8.0553e-02, -3.7181e-01,  ..., -1.7804e-01,\n","          -1.0751e-02, -9.4979e-01],\n","         [ 8.5000e-01, -2.2997e-01, -1.1100e+00,  ..., -2.6581e-01,\n","           4.5181e-01, -4.4495e-04],\n","         ...,\n","         [ 1.0387e+00,  2.0646e-02, -9.4394e-01,  ...,  3.9442e-02,\n","           5.3907e-01, -6.4463e-01],\n","         [ 8.8433e-01, -3.8336e-02, -1.5689e+00,  ...,  3.1330e-01,\n","           6.2395e-01,  3.8496e-02],\n","         [-5.5417e-01, -1.9077e-01, -9.9541e-01,  ..., -4.3991e-01,\n","          -4.3730e-01,  3.4922e-01]]]), pooler_output=tensor([[ 0.0782,  0.0337, -0.4183,  ..., -0.1049,  0.8060, -0.0340]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","torch.Size([1, 1024]) torch.Size([1, 118, 1024])\n"]}],"source":["with torch.no_grad():\n","  output = model(**tokenizer(df_val.other_speaker[2], return_tensors='pt'), )\n","print(output)\n","print(output.pooler_output.shape, output.last_hidden_state.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1635923888287,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"1BUrLzPQfm3e","outputId":"4ffacb2f-5021-4cb1-e8bf-8b470ca8ed2e"},"outputs":[{"data":{"text/plain":["{'input_ids': tensor([[  101, 20054,   126,  5075,   121,   118,  1024,  1114,   780,  1090,\n","          6724,   121,   107,   119,   672,  2289,   121,   693,   110,  3192,\n","          2555,   121,  1747,   693,   119,   672,  1385, 20345,   785,  3122,\n","         20900,   378,  1266,   121,   107,   736,  8501,   121,  1747,   693,\n","          1098,   672,  6474,  3269,   121,   119,  9268,   113,  4775,   780,\n","           121,   693,   119,   784, 34083, 21338,  1102,  3371,  3641, 46962,\n","          2774,   126,  1293, 18341,   121, 10302,   161,  4029, 16437,   121,\n","          4029,  3384,   121,  1293,   110,  5477,   133,   696,   121,   110,\n","          5477,  1098, 22819,   107,  1309,  3730,   121,   693,   795,  5190,\n","           126,   119,  9268,   113,  4775,   121,   693,   660,  3641, 40184,\n","          2774,   784, 34083, 21338,  1102,   818,   194,  4759,   194,  2775,\n","           680,   126,   785,  6568,  9229,  1336,   161,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer(df_val.other_speaker[2], return_tensors='pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1635923888288,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"9osfOgxuaO43","outputId":"51928964-2fc1-4125-ad46-a18bff032606"},"outputs":[{"data":{"text/plain":["{'cls_token': '[CLS]',\n"," 'mask_token': '[MASK]',\n"," 'pad_token': '[PAD]',\n"," 'sep_token': '[SEP]',\n"," 'unk_token': '[UNK]'}"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.special_tokens_map"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1636037511843,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"jLmUmq46a0D6"},"outputs":[],"source":["class SentencePairClassifier(nn.Module):\n","\n","    def __init__(self, model=CHECKPOINT, freeze_model=True):\n","        super(SentencePairClassifier, self).__init__()\n","        #  Instantiating BERT-based model object\n","        # self.pretrained_layer = AutoModel.from_pretrained(CHECKPOINT)\n","        self.pretrained_layer = BertModel.from_pretrained(CHECKPOINT)\n","\n","        hidden_size = self.pretrained_layer.config.hidden_size\n","\n","        # Freeze model layers and only train the classification layer weights\n","        if freeze_model:\n","            for p in self.pretrained_layer.parameters():\n","                p.requires_grad = False\n","            print('All parameters frozen')\n","        # Classification layer\n","        self.cls_layer = nn.Linear(hidden_size, 6)\n","\n","        self.dropout = nn.Dropout(p=0.3)\n","\n","    @autocast()  # run in mixed precision\n","    def forward(self, input_ids, attn_masks, token_type_ids):\n","        '''\n","        Inputs:\n","            -input_ids : Tensor  containing token ids\n","            -attn_masks : Tensor containing attention masks to be used to focus on non-padded values\n","            -token_type_ids : Tensor containing token type ids to be used to identify sentence1 and sentence2\n","        '''\n","\n","        # Feeding the inputs to the BERT-based model to obtain contextualized representations\n","        output = self.pretrained_layer(input_ids, attn_masks, token_type_ids)\n","\n","        # Feeding to the classifier layer the last layer hidden-state of the [CLS] token further processed by a\n","        # Linear Layer and a Tanh activation. The Linear layer weights were trained from the sentence order prediction (ALBERT) or next sentence prediction (BERT)\n","        # objective during pre-training.\n","        logits = self.cls_layer(self.dropout(output.pooler_output))\n","\n","        return logits"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1636037511843,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"JKiUIjwGiWEv"},"outputs":[],"source":["def set_seed(seed):\n","    \"\"\" Set all seeds to make results reproducible \"\"\"\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    #os.environ['PYTHONHASHSEED'] = str(seed)\n","    \n","\n","def evaluate_loss(net, device, criterion, dataloader):\n","    net.eval()\n","    n_correct = 0\n","    mean_loss = 0\n","    count = 0\n","\n","    with torch.no_grad():\n","        for it, (seq, attn_masks, token_type_ids, labels) in enumerate(tqdm(dataloader)):\n","            seq, attn_masks, token_type_ids, labels = \\\n","                seq.to(device), attn_masks.to(device), token_type_ids.to(device), labels.to(device)\n","            logits = net(seq, attn_masks, token_type_ids)\n","            mean_loss += criterion(logits.squeeze(-1), labels).item()\n","            count += 1\n","            max_logits, argmax_idx = torch.max(logits.data, dim=1)\n","            n_correct += calcuate_accu(argmax_idx, labels)\n","    del logits\n","    return mean_loss / count, n_correct / len(dataloader.dataset)\n","  \n","# Function to calcuate the accuracy of the model\n","def calcuate_accu(big_idx, targets):\n","    n_correct = (big_idx==targets).sum().item()\n","    return n_correct"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":271,"status":"ok","timestamp":1636040507768,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"NNBTL2IC8PMJ"},"outputs":[],"source":["def train_bert(net, criterion, opti, lr, lr_scheduler, train_loader, val_loader, epochs, iters_to_accumulate):\n","\n","    best_loss = np.Inf\n","    best_acc = 0\n","    best_ep = 1\n","    n_iterations = len(train_loader)\n","    batch_size = train_loader.batch_size\n","    print_every = 1000 // batch_size  # print the training loss this many times per epoch\n","    print_eval_iters = 10000 // batch_size\n","    scaler = GradScaler()\n","\n","    for ep in range(epochs):\n","        net.train()\n","        curr_loss = 0.0\n","        curr_n_correct = 0.\n","        trailing_loss = 0.\n","        trailing_n_correct = 0.\n","        curr_n_tr_examples = 0\n","        trainling_n_tr_examples = 0\n","\n","        for it, (seq, attn_masks, token_type_ids, labels) in enumerate(tqdm(train_loader)):\n","            # Converting to cuda tensors\n","            seq, attn_masks, token_type_ids, labels = \\\n","                seq.to(device), attn_masks.to(device), token_type_ids.to(device), labels.to(device)\n","  \n","            # Enables autocasting for the forward pass (model + loss)\n","            with autocast():\n","                # Obtaining the logits from the model\n","                pooled = net(seq, attn_masks, token_type_ids)\n","\n","                # Computing loss\n","                loss = criterion(pooled.squeeze(-1), labels)\n","                #print(loss, type(loss))\n","                loss = loss / iters_to_accumulate  # Normalize the loss because it is averaged\n","                # Computing accuracy\n","                #print(pooled.squeeze(-1), labels)\n","                curr_loss += loss.item() \n","                big_val, big_idx = torch.max(pooled.data, dim=1)\n","                n_correct = calcuate_accu(big_idx, labels)\n","                curr_n_correct += n_correct\n","\n","            trailing_loss += loss.item() \n","            trailing_n_correct += n_correct\n","            curr_n_tr_examples += labels.size(0)\n","            trainling_n_tr_examples += labels.size(0)\n","\n","            # Backpropagating the gradients\n","            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n","            scaler.scale(loss).backward()\n","\n","            if (it + 1) % iters_to_accumulate == 0:\n","                # Optimization step\n","                # scaler.step() first unscales the gradients of the optimizer's assigned params.\n","                # If these gradients do not contain infs or NaNs, opti.step() is then called,\n","                # otherwise, opti.step() is skipped.\n","                scaler.step(opti)\n","                # Updates the scale for next iteration.\n","                scaler.update()\n","                # Adjust the learning rate based on the number of iterations.\n","                lr_scheduler.step()\n","                # Clear gradients\n","                opti.zero_grad()\n","\n","            if (it + 1) % print_every == 0:  # Print training loss information\n","                print()\n","                print(\"Batch {}/{} of epoch {} complete. Loss per last {} samples:: {} \"\n","                      .format(it+1, n_iterations, ep+1, curr_n_tr_examples, curr_loss / print_every))\n","                accu_step = (curr_n_correct*100) / curr_n_tr_examples \n","                #print(f\"Training Loss per 5000 steps: {loss_step}\")\n","                print(f\"Training Accuracy per last {curr_n_tr_examples} samples: {accu_step}\")\n","                curr_loss = 0.0\n","                curr_n_tr_examples = 0\n","                curr_n_correct = 0\n","\n","\n","            if (it + 1) % print_eval_iters == 0 or it ==  n_iterations - 1:\n","                del pooled, loss\n","                print(\"Epoch {}, batch {} complete! Training Loss : {}\"\n","                .format(ep+1, it+1, trailing_loss / (it+1)))\n","                print(\"Epoch {}, batch {} complete! Training Accuracy : {}\"\n","                .format(ep+1, it+1, trailing_n_correct / trainling_n_tr_examples))\n","                val_loss, val_accuracy = evaluate_loss(net, device, criterion, val_loader)  # Compute validation loss\n","                #print()\n","                print(\"Epoch {}, batch {} complete! Validation Loss : {}\".format(ep+1, it+1, val_loss))\n","                print(\"Epoch {}, batch {} complete! Validation Accuracy : {}\".format(ep+1, it+1,val_accuracy))\n","                net.train()\n","                #if val_loss < best_loss:\n","                if val_accuracy > best_acc:\n","                    print(\"Validation loss changed from {} to {}\".format(best_loss, val_loss))\n","                    print(\"Best validation accuracy improved from {} to {}\".format(best_acc, val_accuracy))\n","                    print()\n","                    #net_copy = copy.deepcopy(net)  # save a copy of the model\n","                    best_loss = val_loss\n","                    best_acc = val_accuracy\n","                    best_ep = ep + 1\n","                    # Saving the model\n","                    path_to_model='models/{}_lr_{}_val_acc_{}_ep_{}.pt'.format(time.ctime(), lr, round(best_acc, 4), best_ep)\n","                    torch.save(net.state_dict(), path_to_model)\n","                    print(\"The model has been saved in {}\".format(path_to_model))\n","\n","    torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["3d8a373f8b1a4da3841d55ed5fd62935","5435b27f9fab4fcd9f0cf0fe1f11db71","b968066f8f924c309860b111ae0816a4","98ff0c5dbe8049c588ef631dfbc08ef8","121075183d2441ddb2e99f849d2e9686","77b7765f0fe04c8a976230fb2eb01065","88b743167cd44b318de6a3998f466556","ef630b6fc27b4750839918ef7ac13c6c","e55762599f664a0fa5288de998af11c1","e3aeb80a52bf4ccdb69330b3ebce4355","7f4f04df6382427288c4e9422e4fbf7d"]},"executionInfo":{"elapsed":1839309,"status":"ok","timestamp":1636039351577,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"tV_3pDzJ81v9","outputId":"5413e47a-47a4-4216-9f14-592c6d734425"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading training data...\n","Reading validation data...\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at sberbank-ai/ruBert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["cuda:0\n"]}],"source":["from transformers import get_linear_schedule_with_warmup\n","from transformers import get_constant_schedule\n","#  Set all seeds to make reproducible results\n","set_seed(1)\n","\n","# Creating instances of training and validation set\n","print(\"Reading training data...\")\n","#train_set = FriendsDataset(dataframe=df_train, tokenizer=tokenizer, max_length=MAX_LEN)\n","train_set = FriendsDataset(dataframe=df_full, tokenizer=tokenizer, max_length=MAX_LEN)\n","\n","print(\"Reading validation data...\")\n","val_set = FriendsDataset(dataframe=df_val, tokenizer=tokenizer, max_length=MAX_LEN)\n","# Creating instances of training and validation dataloaders\n","train_loader = DataLoader(train_set, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_set, batch_size=VALID_BATCH_SIZE, shuffle=False, num_workers=2)\n","\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","net = SentencePairClassifier(model=CHECKPOINT, freeze_model=False)\n","print(device)\n","\n","if torch.cuda.device_count() > 1:  # if multiple GPUs\n","    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n","    net = nn.DataParallel(net)\n","\n","net.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","opti = AdamW(net.parameters(), lr=LEARNING_RATE, weight_decay=1e-2)\n","num_warmup_steps = 0 # The number of steps for the warmup phase.\n","iters_to_accumulate = 2\n","num_training_steps = EPOCHS * len(train_loader)  # The total number of training steps\n","t_total = (len(train_loader) // iters_to_accumulate) * EPOCHS  # Necessary to take into account Gradient accumulation\n","#lr_scheduler = get_linear_schedule_with_warmup(optimizer=opti, num_warmup_steps=num_warmup_steps, num_training_steps=t_total)\n","lr_scheduler = get_constant_schedule(optimizer=opti)\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  4%|▎         | 62/1736 [00:43<19:45,  1.41it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 62/1736 of epoch 1 complete. Loss per last 992 samples:: 0.9142559420677924 \n","Training Accuracy per last 992 samples: 16.532258064516128\n"]},{"name":"stderr","output_type":"stream","text":["  7%|▋         | 124/1736 [01:27<18:55,  1.42it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 124/1736 of epoch 1 complete. Loss per last 992 samples:: 0.9017220774004536 \n","Training Accuracy per last 992 samples: 17.842741935483872\n"]},{"name":"stderr","output_type":"stream","text":[" 11%|█         | 186/1736 [02:09<17:19,  1.49it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 186/1736 of epoch 1 complete. Loss per last 992 samples:: 0.8977102464245211 \n","Training Accuracy per last 992 samples: 18.447580645161292\n"]},{"name":"stderr","output_type":"stream","text":[" 14%|█▍        | 248/1736 [02:50<16:34,  1.50it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 248/1736 of epoch 1 complete. Loss per last 992 samples:: 0.9006879252772177 \n","Training Accuracy per last 992 samples: 17.641129032258064\n"]},{"name":"stderr","output_type":"stream","text":[" 18%|█▊        | 310/1736 [03:32<15:54,  1.49it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 310/1736 of epoch 1 complete. Loss per last 992 samples:: 0.8991797662550404 \n","Training Accuracy per last 992 samples: 19.052419354838708\n"]},{"name":"stderr","output_type":"stream","text":[" 21%|██▏       | 372/1736 [04:13<14:43,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 372/1736 of epoch 1 complete. Loss per last 992 samples:: 0.9015458629977319 \n","Training Accuracy per last 992 samples: 18.649193548387096\n"]},{"name":"stderr","output_type":"stream","text":[" 25%|██▌       | 434/1736 [04:53<14:05,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 434/1736 of epoch 1 complete. Loss per last 992 samples:: 0.8988888648248488 \n","Training Accuracy per last 992 samples: 17.43951612903226\n"]},{"name":"stderr","output_type":"stream","text":[" 29%|██▊       | 496/1736 [05:33<13:22,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 496/1736 of epoch 1 complete. Loss per last 992 samples:: 0.8943131969821069 \n","Training Accuracy per last 992 samples: 20.463709677419356\n"]},{"name":"stderr","output_type":"stream","text":[" 32%|███▏      | 558/1736 [06:12<12:43,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 558/1736 of epoch 1 complete. Loss per last 992 samples:: 0.8846824399886593 \n","Training Accuracy per last 992 samples: 22.580645161290324\n"]},{"name":"stderr","output_type":"stream","text":[" 35%|███▍      | 603/1736 [06:41<12:04,  1.56it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 36%|███▌      | 620/1736 [06:52<12:05,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 620/1736 of epoch 1 complete. Loss per last 992 samples:: 0.8935738840410786 \n","Training Accuracy per last 992 samples: 19.556451612903224\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▌      | 624/1736 [06:55<12:03,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 625 complete! Training Loss : 0.8986157470703126\n","Epoch 1, batch 625 complete! Training Accuracy : 0.1887\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 625 complete! Validation Loss : 1.7546246408045978\n","Epoch 1, batch 625 complete! Validation Accuracy : 0.25593952483801297\n","Validation loss changed from inf to 1.7546246408045978\n","Best validation accuracy improved from 0 to 0.25593952483801297\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▌      | 625/1736 [07:36<3:53:28, 12.61s/it]"]},{"name":"stdout","output_type":"stream","text":["The model has been saved in models/Fri Nov  5 23:58:53 2021_lr_2e-05_val_acc_0.2559_ep_1.pt\n"]},{"name":"stderr","output_type":"stream","text":[" 39%|███▉      | 682/1736 [08:12<11:24,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 682/1736 of epoch 1 complete. Loss per last 992 samples:: 0.890287829983619 \n","Training Accuracy per last 992 samples: 20.06048387096774\n"]},{"name":"stderr","output_type":"stream","text":[" 43%|████▎     | 744/1736 [08:52<11:01,  1.50it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 744/1736 of epoch 1 complete. Loss per last 992 samples:: 0.8921393117597026 \n","Training Accuracy per last 992 samples: 20.06048387096774\n"]},{"name":"stderr","output_type":"stream","text":[" 46%|████▋     | 806/1736 [09:33<10:04,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 806/1736 of epoch 1 complete. Loss per last 992 samples:: 0.897947988202495 \n","Training Accuracy per last 992 samples: 21.975806451612904\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 868/1736 [10:13<09:34,  1.51it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 868/1736 of epoch 1 complete. Loss per last 992 samples:: 0.8831523772208921 \n","Training Accuracy per last 992 samples: 22.379032258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 54%|█████▎    | 930/1736 [10:53<08:43,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 930/1736 of epoch 1 complete. Loss per last 992 samples:: 0.8777606102728075 \n","Training Accuracy per last 992 samples: 25.806451612903224\n"]},{"name":"stderr","output_type":"stream","text":[" 57%|█████▋    | 992/1736 [11:33<08:03,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 992/1736 of epoch 1 complete. Loss per last 992 samples:: 0.8713051580613659 \n","Training Accuracy per last 992 samples: 25.907258064516128\n"]},{"name":"stderr","output_type":"stream","text":[" 59%|█████▉    | 1021/1736 [11:52<07:38,  1.56it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 61%|██████    | 1054/1736 [12:13<07:22,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1054/1736 of epoch 1 complete. Loss per last 992 samples:: 0.8736240017798639 \n","Training Accuracy per last 992 samples: 25.504032258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 64%|██████▍   | 1116/1736 [12:53<06:43,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1116/1736 of epoch 1 complete. Loss per last 992 samples:: 0.8692367307601436 \n","Training Accuracy per last 992 samples: 25.302419354838708\n"]},{"name":"stderr","output_type":"stream","text":[" 68%|██████▊   | 1178/1736 [13:33<06:01,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1178/1736 of epoch 1 complete. Loss per last 992 samples:: 0.8587212101105721 \n","Training Accuracy per last 992 samples: 28.629032258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 71%|███████▏  | 1240/1736 [14:13<05:22,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1240/1736 of epoch 1 complete. Loss per last 992 samples:: 0.8501249744046119 \n","Training Accuracy per last 992 samples: 28.024193548387096\n"]},{"name":"stderr","output_type":"stream","text":[" 72%|███████▏  | 1249/1736 [14:19<05:11,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 1250 complete! Training Loss : 0.8871855224609375\n","Epoch 1, batch 1250 complete! Training Accuracy : 0.2166\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 1250 complete! Validation Loss : 1.6296639278017242\n","Epoch 1, batch 1250 complete! Validation Accuracy : 0.3362131029517639\n","Validation loss changed from 1.7546246408045978 to 1.6296639278017242\n","Best validation accuracy improved from 0.25593952483801297 to 0.3362131029517639\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 72%|███████▏  | 1250/1736 [15:00<1:42:14, 12.62s/it]"]},{"name":"stdout","output_type":"stream","text":["The model has been saved in models/Sat Nov  6 00:06:17 2021_lr_2e-05_val_acc_0.3362_ep_1.pt\n"]},{"name":"stderr","output_type":"stream","text":[" 75%|███████▌  | 1302/1736 [15:33<04:55,  1.47it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1302/1736 of epoch 1 complete. Loss per last 992 samples:: 0.8515250913558468 \n","Training Accuracy per last 992 samples: 28.528225806451612\n"]},{"name":"stderr","output_type":"stream","text":[" 79%|███████▊  | 1364/1736 [16:14<04:01,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1364/1736 of epoch 1 complete. Loss per last 992 samples:: 0.8515413345829133 \n","Training Accuracy per last 992 samples: 25.60483870967742\n"]},{"name":"stderr","output_type":"stream","text":[" 82%|████████▏ | 1426/1736 [16:53<03:20,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1426/1736 of epoch 1 complete. Loss per last 992 samples:: 0.860899156139743 \n","Training Accuracy per last 992 samples: 24.697580645161292\n"]},{"name":"stderr","output_type":"stream","text":[" 86%|████████▌ | 1488/1736 [17:33<02:41,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1488/1736 of epoch 1 complete. Loss per last 992 samples:: 0.8488450819446195 \n","Training Accuracy per last 992 samples: 28.931451612903224\n"]},{"name":"stderr","output_type":"stream","text":[" 89%|████████▉ | 1542/1736 [18:08<02:06,  1.54it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 89%|████████▉ | 1550/1736 [18:14<02:01,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1550/1736 of epoch 1 complete. Loss per last 992 samples:: 0.8311971849010836 \n","Training Accuracy per last 992 samples: 32.056451612903224\n"]},{"name":"stderr","output_type":"stream","text":[" 93%|█████████▎| 1612/1736 [18:53<01:20,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1612/1736 of epoch 1 complete. Loss per last 992 samples:: 0.839141599593624 \n","Training Accuracy per last 992 samples: 30.64516129032258\n"]},{"name":"stderr","output_type":"stream","text":[" 96%|█████████▋| 1674/1736 [19:33<00:40,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1674/1736 of epoch 1 complete. Loss per last 992 samples:: 0.8388410383655179 \n","Training Accuracy per last 992 samples: 29.032258064516128\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 1735/1736 [20:13<00:00,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1736/1736 of epoch 1 complete. Loss per last 987 samples:: 0.8412499129772186 \n","Training Accuracy per last 987 samples: 33.232016210739616\n","Epoch 1, batch 1736 complete! Training Loss : 0.8755035999527175\n","Epoch 1, batch 1736 complete! Training Accuracy : 0.23733390947391164\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, batch 1736 complete! Validation Loss : 1.5837430405890804\n","Epoch 1, batch 1736 complete! Validation Accuracy : 0.3722102231821454\n","Validation loss changed from 1.6296639278017242 to 1.5837430405890804\n","Best validation accuracy improved from 0.3362131029517639 to 0.3722102231821454\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1736/1736 [20:54<00:00,  1.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["The model has been saved in models/Sat Nov  6 00:12:11 2021_lr_2e-05_val_acc_0.3722_ep_1.pt\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▎         | 62/1736 [00:40<18:05,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 62/1736 of epoch 2 complete. Loss per last 992 samples:: 0.8069820404052734 \n","Training Accuracy per last 992 samples: 35.181451612903224\n"]},{"name":"stderr","output_type":"stream","text":["  7%|▋         | 124/1736 [01:20<17:27,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 124/1736 of epoch 2 complete. Loss per last 992 samples:: 0.8048092626756237 \n","Training Accuracy per last 992 samples: 34.274193548387096\n"]},{"name":"stderr","output_type":"stream","text":[" 11%|█         | 186/1736 [02:00<16:47,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 186/1736 of epoch 2 complete. Loss per last 992 samples:: 0.8007730053317162 \n","Training Accuracy per last 992 samples: 35.08064516129032\n"]},{"name":"stderr","output_type":"stream","text":[" 14%|█▍        | 248/1736 [02:40<16:07,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 248/1736 of epoch 2 complete. Loss per last 992 samples:: 0.8188519016388924 \n","Training Accuracy per last 992 samples: 35.38306451612903\n"]},{"name":"stderr","output_type":"stream","text":[" 18%|█▊        | 310/1736 [03:20<15:25,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 310/1736 of epoch 2 complete. Loss per last 992 samples:: 0.8051538775044103 \n","Training Accuracy per last 992 samples: 33.770161290322584\n"]},{"name":"stderr","output_type":"stream","text":[" 21%|██▏       | 372/1736 [04:00<14:43,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 372/1736 of epoch 2 complete. Loss per last 992 samples:: 0.7766296940465127 \n","Training Accuracy per last 992 samples: 39.01209677419355\n"]},{"name":"stderr","output_type":"stream","text":[" 25%|██▌       | 434/1736 [04:40<14:03,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 434/1736 of epoch 2 complete. Loss per last 992 samples:: 0.7839053676974389 \n","Training Accuracy per last 992 samples: 35.38306451612903\n"]},{"name":"stderr","output_type":"stream","text":[" 29%|██▊       | 496/1736 [05:20<13:43,  1.51it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 496/1736 of epoch 2 complete. Loss per last 992 samples:: 0.7983154173820249 \n","Training Accuracy per last 992 samples: 35.88709677419355\n"]},{"name":"stderr","output_type":"stream","text":[" 32%|███▏      | 558/1736 [06:00<12:44,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 558/1736 of epoch 2 complete. Loss per last 992 samples:: 0.7827376704062184 \n","Training Accuracy per last 992 samples: 37.5\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▌      | 620/1736 [06:40<12:05,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 620/1736 of epoch 2 complete. Loss per last 992 samples:: 0.7769500363257623 \n","Training Accuracy per last 992 samples: 38.104838709677416\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▌      | 624/1736 [06:43<12:03,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 625 complete! Training Loss : 0.7948761047363281\n","Epoch 2, batch 625 complete! Training Accuracy : 0.3604\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 625 complete! Validation Loss : 1.451727505387931\n","Epoch 2, batch 625 complete! Validation Accuracy : 0.4528437724982001\n","Validation loss changed from 1.5837430405890804 to 1.451727505387931\n","Best validation accuracy improved from 0.3722102231821454 to 0.4528437724982001\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▌      | 625/1736 [07:23<3:53:41, 12.62s/it]"]},{"name":"stdout","output_type":"stream","text":["The model has been saved in models/Sat Nov  6 00:19:34 2021_lr_2e-05_val_acc_0.4528_ep_2.pt\n"]},{"name":"stderr","output_type":"stream","text":[" 39%|███▉      | 682/1736 [08:00<11:21,  1.55it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 682/1736 of epoch 2 complete. Loss per last 992 samples:: 0.7949572224770823 \n","Training Accuracy per last 992 samples: 34.778225806451616\n"]},{"name":"stderr","output_type":"stream","text":[" 43%|████▎     | 744/1736 [08:40<10:42,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 744/1736 of epoch 2 complete. Loss per last 992 samples:: 0.772640505144673 \n","Training Accuracy per last 992 samples: 36.189516129032256\n"]},{"name":"stderr","output_type":"stream","text":[" 45%|████▍     | 780/1736 [09:03<10:20,  1.54it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 46%|████▋     | 806/1736 [09:20<10:02,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 806/1736 of epoch 2 complete. Loss per last 992 samples:: 0.7756284590690367 \n","Training Accuracy per last 992 samples: 37.70161290322581\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 868/1736 [10:00<09:23,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 868/1736 of epoch 2 complete. Loss per last 992 samples:: 0.8023288788334015 \n","Training Accuracy per last 992 samples: 34.57661290322581\n"]},{"name":"stderr","output_type":"stream","text":[" 54%|█████▎    | 930/1736 [10:40<08:43,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 930/1736 of epoch 2 complete. Loss per last 992 samples:: 0.7891144291047127 \n","Training Accuracy per last 992 samples: 35.28225806451613\n"]},{"name":"stderr","output_type":"stream","text":[" 57%|█████▋    | 992/1736 [11:20<08:03,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 992/1736 of epoch 2 complete. Loss per last 992 samples:: 0.814882093860257 \n","Training Accuracy per last 992 samples: 32.25806451612903\n"]},{"name":"stderr","output_type":"stream","text":[" 61%|██████    | 1051/1736 [11:59<07:18,  1.56it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 61%|██████    | 1054/1736 [12:01<07:25,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1054/1736 of epoch 2 complete. Loss per last 992 samples:: 0.7836554434991652 \n","Training Accuracy per last 992 samples: 37.600806451612904\n"]},{"name":"stderr","output_type":"stream","text":[" 64%|██████▍   | 1116/1736 [12:41<06:42,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1116/1736 of epoch 2 complete. Loss per last 992 samples:: 0.7634975987095987 \n","Training Accuracy per last 992 samples: 38.70967741935484\n"]},{"name":"stderr","output_type":"stream","text":[" 68%|██████▊   | 1178/1736 [13:20<06:02,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1178/1736 of epoch 2 complete. Loss per last 992 samples:: 0.788209730579007 \n","Training Accuracy per last 992 samples: 37.19758064516129\n"]},{"name":"stderr","output_type":"stream","text":[" 71%|███████▏  | 1240/1736 [14:00<05:22,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1240/1736 of epoch 2 complete. Loss per last 992 samples:: 0.7837414280060799 \n","Training Accuracy per last 992 samples: 35.28225806451613\n"]},{"name":"stderr","output_type":"stream","text":[" 72%|███████▏  | 1249/1736 [14:06<05:11,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 1250 complete! Training Loss : 0.7909677093505859\n","Epoch 2, batch 1250 complete! Training Accuracy : 0.35985\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 1250 complete! Validation Loss : 1.3701171875\n","Epoch 2, batch 1250 complete! Validation Accuracy : 0.5003599712023038\n","Validation loss changed from 1.451727505387931 to 1.3701171875\n","Best validation accuracy improved from 0.4528437724982001 to 0.5003599712023038\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 72%|███████▏  | 1250/1736 [14:47<1:41:50, 12.57s/it]"]},{"name":"stdout","output_type":"stream","text":["The model has been saved in models/Sat Nov  6 00:26:58 2021_lr_2e-05_val_acc_0.5004_ep_2.pt\n"]},{"name":"stderr","output_type":"stream","text":[" 75%|███████▌  | 1302/1736 [15:20<04:42,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1302/1736 of epoch 2 complete. Loss per last 992 samples:: 0.7926104760939076 \n","Training Accuracy per last 992 samples: 34.57661290322581\n"]},{"name":"stderr","output_type":"stream","text":[" 79%|███████▊  | 1364/1736 [16:00<04:01,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1364/1736 of epoch 2 complete. Loss per last 992 samples:: 0.7930367377496534 \n","Training Accuracy per last 992 samples: 34.87903225806452\n"]},{"name":"stderr","output_type":"stream","text":[" 82%|████████▏ | 1416/1736 [16:34<03:27,  1.54it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 82%|████████▏ | 1426/1736 [16:40<03:21,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1426/1736 of epoch 2 complete. Loss per last 992 samples:: 0.7733944616010112 \n","Training Accuracy per last 992 samples: 38.810483870967744\n"]},{"name":"stderr","output_type":"stream","text":[" 86%|████████▌ | 1488/1736 [17:20<02:40,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1488/1736 of epoch 2 complete. Loss per last 992 samples:: 0.7829858103106099 \n","Training Accuracy per last 992 samples: 36.895161290322584\n"]},{"name":"stderr","output_type":"stream","text":[" 89%|████████▉ | 1550/1736 [18:00<02:01,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1550/1736 of epoch 2 complete. Loss per last 992 samples:: 0.7747752897201046 \n","Training Accuracy per last 992 samples: 38.50806451612903\n"]},{"name":"stderr","output_type":"stream","text":[" 93%|█████████▎| 1612/1736 [18:40<01:20,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1612/1736 of epoch 2 complete. Loss per last 992 samples:: 0.7715068632556547 \n","Training Accuracy per last 992 samples: 37.600806451612904\n"]},{"name":"stderr","output_type":"stream","text":[" 96%|█████████▋| 1674/1736 [19:20<00:40,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1674/1736 of epoch 2 complete. Loss per last 992 samples:: 0.7936443821076424 \n","Training Accuracy per last 992 samples: 36.693548387096776\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 1735/1736 [20:00<00:00,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1736/1736 of epoch 2 complete. Loss per last 987 samples:: 0.7790754995038432 \n","Training Accuracy per last 987 samples: 38.095238095238095\n","Epoch 2, batch 1736 complete! Training Loss : 0.7887426279656898\n","Epoch 2, batch 1736 complete! Training Accuracy : 0.36257246768211443\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, batch 1736 complete! Validation Loss : 1.30810546875\n","Epoch 2, batch 1736 complete! Validation Accuracy : 0.5212383009359252\n","Validation loss changed from 1.3701171875 to 1.30810546875\n","Best validation accuracy improved from 0.5003599712023038 to 0.5212383009359252\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1736/1736 [20:40<00:00,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["The model has been saved in models/Sat Nov  6 00:32:51 2021_lr_2e-05_val_acc_0.5212_ep_2.pt\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▎         | 62/1736 [00:40<18:06,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 62/1736 of epoch 3 complete. Loss per last 992 samples:: 0.6768753913141066 \n","Training Accuracy per last 992 samples: 49.09274193548387\n"]},{"name":"stderr","output_type":"stream","text":["  7%|▋         | 124/1736 [01:20<17:23,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 124/1736 of epoch 3 complete. Loss per last 992 samples:: 0.6816564067717521 \n","Training Accuracy per last 992 samples: 49.395161290322584\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 146/1736 [01:34<17:09,  1.54it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 11%|█         | 186/1736 [02:00<16:44,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 186/1736 of epoch 3 complete. Loss per last 992 samples:: 0.6706525433448053 \n","Training Accuracy per last 992 samples: 48.99193548387097\n"]},{"name":"stderr","output_type":"stream","text":[" 14%|█▍        | 248/1736 [02:40<16:04,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 248/1736 of epoch 3 complete. Loss per last 992 samples:: 0.6693052476452243 \n","Training Accuracy per last 992 samples: 49.596774193548384\n"]},{"name":"stderr","output_type":"stream","text":[" 18%|█▊        | 310/1736 [03:20<15:27,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 310/1736 of epoch 3 complete. Loss per last 992 samples:: 0.6565530530868038 \n","Training Accuracy per last 992 samples: 51.20967741935484\n"]},{"name":"stderr","output_type":"stream","text":[" 21%|██▏       | 372/1736 [04:00<14:45,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 372/1736 of epoch 3 complete. Loss per last 992 samples:: 0.6532707829629222 \n","Training Accuracy per last 992 samples: 50.70564516129032\n"]},{"name":"stderr","output_type":"stream","text":[" 25%|██▌       | 434/1736 [04:40<14:03,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 434/1736 of epoch 3 complete. Loss per last 992 samples:: 0.6828036000651698 \n","Training Accuracy per last 992 samples: 47.78225806451613\n"]},{"name":"stderr","output_type":"stream","text":[" 29%|██▊       | 496/1736 [05:20<13:23,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 496/1736 of epoch 3 complete. Loss per last 992 samples:: 0.6695453274634576 \n","Training Accuracy per last 992 samples: 49.899193548387096\n"]},{"name":"stderr","output_type":"stream","text":[" 32%|███▏      | 558/1736 [06:00<12:44,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 558/1736 of epoch 3 complete. Loss per last 992 samples:: 0.6772743194333969 \n","Training Accuracy per last 992 samples: 47.37903225806452\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▌      | 620/1736 [06:40<12:03,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 620/1736 of epoch 3 complete. Loss per last 992 samples:: 0.6840108133131458 \n","Training Accuracy per last 992 samples: 47.983870967741936\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▌      | 624/1736 [06:42<12:03,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 625 complete! Training Loss : 0.672509683227539\n","Epoch 3, batch 625 complete! Training Accuracy : 0.4917\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 625 complete! Validation Loss : 1.1083872126436782\n","Epoch 3, batch 625 complete! Validation Accuracy : 0.615190784737221\n","Validation loss changed from 1.30810546875 to 1.1083872126436782\n","Best validation accuracy improved from 0.5212383009359252 to 0.615190784737221\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▌      | 625/1736 [07:23<3:54:09, 12.65s/it]"]},{"name":"stdout","output_type":"stream","text":["The model has been saved in models/Sat Nov  6 00:40:15 2021_lr_2e-05_val_acc_0.6152_ep_3.pt\n"]},{"name":"stderr","output_type":"stream","text":[" 39%|███▉      | 682/1736 [08:00<11:24,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 682/1736 of epoch 3 complete. Loss per last 992 samples:: 0.6626892397480626 \n","Training Accuracy per last 992 samples: 49.49596774193548\n"]},{"name":"stderr","output_type":"stream","text":[" 43%|████▎     | 744/1736 [08:40<10:45,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 744/1736 of epoch 3 complete. Loss per last 992 samples:: 0.6731918242669874 \n","Training Accuracy per last 992 samples: 47.78225806451613\n"]},{"name":"stderr","output_type":"stream","text":[" 46%|████▋     | 806/1736 [09:20<10:31,  1.47it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 806/1736 of epoch 3 complete. Loss per last 992 samples:: 0.6798993079893051 \n","Training Accuracy per last 992 samples: 47.88306451612903\n"]},{"name":"stderr","output_type":"stream","text":[" 49%|████▊     | 845/1736 [09:45<09:31,  1.56it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 50%|█████     | 868/1736 [10:00<09:24,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 868/1736 of epoch 3 complete. Loss per last 992 samples:: 0.6515380797847625 \n","Training Accuracy per last 992 samples: 51.00806451612903\n"]},{"name":"stderr","output_type":"stream","text":[" 54%|█████▎    | 930/1736 [10:40<08:42,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 930/1736 of epoch 3 complete. Loss per last 992 samples:: 0.6720427697704684 \n","Training Accuracy per last 992 samples: 47.58064516129032\n"]},{"name":"stderr","output_type":"stream","text":[" 55%|█████▌    | 957/1736 [10:57<08:20,  1.56it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 57%|█████▋    | 992/1736 [11:20<08:05,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 992/1736 of epoch 3 complete. Loss per last 992 samples:: 0.6550033784681751 \n","Training Accuracy per last 992 samples: 49.69758064516129\n"]},{"name":"stderr","output_type":"stream","text":[" 61%|██████    | 1054/1736 [12:00<07:22,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1054/1736 of epoch 3 complete. Loss per last 992 samples:: 0.66969879211918 \n","Training Accuracy per last 992 samples: 48.48790322580645\n"]},{"name":"stderr","output_type":"stream","text":[" 64%|██████▍   | 1116/1736 [12:40<06:42,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1116/1736 of epoch 3 complete. Loss per last 992 samples:: 0.6956402870916552 \n","Training Accuracy per last 992 samples: 46.57258064516129\n"]},{"name":"stderr","output_type":"stream","text":[" 68%|██████▊   | 1178/1736 [13:20<06:01,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1178/1736 of epoch 3 complete. Loss per last 992 samples:: 0.6784681043317241 \n","Training Accuracy per last 992 samples: 48.08467741935484\n"]},{"name":"stderr","output_type":"stream","text":[" 71%|███████▏  | 1240/1736 [14:00<05:21,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1240/1736 of epoch 3 complete. Loss per last 992 samples:: 0.6868589001317178 \n","Training Accuracy per last 992 samples: 47.37903225806452\n"]},{"name":"stderr","output_type":"stream","text":[" 72%|███████▏  | 1249/1736 [14:06<05:11,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 1250 complete! Training Loss : 0.6725999572753906\n","Epoch 3, batch 1250 complete! Training Accuracy : 0.48745\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 1250 complete! Validation Loss : 0.9910509832974138\n","Epoch 3, batch 1250 complete! Validation Accuracy : 0.6882649388048956\n","Validation loss changed from 1.1083872126436782 to 0.9910509832974138\n","Best validation accuracy improved from 0.615190784737221 to 0.6882649388048956\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 72%|███████▏  | 1250/1736 [14:47<1:42:54, 12.70s/it]"]},{"name":"stdout","output_type":"stream","text":["The model has been saved in models/Sat Nov  6 00:47:38 2021_lr_2e-05_val_acc_0.6883_ep_3.pt\n"]},{"name":"stderr","output_type":"stream","text":[" 75%|███████▌  | 1302/1736 [15:20<04:41,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1302/1736 of epoch 3 complete. Loss per last 992 samples:: 0.6839275052470546 \n","Training Accuracy per last 992 samples: 47.88306451612903\n"]},{"name":"stderr","output_type":"stream","text":[" 79%|███████▊  | 1364/1736 [16:00<04:02,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1364/1736 of epoch 3 complete. Loss per last 992 samples:: 0.6840720176696777 \n","Training Accuracy per last 992 samples: 48.891129032258064\n"]},{"name":"stderr","output_type":"stream","text":[" 82%|████████▏ | 1426/1736 [16:40<03:21,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1426/1736 of epoch 3 complete. Loss per last 992 samples:: 0.6924420018349925 \n","Training Accuracy per last 992 samples: 44.45564516129032\n"]},{"name":"stderr","output_type":"stream","text":[" 86%|████████▌ | 1488/1736 [17:21<02:40,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1488/1736 of epoch 3 complete. Loss per last 992 samples:: 0.6624703099650722 \n","Training Accuracy per last 992 samples: 50.30241935483871\n"]},{"name":"stderr","output_type":"stream","text":[" 89%|████████▉ | 1550/1736 [18:01<02:00,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1550/1736 of epoch 3 complete. Loss per last 992 samples:: 0.6705495772823211 \n","Training Accuracy per last 992 samples: 49.29435483870968\n"]},{"name":"stderr","output_type":"stream","text":[" 93%|█████████▎| 1612/1736 [18:41<01:21,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1612/1736 of epoch 3 complete. Loss per last 992 samples:: 0.6711762335992628 \n","Training Accuracy per last 992 samples: 48.79032258064516\n"]},{"name":"stderr","output_type":"stream","text":[" 96%|█████████▋| 1674/1736 [19:21<00:40,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1674/1736 of epoch 3 complete. Loss per last 992 samples:: 0.6754532783262192 \n","Training Accuracy per last 992 samples: 48.38709677419355\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 1735/1736 [20:00<00:00,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Batch 1736/1736 of epoch 3 complete. Loss per last 987 samples:: 0.6797780471463357 \n","Training Accuracy per last 987 samples: 48.02431610942249\n","Epoch 3, batch 1736 complete! Training Loss : 0.6738159692919199\n","Epoch 3, batch 1736 complete! Training Accuracy : 0.4864426920168521\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:38<00:00,  4.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, batch 1736 complete! Validation Loss : 0.8625740840517241\n","Epoch 3, batch 1736 complete! Validation Accuracy : 0.751979841612671\n","Validation loss changed from 0.9910509832974138 to 0.8625740840517241\n","Best validation accuracy improved from 0.6882649388048956 to 0.751979841612671\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1736/1736 [20:41<00:00,  1.40it/s]"]},{"name":"stdout","output_type":"stream","text":["The model has been saved in models/Sat Nov  6 00:53:33 2021_lr_2e-05_val_acc_0.752_ep_3.pt\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["train_bert(net, criterion, opti, LEARNING_RATE, lr_scheduler, train_loader, val_loader, EPOCHS, iters_to_accumulate)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["torch.save(net.state_dict(), 'models/final_model.pt')"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":[" 37%|███▋      | 71/193 [00:16<00:27,  4.43it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","100%|██████████| 193/193 [00:43<00:00,  4.41it/s]\n"]}],"source":["test_set = FriendsDataset(dataframe=df_test, tokenizer=tokenizer, max_length=MAX_LEN)\n","test_loader = DataLoader(test_set, batch_size=VALID_BATCH_SIZE, shuffle=False, num_workers=1)\n","def predict(net, device, dataloader):\n","    net.eval()\n","    predictions = []\n","\n","    with torch.no_grad():\n","        for it, (seq, attn_masks, token_type_ids) in enumerate(tqdm(dataloader)):\n","            seq, attn_masks, token_type_ids = \\\n","                seq.to(device), attn_masks.to(device), token_type_ids.to(device)\n","            logits = net(seq, attn_masks, token_type_ids)\n","            max_logits, argmax_idx = torch.max(logits.data, dim=1)\n","            predictions.extend(argmax_idx.tolist())\n","    del logits\n","    return predictions\n","preds = predict(net, device, test_loader)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>other_speaker</th>\n","      <th>friend_response</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Но я безработный, моя музыка - это все, что у ...</td>\n","      <td>Меня застрелят. Любой совет?</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Посмотри. Пятьсот семнадцать коробок!</td>\n","      <td>Боже мой, как ты это сделал?</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Хорошо. Хорошо. Помогло бы, если бы я подошел ...</td>\n","      <td>Это было бы очень полезно!</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Росс, чего ты так долго?</td>\n","      <td>Простите, это как будто не для быстрого отдыха!</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Так кто ты?</td>\n","      <td>Ну, наши имена действительно Моника и Чендлер....</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3081</th>\n","      <td>3081</td>\n","      <td>Дело не только в барабанах. Каждые пять минут ...</td>\n","      <td>Понимаете, именно так нормальные люди должны р...</td>\n","    </tr>\n","    <tr>\n","      <th>3082</th>\n","      <td>3082</td>\n","      <td>Кажется, я случайно использовал коробки Моники...</td>\n","      <td>Боже, все испорчено! Папа, она будет раздавлена!</td>\n","    </tr>\n","    <tr>\n","      <th>3083</th>\n","      <td>3083</td>\n","      <td>ну знаете, вот почему через несколько лет расп...</td>\n","      <td>Ой, это так здорово.</td>\n","    </tr>\n","    <tr>\n","      <th>3084</th>\n","      <td>3084</td>\n","      <td>Он переспал с тобой, а потом никогда тебе не з...</td>\n","      <td>А я просто хотела нового папу для Дэви и Бекки.</td>\n","    </tr>\n","    <tr>\n","      <th>3085</th>\n","      <td>3085</td>\n","      <td>Я знаю, разве он не классный? Так приятно нако...</td>\n","      <td>Ну, может он скоро уедет, как в классную поезд...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3086 rows × 3 columns</p>\n","</div>"],"text/plain":["        Id                                      other_speaker  \\\n","0        0  Но я безработный, моя музыка - это все, что у ...   \n","1        1              Посмотри. Пятьсот семнадцать коробок!   \n","2        2  Хорошо. Хорошо. Помогло бы, если бы я подошел ...   \n","3        3                           Росс, чего ты так долго?   \n","4        4                                        Так кто ты?   \n","...    ...                                                ...   \n","3081  3081  Дело не только в барабанах. Каждые пять минут ...   \n","3082  3082  Кажется, я случайно использовал коробки Моники...   \n","3083  3083  ну знаете, вот почему через несколько лет расп...   \n","3084  3084  Он переспал с тобой, а потом никогда тебе не з...   \n","3085  3085  Я знаю, разве он не классный? Так приятно нако...   \n","\n","                                        friend_response  \n","0                          Меня застрелят. Любой совет?  \n","1                          Боже мой, как ты это сделал?  \n","2                            Это было бы очень полезно!  \n","3       Простите, это как будто не для быстрого отдыха!  \n","4     Ну, наши имена действительно Моника и Чендлер....  \n","...                                                 ...  \n","3081  Понимаете, именно так нормальные люди должны р...  \n","3082   Боже, все испорчено! Папа, она будет раздавлена!  \n","3083                               Ой, это так здорово.  \n","3084    А я просто хотела нового папу для Дэви и Бекки.  \n","3085  Ну, может он скоро уедет, как в классную поезд...  \n","\n","[3086 rows x 3 columns]"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["df_test"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Category</th>\n","    </tr>\n","    <tr>\n","      <th>Id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ФИБИ</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>МОНИКА</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>РЕЙЧЕЛ</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>РОСС</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ЧЕНДЛЕР</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3081</th>\n","      <td>ФИБИ</td>\n","    </tr>\n","    <tr>\n","      <th>3082</th>\n","      <td>МОНИКА</td>\n","    </tr>\n","    <tr>\n","      <th>3083</th>\n","      <td>РЕЙЧЕЛ</td>\n","    </tr>\n","    <tr>\n","      <th>3084</th>\n","      <td>МОНИКА</td>\n","    </tr>\n","    <tr>\n","      <th>3085</th>\n","      <td>РЕЙЧЕЛ</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3086 rows × 1 columns</p>\n","</div>"],"text/plain":["     Category\n","Id           \n","0        ФИБИ\n","1      МОНИКА\n","2      РЕЙЧЕЛ\n","3        РОСС\n","4     ЧЕНДЛЕР\n","...       ...\n","3081     ФИБИ\n","3082   МОНИКА\n","3083   РЕЙЧЕЛ\n","3084   МОНИКА\n","3085   РЕЙЧЕЛ\n","\n","[3086 rows x 1 columns]"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["answers = pd.DataFrame(\n","    names_to_cats.inverse_transform(preds), \n","    index=df_test.Id, columns=[\"Category\"])\n","answers.to_csv('submission1.csv')\n","answers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bxhl6QhJlbfE"},"outputs":[],"source":["from transformers import get_constant_schedule\n","opti = AdamW(net.parameters(), lr=LEARNING_RATE, weight_decay=1e-2)\n","lr_scheduler = get_constant_schedule(optimizer=opti)\n","train_set = FriendsDataset(dataframe=df_train.iloc[5000:], tokenizer=tokenizer, max_length=MAX_LEN)\n","\n","val_set = FriendsDataset(dataframe=df_val, tokenizer=tokenizer, max_length=MAX_LEN)\n","# Creating instances of training and validation dataloaders\n","train_loader = DataLoader(train_set, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_set, batch_size=VALID_BATCH_SIZE, shuffle=False, num_workers=2)\n","\n","train_bert(net, criterion, opti, LEARNING_RATE, lr_scheduler, train_loader, val_loader, EPOCHS, iters_to_accumulate)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":939,"status":"ok","timestamp":1636033344945,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"r6o9XkFVL6qD","outputId":"2c4ae139-f975-4f8c-e7b0-88897023e72e"},"outputs":[{"data":{"text/plain":["(1.7879175646551724, 0.1861051115910727)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["val_loss, val_accuracy"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":268,"status":"ok","timestamp":1636042247525,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"BnAB6Udp9Z-1"},"outputs":[],"source":["import gc\n","gc.collect()\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":448,"status":"ok","timestamp":1636024184045,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"VEInewq0pYTk","outputId":"f8944075-b0f8-41a9-8378-f5fc6d1f90fb"},"outputs":[{"data":{"text/plain":["8506.769408"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.get_device_properties(0).total_memory / 1e6"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11448,"status":"ok","timestamp":1635932769348,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"zYNBGqTwpoHn","outputId":"74b194fd-8d8b-4c9f-a35c-9d95859f2c6d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Gen RAM Free: 11.1 GB  | Proc size: 5.1 GB\n","GPU RAM Free: 10137MB | Used: 1304MB | Util  11% | Total 11441MB\n"]}],"source":["# Check that we are using 100% of GPU memory footprint support libraries/code\n","# from https://github.com/patrickvonplaten/notebooks/blob/master/PyTorch_Reformer.ipynb\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip -q install gputil\n","!pip -q install psutil\n","!pip -q install humanize\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isn’t guaranteed\n","gpu = GPUs[0]\n","def printm():\n"," process = psutil.Process(os.getpid())\n"," print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n"," print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm()\n"," #!kill -9 -1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":452,"status":"ok","timestamp":1635932801898,"user":{"displayName":"Andrew Argatkiny","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04422905123959661601"},"user_tz":-420},"id":"e9gyehyY6n8C","outputId":"0e7574a4-b8d7-44fa-8f06-717912d52d5a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Gen RAM Free: 11.1 GB  | Proc size: 5.1 GB\n","GPU RAM Free: 10137MB | Used: 1304MB | Util  11% | Total 11441MB\n"]}],"source":["printm()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v1kSrbCvMNDf"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNFzSvllZcK0G034IIhIOS7","collapsed_sections":[],"mount_file_id":"144h_eAZbCarOnrPb3zxIWY7HYm27TGhi","name":"FriendsPredictNLP","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0344eb1638a44fc0bd8be3d2b5aafc99":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2cbc04f6abc4b45b5374f424dd88efa","placeholder":"​","style":"IPY_MODEL_91647e75ea5e4c16a11046fda73ba026","value":" 521/521 [00:00&lt;00:00, 12.4kB/s]"}},"0f3925eaafb9438ab0f6b27c356cfe99":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82b0759acdb845ea9859d2f96ce0e5d3","placeholder":"​","style":"IPY_MODEL_487d23c4e2b64adda4a945df313d1ed1","value":" 1.70M/1.70M [00:00&lt;00:00, 7.10MB/s]"}},"121075183d2441ddb2e99f849d2e9686":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f4f04df6382427288c4e9422e4fbf7d","placeholder":"​","style":"IPY_MODEL_e3aeb80a52bf4ccdb69330b3ebce4355","value":" 683M/683M [00:23&lt;00:00, 32.0MB/s]"}},"158f6d85beec4b33bdc422ee9e115808":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e6a2c5306764e31bea3a9e37121ff8c","placeholder":"​","style":"IPY_MODEL_faaf710ce2cc471c9370811df2f54ba6","value":" 655/655 [00:00&lt;00:00, 15.7kB/s]"}},"192f33925dd045d792b38a2444794a10":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21bf688381ef4a8495a3a6981a84ef8d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_939389df612a4f23b8ab42d6dccd6c8d","max":323,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6c7f0e73512743efb870026d6677531e","value":323}},"269978945c9c48d280cd1eb1ddf2f7fc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d185bee7972497296fc31ba5c0d54d6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e6a2c5306764e31bea3a9e37121ff8c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"317c759beaf6494db054eae9162ccfb2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32acd792c0bf45419a87561dc4ccdb4c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d8a373f8b1a4da3841d55ed5fd62935":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b968066f8f924c309860b111ae0816a4","IPY_MODEL_98ff0c5dbe8049c588ef631dfbc08ef8","IPY_MODEL_121075183d2441ddb2e99f849d2e9686"],"layout":"IPY_MODEL_5435b27f9fab4fcd9f0cf0fe1f11db71"}},"4718ae66701049229c66c8506b3efe1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_65cbb712ea2f4dab90ba6600d8440c0b","placeholder":"​","style":"IPY_MODEL_d70b870ad108499e8651b57c9e9be34b","value":"Downloading: 100%"}},"487d23c4e2b64adda4a945df313d1ed1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e0b4d1769974ba88e49d4fb02e2c4a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"52e9ba2a4d974b15ae4b6ab1232dc256":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5435b27f9fab4fcd9f0cf0fe1f11db71":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54feb1dd180f4bf8b47c18713336d41c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58564c36a43e4f3ab99a0e153cb5e480":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58c863f270ac42c3b195987575a8bc9a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5e3622f69800454d9704f414226d5869":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5fa6528c3aa5487e87edb8797ebf465e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"632a7169fbd74159b11d92ab6cbacfa7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6502e372ae624b618f6248ee2ea778b6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65cbb712ea2f4dab90ba6600d8440c0b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c7b0a0b13b3450fa83c21af7c8525a2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c7f0e73512743efb870026d6677531e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6cd8338fff6a4f469d417911e8b8142b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54feb1dd180f4bf8b47c18713336d41c","placeholder":"​","style":"IPY_MODEL_7148c15a118641d3a9488fd981cc3bf3","value":"Downloading: 100%"}},"7148c15a118641d3a9488fd981cc3bf3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"717056921033432aa1612afdd7aab763":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d900d48dde840e0824e409582df0dd2","placeholder":"​","style":"IPY_MODEL_58564c36a43e4f3ab99a0e153cb5e480","value":"Downloading: 100%"}},"73c9f7d056704fd2ac03cb76d6f36df5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d83773323bd4e90bc86003c4220a662","placeholder":"​","style":"IPY_MODEL_df27936694364ed583b70df9a0870a08","value":"Downloading: 100%"}},"769e20765ef64788b8de218a9853c99e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77b7765f0fe04c8a976230fb2eb01065":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"784667efc3604b52a7a3e90afeeba909":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79f29a0c5f01482dbbb7700bd7b573a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4718ae66701049229c66c8506b3efe1b","IPY_MODEL_bddc64019a20420589041d59a8ac1e86","IPY_MODEL_158f6d85beec4b33bdc422ee9e115808"],"layout":"IPY_MODEL_d469fb245e2244848f21d12c9897e0e8"}},"7d83773323bd4e90bc86003c4220a662":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f4f04df6382427288c4e9422e4fbf7d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82b0759acdb845ea9859d2f96ce0e5d3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"830958dc67714696a237fc7a051931bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85aa7a96758841a3bb30895cf30d9912":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88b743167cd44b318de6a3998f466556":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d900d48dde840e0824e409582df0dd2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e60d43dcd7e4df9a554b7b8ed28c56d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7c1b532fc64473eab127d4f73c4ffd7","placeholder":"​","style":"IPY_MODEL_192f33925dd045d792b38a2444794a10","value":"Downloading: 100%"}},"91647e75ea5e4c16a11046fda73ba026":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"939389df612a4f23b8ab42d6dccd6c8d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"972de0d98911484dad5f2c7b560d973c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_269978945c9c48d280cd1eb1ddf2f7fc","max":521,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f543e115e78f40f7bc9813a76b5ba862","value":521}},"98ff0c5dbe8049c588ef631dfbc08ef8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e55762599f664a0fa5288de998af11c1","max":716133354,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ef630b6fc27b4750839918ef7ac13c6c","value":716133354}},"a56c41e3f2744ba6b2f5cd408a86e6d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8e60d43dcd7e4df9a554b7b8ed28c56d","IPY_MODEL_ebbe8ae171e94413be8fcc944c05b28b","IPY_MODEL_c280900ff8ba4cc8a2dbf30daad33a4b"],"layout":"IPY_MODEL_d15f42cd6e9d427c99f12b45ba2b04e1"}},"a7c1b532fc64473eab127d4f73c4ffd7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a825221a71434b82be79352ad867c68a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a89df2c0f77a445eb9a12550fcaed50d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6cd8338fff6a4f469d417911e8b8142b","IPY_MODEL_edd582160bd349c68d35b5461b9771c2","IPY_MODEL_f1868ee80eff44af8596b13875f7cddd"],"layout":"IPY_MODEL_ee730afc554f486591437c1c9de33490"}},"adef346525b5428cb77ce85b67b7de02":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f32062e1b8f74b2ba3ebb65244b8345d","IPY_MODEL_21bf688381ef4a8495a3a6981a84ef8d","IPY_MODEL_d601368d185f4c2f8de3b222976c42ef"],"layout":"IPY_MODEL_632a7169fbd74159b11d92ab6cbacfa7"}},"b968066f8f924c309860b111ae0816a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88b743167cd44b318de6a3998f466556","placeholder":"​","style":"IPY_MODEL_77b7765f0fe04c8a976230fb2eb01065","value":"Downloading: 100%"}},"b9b60187d34644bda94b224017bc450d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bddc64019a20420589041d59a8ac1e86":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d185bee7972497296fc31ba5c0d54d6","max":655,"min":0,"orientation":"horizontal","style":"IPY_MODEL_830958dc67714696a237fc7a051931bc","value":655}},"c280900ff8ba4cc8a2dbf30daad33a4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_317c759beaf6494db054eae9162ccfb2","placeholder":"​","style":"IPY_MODEL_4e0b4d1769974ba88e49d4fb02e2c4a2","value":" 1.70M/1.70M [00:00&lt;00:00, 3.07MB/s]"}},"d15f42cd6e9d427c99f12b45ba2b04e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3ce46e504bd4daf9ac3763a7cdc222f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d469fb245e2244848f21d12c9897e0e8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5ed4335e6bb418aaebd5316b616f54c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d601368d185f4c2f8de3b222976c42ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32acd792c0bf45419a87561dc4ccdb4c","placeholder":"​","style":"IPY_MODEL_769e20765ef64788b8de218a9853c99e","value":" 323/323 [00:00&lt;00:00, 7.17kB/s]"}},"d70b870ad108499e8651b57c9e9be34b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df27936694364ed583b70df9a0870a08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2cbc04f6abc4b45b5374f424dd88efa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3aeb80a52bf4ccdb69330b3ebce4355":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e55762599f664a0fa5288de998af11c1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e87825600783430391ed6af6be32c278":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_73c9f7d056704fd2ac03cb76d6f36df5","IPY_MODEL_972de0d98911484dad5f2c7b560d973c","IPY_MODEL_0344eb1638a44fc0bd8be3d2b5aafc99"],"layout":"IPY_MODEL_b9b60187d34644bda94b224017bc450d"}},"e9d9038ad82440aebdb0fb714add647d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_717056921033432aa1612afdd7aab763","IPY_MODEL_f010001c717b439797f738bb4353b74d","IPY_MODEL_0f3925eaafb9438ab0f6b27c356cfe99"],"layout":"IPY_MODEL_85aa7a96758841a3bb30895cf30d9912"}},"ebbe8ae171e94413be8fcc944c05b28b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6502e372ae624b618f6248ee2ea778b6","max":1780720,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d5ed4335e6bb418aaebd5316b616f54c","value":1780720}},"edd582160bd349c68d35b5461b9771c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_784667efc3604b52a7a3e90afeeba909","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_58c863f270ac42c3b195987575a8bc9a","value":112}},"ee730afc554f486591437c1c9de33490":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef630b6fc27b4750839918ef7ac13c6c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f010001c717b439797f738bb4353b74d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3ce46e504bd4daf9ac3763a7cdc222f","max":1780720,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5fa6528c3aa5487e87edb8797ebf465e","value":1780720}},"f1868ee80eff44af8596b13875f7cddd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c7b0a0b13b3450fa83c21af7c8525a2","placeholder":"​","style":"IPY_MODEL_5e3622f69800454d9704f414226d5869","value":" 112/112 [00:00&lt;00:00, 2.29kB/s]"}},"f32062e1b8f74b2ba3ebb65244b8345d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52e9ba2a4d974b15ae4b6ab1232dc256","placeholder":"​","style":"IPY_MODEL_a825221a71434b82be79352ad867c68a","value":"Downloading: 100%"}},"f543e115e78f40f7bc9813a76b5ba862":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"faaf710ce2cc471c9370811df2f54ba6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
